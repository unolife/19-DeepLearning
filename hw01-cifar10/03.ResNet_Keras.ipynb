{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출처:\n",
    "https://keras.io/examples/cifar10_resnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from six.moves import cPickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 32 \n",
    "epochs = 200\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "# Subtracting pixel mean imporves accuracy\n",
    "subtract_pixel_mean = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "version = 1\n",
    "\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "    \n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Modify path string. use your path which your dataset is in\n",
    "    path =  r'C:\\Users\\strea\\Links\\baseline_code_final (2)'\n",
    "    fpath = os.path.join(path, 'train_data')\n",
    "    \n",
    "    with open(fpath, 'rb') as f:\n",
    "        d = cPickle.load(f, encoding='bytes')\n",
    "    X_train = d['data']\n",
    "    y_train = d['labels']\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, 32, 32) # 3072개 숫자가 한줄로 이어진 배열 하나를 32x32짜리 배열 3개로 만듦\n",
    "    X_train = X_train.transpose(0, 2, 3, 1)\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    return X_train, y_train\n",
    "\n",
    "x_train, y_train = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "# tf.set_random_seed(seed)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image dimensions\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (28000, 32, 32, 3)\n",
      "y_train shape:  (28000, 1)\n",
      "28000 train samples\n",
      "12000 test samples\n"
     ]
    }
   ],
   "source": [
    "# If subtract pixel mean is enabled - 픽셀 몊균값을 빼줌(normalize)\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean # 왜 train의 평균을 빼는거지....\n",
    "    \n",
    "print('x_train shape: ', x_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrics.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    \n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    \n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "        \n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *- 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                num_filters=16,\n",
    "                kernel_size=3,\n",
    "                strides=1,\n",
    "                activation='relu',\n",
    "                batch_normaliztion=True,\n",
    "                conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    \n",
    "    # Arguemnts\n",
    "        input (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions / kernel= 핵, 선대 책 복습\n",
    "        strides (int): Conv2D square stride dimensions 몇 칸씩 건너 뛸건지\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool) : conv-bn-activation (True) or bn-activation-conv (False) / conv가 앞에오냐 뒤에오냐 차이\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                 kernel_size=kernel_size,\n",
    "                 strides=stridses,\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=l2(1e-4))\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x) # 인자가 주어지면 적용하는 코드 \n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x) # 인자가 주어지면 적용하는 코드 \n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x) # conv가 앞에오냐 뒤에오냐에 따라 적용 순서를 달리함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "    \n",
    "    Stacks f 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled) by a convolutional layer with strides=2,\n",
    "    while the number of filters is doubled. # 스트라이드로 레이어는 반으로 줄이고, 필터는 두배로 키움\n",
    "    Within each stage, the layers have the same number filters and the same number of filters.\n",
    "    각 단계 내에서, 계층들은 동일한 수의 필터와 동일한 수의 필터를 가지고 있다.-파파고\n",
    "    각 단계 내에서 레이어는 동일한 수의 필터와 같은 수의 필터를가집니다.-구글번역\n",
    "    뭐라는거냐...\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "    \n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "        \n",
    "    # Returns \n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if(depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])') # 왜지....\n",
    "    # Start model definition\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    #instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0: # first layer but not first stack ??????????\n",
    "                strides = 2 # downsample 각 단계 앞부분에 줄인다고 했었는데 그건가봄...\n",
    "            y = resnet_layer(inputs=x,\n",
    "                            num_filters=num_filters,   # x를 받아서 필터랑 stride 적용해서 y에 저장\n",
    "                            strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                            num_filters=num_filters,   # y를 받아서 필터 적용하고 y에 저장\n",
    "                            activation=None)\n",
    "            if stack > 0 and res_block == 0: # first Layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model       # 뭔 소린지 모르겠다..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
