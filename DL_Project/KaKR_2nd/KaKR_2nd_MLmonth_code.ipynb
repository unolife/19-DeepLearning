{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15030</th>\n",
       "      <td>15030</td>\n",
       "      <td>20141014T000000</td>\n",
       "      <td>610685.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2520</td>\n",
       "      <td>6023</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2520</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98056</td>\n",
       "      <td>47.5137</td>\n",
       "      <td>-122.167</td>\n",
       "      <td>2520</td>\n",
       "      <td>6023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15031</th>\n",
       "      <td>15031</td>\n",
       "      <td>20150326T000000</td>\n",
       "      <td>1007500.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3510</td>\n",
       "      <td>7200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2600</td>\n",
       "      <td>910</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5537</td>\n",
       "      <td>-122.398</td>\n",
       "      <td>2050</td>\n",
       "      <td>6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15032</th>\n",
       "      <td>15032</td>\n",
       "      <td>20140521T000000</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15033</th>\n",
       "      <td>15033</td>\n",
       "      <td>20150223T000000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>15034</td>\n",
       "      <td>20141015T000000</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id             date      price  bedrooms  bathrooms  sqft_living  \\\n",
       "15030  15030  20141014T000000   610685.0         4       2.50         2520   \n",
       "15031  15031  20150326T000000  1007500.0         4       3.50         3510   \n",
       "15032  15032  20140521T000000   360000.0         3       2.50         1530   \n",
       "15033  15033  20150223T000000   400000.0         4       2.50         2310   \n",
       "15034  15034  20141015T000000   325000.0         2       0.75         1020   \n",
       "\n",
       "       sqft_lot  floors  waterfront  view  ...  grade  sqft_above  \\\n",
       "15030      6023     2.0           0     0  ...      9        2520   \n",
       "15031      7200     2.0           0     0  ...      9        2600   \n",
       "15032      1131     3.0           0     0  ...      8        1530   \n",
       "15033      5813     2.0           0     0  ...      8        2310   \n",
       "15034      1076     2.0           0     0  ...      7        1020   \n",
       "\n",
       "       sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "15030              0      2014             0    98056  47.5137 -122.167   \n",
       "15031            910      2009             0    98136  47.5537 -122.398   \n",
       "15032              0      2009             0    98103  47.6993 -122.346   \n",
       "15033              0      2014             0    98146  47.5107 -122.362   \n",
       "15034              0      2008             0    98144  47.5941 -122.299   \n",
       "\n",
       "       sqft_living15  sqft_lot15  \n",
       "15030           2520        6023  \n",
       "15031           2050        6200  \n",
       "15032           1530        1509  \n",
       "15033           1830        7200  \n",
       "15034           1020        1357  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./input/train.csv')\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1.0, 1180, 5650, 1.0, 0, 0, 3, 7, 1180, 0, 1955, 0, 98178,\n",
       "       47.5112, -122.257, 1340, 5650], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.values\n",
    "# id, date ,price 빼고 저장\n",
    "X = dataset[:,3:21]\n",
    "# price만 담음\n",
    "Y = dataset[:,2]\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([221900.0, 180000.0, 510000.0, ..., 360000.0, 400000.0, 325000.0],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.001, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=18, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(3, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "15019/15019 [==============================] - 2s 141us/step - loss: 426229197880.1124\n",
      "Epoch 2/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 416608338955.2498\n",
      "Epoch 3/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 392216599615.4759\n",
      "Epoch 4/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 354317691565.2120\n",
      "Epoch 5/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 300905962006.3973\n",
      "Epoch 6/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 234845201484.1574\n",
      "Epoch 7/300\n",
      "15019/15019 [==============================] - 0s 12us/step - loss: 180658668095.9872\n",
      "Epoch 8/300\n",
      "15019/15019 [==============================] - 0s 12us/step - loss: 153622669128.5950\n",
      "Epoch 9/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 140904931553.2677\n",
      "Epoch 10/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 134301031179.8463\n",
      "Epoch 11/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 131260499926.9555\n",
      "Epoch 12/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 129921147457.0781\n",
      "Epoch 13/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 129211228089.6379\n",
      "Epoch 14/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 128620063142.8542\n",
      "Epoch 15/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 128088721485.0437\n",
      "Epoch 16/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 127549721581.9322\n",
      "Epoch 17/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 126969131106.9978\n",
      "Epoch 18/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 126375449717.3383\n",
      "Epoch 19/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 125750478134.6976\n",
      "Epoch 20/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 125115138592.3516 0s - loss: 131090874724.\n",
      "Epoch 21/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 124438854247.9409\n",
      "Epoch 22/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 123769416972.8349\n",
      "Epoch 23/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 123043002621.4944\n",
      "Epoch 24/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 122182527381.9455\n",
      "Epoch 25/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 121334927817.3535\n",
      "Epoch 26/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 120363608007.9558\n",
      "Epoch 27/300\n",
      "15019/15019 [==============================] - 0s 12us/step - loss: 119365442924.2874\n",
      "Epoch 28/300\n",
      "15019/15019 [==============================] - 0s 12us/step - loss: 118247457591.0726\n",
      "Epoch 29/300\n",
      "15019/15019 [==============================] - 0s 12us/step - loss: 117090290107.3083\n",
      "Epoch 30/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 115797010768.1289\n",
      "Epoch 31/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 114313132060.6357\n",
      "Epoch 32/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 112772542143.5526\n",
      "Epoch 33/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 111053075423.3416\n",
      "Epoch 34/300\n",
      "15019/15019 [==============================] - 0s 10us/step - loss: 109229990210.3565\n",
      "Epoch 35/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 107216122000.8150\n",
      "Epoch 36/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 104399232161.5191\n",
      "Epoch 37/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 101556972570.9312\n",
      "Epoch 38/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 99003669259.3009\n",
      "Epoch 39/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 96275940415.8849\n",
      "Epoch 40/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 92850480152.0676\n",
      "Epoch 41/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 89241477791.4396\n",
      "Epoch 42/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 84789007183.8903\n",
      "Epoch 43/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 81502907552.0192\n",
      "Epoch 44/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 78603933094.7861\n",
      "Epoch 45/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 76046146459.1613\n",
      "Epoch 46/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 73663885577.9032\n",
      "Epoch 47/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 71554951564.6730\n",
      "Epoch 48/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 69897609677.9897\n",
      "Epoch 49/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 68498324893.3772\n",
      "Epoch 50/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 67259290102.3525\n",
      "Epoch 51/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 66406077776.8789\n",
      "Epoch 52/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 65565243717.4928\n",
      "Epoch 53/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 64803786729.0914\n",
      "Epoch 54/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 64319537267.9065\n",
      "Epoch 55/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 63912791438.3775\n",
      "Epoch 56/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 63912010529.1186\n",
      "Epoch 57/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 63303214933.5492\n",
      "Epoch 58/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 63088323325.1194\n",
      "Epoch 59/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 62737973427.9960\n",
      "Epoch 60/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 62437673935.1147\n",
      "Epoch 61/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 61800423968.8970\n",
      "Epoch 62/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 61751983735.2814\n",
      "Epoch 63/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 61029803439.5132\n",
      "Epoch 64/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 60775229987.3515\n",
      "Epoch 65/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 60488263921.7674\n",
      "Epoch 66/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 60285100278.1309\n",
      "Epoch 67/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 60043642883.6817\n",
      "Epoch 68/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 59749415869.3878\n",
      "Epoch 69/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 59587033320.2221\n",
      "Epoch 70/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 59486411478.9384\n",
      "Epoch 71/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 59266815203.7904\n",
      "Epoch 72/300\n",
      "15019/15019 [==============================] - 0s 12us/step - loss: 59102764272.1992\n",
      "Epoch 73/300\n",
      "15019/15019 [==============================] - 0s 12us/step - loss: 59108575829.3958\n",
      "Epoch 74/300\n",
      "15019/15019 [==============================] - 0s 11us/step - loss: 58877011740.9596\n",
      "Epoch 75/300\n",
      "15019/15019 [==============================] - 0s 12us/step - loss: 58708001367.3049\n",
      "Epoch 76/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 58532706543.8583\n",
      "Epoch 77/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 58499433306.5264\n",
      "Epoch 78/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 58364026232.0144\n",
      "Epoch 79/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 58309647219.4804\n",
      "Epoch 80/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 58289863654.1597\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15019/15019 [==============================] - 0s 15us/step - loss: 58177275764.7758\n",
      "Epoch 82/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 58097144683.9806\n",
      "Epoch 83/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 58058657081.2885\n",
      "Epoch 84/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 58104524156.6506\n",
      "Epoch 85/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 57918923125.6281\n",
      "Epoch 86/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 57867129114.2665\n",
      "Epoch 87/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 57777658666.1184\n",
      "Epoch 88/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 57832612310.7168\n",
      "Epoch 89/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 57736819604.2069\n",
      "Epoch 90/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 57634697934.7568\n",
      "Epoch 91/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 57658855890.3533\n",
      "Epoch 92/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 57768338484.9761\n",
      "Epoch 93/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 57552549681.4137\n",
      "Epoch 94/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 57510116617.8350\n",
      "Epoch 95/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 57475967956.9782\n",
      "Epoch 96/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 57460304885.5684\n",
      "Epoch 97/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 57351083584.4645\n",
      "Epoch 98/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 57337948430.9485\n",
      "Epoch 99/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 57274839086.6353\n",
      "Epoch 100/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 57463514342.9267\n",
      "Epoch 101/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 57230956353.5042\n",
      "Epoch 102/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 57202923318.0499\n",
      "Epoch 103/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 57198259633.8313\n",
      "Epoch 104/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 57157967872.5454\n",
      "Epoch 105/300\n",
      "15019/15019 [==============================] - 0s 12us/step - loss: 57087360608.3729\n",
      "Epoch 106/300\n",
      "15019/15019 [==============================] - 0s 12us/step - loss: 57101067248.5231\n",
      "Epoch 107/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 57338816983.2623\n",
      "Epoch 108/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 57467001261.1268\n",
      "Epoch 109/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 56989294823.8130\n",
      "Epoch 110/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 56967526896.2163\n",
      "Epoch 111/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 57043983659.1070\n",
      "Epoch 112/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 56845364374.0648\n",
      "Epoch 113/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 56844962467.9395\n",
      "Epoch 114/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 56821466333.7905\n",
      "Epoch 115/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 56832021063.6234\n",
      "Epoch 116/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 56731731713.4147\n",
      "Epoch 117/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 56698982074.0981\n",
      "Epoch 118/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 56758695089.8824\n",
      "Epoch 119/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 56853681265.1111\n",
      "Epoch 120/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 56827711194.2792\n",
      "Epoch 121/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 56756156049.3263\n",
      "Epoch 122/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 56512941836.1872\n",
      "Epoch 123/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 56560758324.7375\n",
      "Epoch 124/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 56511343649.0674\n",
      "Epoch 125/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 56402348647.3954\n",
      "Epoch 126/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 56392321104.8618\n",
      "Epoch 127/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 56420725814.4761\n",
      "Epoch 128/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 56415692161.6960\n",
      "Epoch 129/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 56315872321.1122\n",
      "Epoch 130/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 56338298782.5022\n",
      "Epoch 131/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 56284280974.2241\n",
      "Epoch 132/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 56176799015.5616\n",
      "Epoch 133/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 56395397781.4853\n",
      "Epoch 134/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 56254178330.5221\n",
      "Epoch 135/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 56123818881.9346\n",
      "Epoch 136/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 56094145707.4735\n",
      "Epoch 137/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 56392194772.9612\n",
      "Epoch 138/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55954595933.2707\n",
      "Epoch 139/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 56263386358.3354\n",
      "Epoch 140/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 56005505659.5768\n",
      "Epoch 141/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55917053676.4152\n",
      "Epoch 142/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55856607546.5839\n",
      "Epoch 143/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55880431795.5869\n",
      "Epoch 144/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 55870884496.7127\n",
      "Epoch 145/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55927902957.1652\n",
      "Epoch 146/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55840870849.5809\n",
      "Epoch 147/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 55876894585.8212\n",
      "Epoch 148/300\n",
      "15019/15019 [==============================] - 0s 12us/step - loss: 55942722891.6972\n",
      "Epoch 149/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 55746360155.3446\n",
      "Epoch 150/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 55761979841.3082\n",
      "Epoch 151/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55691654499.1512\n",
      "Epoch 152/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55837624166.3216\n",
      "Epoch 153/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 55799189760.0852: 0s - loss: 55939670835.2\n",
      "Epoch 154/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55682224129.6363\n",
      "Epoch 155/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55799297717.3255\n",
      "Epoch 156/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55602719133.7863\n",
      "Epoch 157/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55823990557.2323\n",
      "Epoch 158/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55605282578.5962\n",
      "Epoch 159/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 55598065609.0467\n",
      "Epoch 160/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55574710633.9011\n",
      "Epoch 161/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 55557553926.1874\n",
      "Epoch 162/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55593535102.5086\n",
      "Epoch 163/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15019/15019 [==============================] - 0s 14us/step - loss: 55848660127.6101\n",
      "Epoch 164/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55485193609.4685\n",
      "Epoch 165/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 55511808469.6259\n",
      "Epoch 166/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55529352727.0109\n",
      "Epoch 167/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55523222727.9728\n",
      "Epoch 168/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 55612063982.3583\n",
      "Epoch 169/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55518518543.6985\n",
      "Epoch 170/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 55460604978.3852\n",
      "Epoch 171/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 55434863679.0668\n",
      "Epoch 172/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 55460822602.5552\n",
      "Epoch 173/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55777457143.8865\n",
      "Epoch 174/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 55388384771.3749\n",
      "Epoch 175/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55679043651.2258\n",
      "Epoch 176/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 55426586333.0065\n",
      "Epoch 177/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55385152825.8339\n",
      "Epoch 178/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55512835607.2836\n",
      "Epoch 179/300\n",
      "15019/15019 [==============================] - ETA: 0s - loss: 55390842597.517 - 0s 17us/step - loss: 55430370379.8847\n",
      "Epoch 180/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 55319165005.5892\n",
      "Epoch 181/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55352195831.9377\n",
      "Epoch 182/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55307147076.7769\n",
      "Epoch 183/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55356021273.8063\n",
      "Epoch 184/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55373066397.9056\n",
      "Epoch 185/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 55290809785.1948\n",
      "Epoch 186/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55299379553.7194\n",
      "Epoch 187/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55260546402.8785\n",
      "Epoch 188/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55217901909.7197\n",
      "Epoch 189/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55221355403.0708\n",
      "Epoch 190/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55752760490.9280\n",
      "Epoch 191/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55393606103.6713\n",
      "Epoch 192/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55281377339.4532\n",
      "Epoch 193/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55292950718.0867\n",
      "Epoch 194/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55245908564.8504\n",
      "Epoch 195/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55181924964.9409\n",
      "Epoch 196/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55280734805.6686\n",
      "Epoch 197/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55090978531.0063\n",
      "Epoch 198/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55345551424.7713\n",
      "Epoch 199/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55061161567.5547\n",
      "Epoch 200/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55085761286.5283\n",
      "Epoch 201/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55813178506.8833\n",
      "Epoch 202/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55696406157.0310\n",
      "Epoch 203/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55192244792.6237\n",
      "Epoch 204/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55489126930.1701\n",
      "Epoch 205/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55147056072.2626\n",
      "Epoch 206/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54982995955.1821\n",
      "Epoch 207/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54941003964.8595\n",
      "Epoch 208/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54963384372.0898\n",
      "Epoch 209/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 55039167431.7512\n",
      "Epoch 210/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 54994272617.0829\n",
      "Epoch 211/300\n",
      "15019/15019 [==============================] - 0s 12us/step - loss: 54956585370.8545\n",
      "Epoch 212/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 54972195266.5355\n",
      "Epoch 213/300\n",
      "15019/15019 [==============================] - 0s 12us/step - loss: 55064841808.2823\n",
      "Epoch 214/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54855773393.1090\n",
      "Epoch 215/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54902829717.8944\n",
      "Epoch 216/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55095277658.5434\n",
      "Epoch 217/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55116056284.3247\n",
      "Epoch 218/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55099841216.5753\n",
      "Epoch 219/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55538154112.7585\n",
      "Epoch 220/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54946775759.7113\n",
      "Epoch 221/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54873659079.3251\n",
      "Epoch 222/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55187100123.8985\n",
      "Epoch 223/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54962684998.7030\n",
      "Epoch 224/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 54800590174.7877\n",
      "Epoch 225/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54817142842.2260\n",
      "Epoch 226/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54817228232.8762\n",
      "Epoch 227/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55111444900.5361\n",
      "Epoch 228/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54805495876.1803\n",
      "Epoch 229/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54943272226.1072\n",
      "Epoch 230/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54980956762.7139\n",
      "Epoch 231/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54730466830.6929\n",
      "Epoch 232/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 55113950531.7883\n",
      "Epoch 233/300\n",
      "15019/15019 [==============================] - 0s 12us/step - loss: 54952077960.2583\n",
      "Epoch 234/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 54781274483.8554\n",
      "Epoch 235/300\n",
      "15019/15019 [==============================] - 0s 13us/step - loss: 54834993994.9813\n",
      "Epoch 236/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 55032694683.2295\n",
      "Epoch 237/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54734117356.3982\n",
      "Epoch 238/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54979200060.4759\n",
      "Epoch 239/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54764851702.6252\n",
      "Epoch 240/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54818752890.4007\n",
      "Epoch 241/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 54722792985.7381\n",
      "Epoch 242/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54772971172.6895\n",
      "Epoch 243/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54664624866.9381\n",
      "Epoch 244/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 55057500770.3501\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15019/15019 [==============================] - 0s 15us/step - loss: 54693945864.8975\n",
      "Epoch 246/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54800825907.3739\n",
      "Epoch 247/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 54665734442.2207\n",
      "Epoch 248/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54680408785.6203\n",
      "Epoch 249/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54705407808.9588\n",
      "Epoch 250/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54611001814.1714\n",
      "Epoch 251/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 54582967743.7401\n",
      "Epoch 252/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 54954227804.3161: 0s - loss: 55264330100.36\n",
      "Epoch 253/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54675352307.0287\n",
      "Epoch 254/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 54563711253.9029\n",
      "Epoch 255/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54510774942.4851\n",
      "Epoch 256/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 54646170615.0684\n",
      "Epoch 257/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54576220305.7695\n",
      "Epoch 258/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54750016546.9765\n",
      "Epoch 259/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54666715687.4423\n",
      "Epoch 260/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54687191539.0798\n",
      "Epoch 261/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54530959724.4919\n",
      "Epoch 262/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54505139132.8424\n",
      "Epoch 263/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54563999998.9943\n",
      "Epoch 264/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54676272774.0084\n",
      "Epoch 265/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54485660188.6698\n",
      "Epoch 266/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 54648711450.4028\n",
      "Epoch 267/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54452903392.4666\n",
      "Epoch 268/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54472010875.4745\n",
      "Epoch 269/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54527591707.9710\n",
      "Epoch 270/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54587641079.0173\n",
      "Epoch 271/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54458205037.0714\n",
      "Epoch 272/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 54758017573.5333\n",
      "Epoch 273/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 54445156762.8545\n",
      "Epoch 274/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54412430946.0092\n",
      "Epoch 275/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54505265199.9989\n",
      "Epoch 276/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54463386123.3520\n",
      "Epoch 277/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54458478405.1860\n",
      "Epoch 278/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54450661363.7275\n",
      "Epoch 279/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54411328160.6669\n",
      "Epoch 280/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54358410446.3818\n",
      "Epoch 281/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54372691924.0919\n",
      "Epoch 282/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54320420438.9640\n",
      "Epoch 283/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54426076114.5237\n",
      "Epoch 284/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54383419034.0534\n",
      "Epoch 285/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54401834836.4584\n",
      "Epoch 286/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 55046416348.4099\n",
      "Epoch 287/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54376045819.9262\n",
      "Epoch 288/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54335927611.4703\n",
      "Epoch 289/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 54391499214.9443\n",
      "Epoch 290/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 54550391621.6632\n",
      "Epoch 291/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54283957094.3898\n",
      "Epoch 292/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54422795110.2534\n",
      "Epoch 293/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54354775236.9047\n",
      "Epoch 294/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54343884826.4540\n",
      "Epoch 295/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54517939484.1073\n",
      "Epoch 296/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54259361972.4051\n",
      "Epoch 297/300\n",
      "15019/15019 [==============================] - 0s 16us/step - loss: 54286534809.6784\n",
      "Epoch 298/300\n",
      "15019/15019 [==============================] - 0s 17us/step - loss: 54244216784.2738: 0s - loss: 52498854518.1\n",
      "Epoch 299/300\n",
      "15019/15019 [==============================] - 0s 15us/step - loss: 54257699325.0342\n",
      "Epoch 300/300\n",
      "15019/15019 [==============================] - 0s 14us/step - loss: 54268716867.6860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a9f4f56128>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=300, batch_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch size\n",
    "* 배치사이즈는 몇 문항을 풀고 해답을 맞추는 지를 의미합니다. 100문항일 때, 배치사이즈가 100이면 전체를 다 풀고 난 뒤에 해답을 맞춰보는 것입니다. \n",
    "* 배치사이즈가 10이면 열 문제씩 풀어보고 해답 맞춰보는 것입니다. 100문항을 10문제씩 나누어서 10번 해답을 맞추므로 가중치 갱신은 10번 일어납니다.\n",
    "* 배치사이즈가 작을수록 가중치 갱신이 자주 일어납니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epochs\n",
    "* 에포크는 모의고사 1회분을 몇 번 풀어볼까 입니다. 즉 100문항의 문제들을 몇 번이나 반복해서 풀어보는 지 정하는 것입니다. 에포크가 20이면 모의고사 1회분을 20번 푸는 것입니다. 처음에는 같은 문제를 반복적으로 풀어보는 것이 무슨 효과가 있는 지 의문이 들었지만 우리가 같은 문제집을 여러 번 풀면서 점차 학습되듯이 모델도 같은 데이터셋으로 반복적으로 가중치를 갱신하면서 모델이 학습됩니다. 같은 문제라도 이전에 풀었을 때랑 지금 풀었을 때랑 학습상태(가중치)가 다르기 때문에 다시 학습이 일어납니다.\n",
    "* 같은 문제집이라도 반복해서 풀면 학습이 일어납니다.\n",
    "* 모의고사 1회분을 20번 푸는 것과 서로 다른 모의고사 20회분을 1번 푸는 것과는 어떤 차이가 있을까요? 이것은 분야에 따라 데이터특성에 따라 다를 것이라고 생각합니다. 잡다한 문제를 많이 푸는 것보다 양질의 문제를 여러 번 푸는 것이 도움이 된다고 생각합니다. 피아노를 배울 때도 기본 곡을 반복적으로 학습하면 다양한 악보도 쉽게 보는 반면 이곡 저곡 연습하면 제대로 익히기 쉽지 않습니다. 이런 문제를 제외하고도 현실적으로 데이터를 구하기가 쉽지 않기 때문에 제한된 데이터셋으로 반복적으로 학습하는 것이 효율적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 380000.000, 예상가격: 188821.375\n",
      "실제가격: 950000.000, 예상가격: 1198259.875\n",
      "실제가격: 580000.000, 예상가격: 637780.312\n",
      "실제가격: 335000.000, 예상가격: 194153.109\n",
      "실제가격: 861990.000, 예상가격: 1022958.688\n",
      "실제가격: 410000.000, 예상가격: 317610.125\n",
      "실제가격: 342400.000, 예상가격: 382523.750\n",
      "실제가격: 748000.000, 예상가격: 830348.312\n",
      "실제가격: 492000.000, 예상가격: 696375.188\n",
      "실제가격: 1142000.000, 예상가격: 766436.938\n"
     ]
    }
   ],
   "source": [
    "# 7:3으로 쪼갬 (30,6,1)\n",
    "# 예측 값과 실제 값의 비교 - epoch = 10의 결과\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 380000.000, 예상가격: 309096.719\n",
      "실제가격: 950000.000, 예상가격: 1269885.750\n",
      "실제가격: 580000.000, 예상가격: 654275.875\n",
      "실제가격: 335000.000, 예상가격: 251189.109\n",
      "실제가격: 861990.000, 예상가격: 1001344.938\n",
      "실제가격: 410000.000, 예상가격: 329298.625\n",
      "실제가격: 342400.000, 예상가격: 390568.469\n",
      "실제가격: 748000.000, 예상가격: 784984.062\n",
      "실제가격: 492000.000, 예상가격: 669180.625\n",
      "실제가격: 1142000.000, 예상가격: 723493.375\n"
     ]
    }
   ],
   "source": [
    "# 7:3으로 쪼갬 (30,6,1)\n",
    "# 예측 값과 실제 값의 비교 - epoch = 200의 결과 - los 50\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 380000.000, 예상가격: 300420.375,      오차: 79579.625\n",
      "실제가격: 950000.000, 예상가격: 981992.000,      오차: 31992.000\n",
      "실제가격: 580000.000, 예상가격: 637040.688,      오차: 57040.688\n",
      "실제가격: 335000.000, 예상가격: 230373.797,      오차: 104626.203\n",
      "실제가격: 861990.000, 예상가격: 764127.188,      오차: 97862.812\n",
      "실제가격: 410000.000, 예상가격: 324789.031,      오차: 85210.969\n",
      "실제가격: 342400.000, 예상가격: 423471.406,      오차: 81071.406\n",
      "실제가격: 748000.000, 예상가격: 715748.625,      오차: 32251.375\n",
      "실제가격: 492000.000, 예상가격: 685383.500,      오차: 193383.500\n",
      "실제가격: 1142000.000, 예상가격: 762045.812,      오차: 379954.188\n",
      "실제가격: 345000.000, 예상가격: 500264.719,      오차: 155264.719\n",
      "실제가격: 292000.000, 예상가격: 450863.469,      오차: 158863.469\n",
      "실제가격: 286000.000, 예상가격: 445862.375,      오차: 159862.375\n",
      "실제가격: 705000.000, 예상가격: 473212.250,      오차: 231787.750\n",
      "실제가격: 210000.000, 예상가격: 325764.844,      오차: 115764.844\n",
      "실제가격: 329950.000, 예상가격: 323600.281,      오차: 6349.719\n",
      "실제가격: 436800.000, 예상가격: 458993.938,      오차: 22193.938\n",
      "실제가격: 543000.000, 예상가격: 477974.594,      오차: 65025.406\n",
      "실제가격: 481000.000, 예상가격: 429708.344,      오차: 51291.656\n",
      "실제가격: 382500.000, 예상가격: 313321.406,      오차: 69178.594\n",
      "실제가격: 608095.000, 예상가격: 715967.375,      오차: 107872.375\n",
      "실제가격: 179950.000, 예상가격: 228889.969,      오차: 48939.969\n",
      "실제가격: 270000.000, 예상가격: 395719.156,      오차: 125719.156\n",
      "실제가격: 209500.000, 예상가격: 283277.875,      오차: 73777.875\n",
      "실제가격: 335000.000, 예상가격: 558691.750,      오차: 223691.750\n",
      "실제가격: 1250000.000, 예상가격: 1343980.375,      오차: 93980.375\n",
      "실제가격: 530000.000, 예상가격: 421279.656,      오차: 108720.344\n",
      "실제가격: 210000.000, 예상가격: 456385.750,      오차: 246385.750\n",
      "실제가격: 275000.000, 예상가격: 348158.375,      오차: 73158.375\n",
      "실제가격: 354000.000, 예상가격: 276257.969,      오차: 77742.031\n"
     ]
    }
   ],
   "source": [
    "# 9:1로 쪼갬 (30,6,1)\n",
    "# 예측 값과 실제 값의 비교 - epoch = 300의 결과 - loss 46\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "for i in range(30):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f},      오차: {:.3f}\".format(label, prediction, abs(label - prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 380000.000, 예상가격: 332577.062,      오차: 47422.938\n",
      "실제가격: 950000.000, 예상가격: 1279008.000,      오차: 329008.000\n",
      "실제가격: 580000.000, 예상가격: 694180.188,      오차: 114180.188\n",
      "실제가격: 335000.000, 예상가격: 225536.703,      오차: 109463.297\n",
      "실제가격: 861990.000, 예상가격: 982693.188,      오차: 120703.188\n",
      "실제가격: 410000.000, 예상가격: 326779.062,      오차: 83220.938\n",
      "실제가격: 342400.000, 예상가격: 410596.188,      오차: 68196.188\n",
      "실제가격: 748000.000, 예상가격: 796374.938,      오차: 48374.938\n",
      "실제가격: 492000.000, 예상가격: 709275.312,      오차: 217275.312\n",
      "실제가격: 1142000.000, 예상가격: 757918.312,      오차: 384081.688\n"
     ]
    }
   ],
   "source": [
    "# 99:1로 쪼갬\n",
    "# 층을 하나 늘림, dense=3을 추가 (30,6,3,1)\n",
    "# batch size 10에서 128로 늘림\n",
    "# 예측 값과 실제 값의 비교 - epoch = 300의 결과 / epoch당 순회 속도가 7초에서 1초로 줄어듬 - loss 53\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f},      오차: {:.3f}\".format(label, prediction, abs(label - prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 380000.000, 예상가격: 297041.000,      오차: 82959.000\n",
      "실제가격: 950000.000, 예상가격: 979617.688,      오차: 29617.688\n",
      "실제가격: 580000.000, 예상가격: 630454.000,      오차: 50454.000\n",
      "실제가격: 335000.000, 예상가격: 269082.875,      오차: 65917.125\n",
      "실제가격: 861990.000, 예상가격: 812836.000,      오차: 49154.000\n",
      "실제가격: 410000.000, 예상가격: 325695.938,      오차: 84304.062\n",
      "실제가격: 342400.000, 예상가격: 475397.000,      오차: 132997.000\n",
      "실제가격: 748000.000, 예상가격: 747869.312,      오차: 130.688\n",
      "실제가격: 492000.000, 예상가격: 657918.688,      오차: 165918.688\n",
      "실제가격: 1142000.000, 예상가격: 735634.062,      오차: 406365.938\n"
     ]
    }
   ],
   "source": [
    "# restart kernel\n",
    "# 99:1로 쪼갬\n",
    "# 층을 하나 늘림, dense=3을 추가 (30,6,3,1)\n",
    "# batch size 다시 10으로 줄임\n",
    "# 예측 값과 실제 값의 비교 - epoch = 300의 결과 / epoch당 순회 속도 9초 - loss 46\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f},      오차: {:.3f}\".format(label, prediction, abs(label - prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 380000.000, 예상가격: 326839.281,      오차: 53160.719\n",
      "실제가격: 950000.000, 예상가격: 1292310.875,      오차: 342310.875\n",
      "실제가격: 580000.000, 예상가격: 631366.188,      오차: 51366.188\n",
      "실제가격: 335000.000, 예상가격: 285191.531,      오차: 49808.469\n",
      "실제가격: 861990.000, 예상가격: 1016752.938,      오차: 154762.938\n",
      "실제가격: 410000.000, 예상가격: 362667.250,      오차: 47332.750\n",
      "실제가격: 342400.000, 예상가격: 396665.594,      오차: 54265.594\n",
      "실제가격: 748000.000, 예상가격: 810334.875,      오차: 62334.875\n",
      "실제가격: 492000.000, 예상가격: 676711.375,      오차: 184711.375\n",
      "실제가격: 1142000.000, 예상가격: 733225.625,      오차: 408774.375\n"
     ]
    }
   ],
   "source": [
    "# restart kernel\n",
    "# 999:1로 쪼갬\n",
    "# 층을 하나 늘림, dense=3을 추가 (30,6,3,1)b\n",
    "# batch size 500으로 함                                                             \n",
    "# 예측 값과 실제 값의 비교 - epoch = 300의 결과 / epoch당 순회 속도 0.몇초 - loss 54\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f},      오차: {:.3f}\".format(label, prediction, abs(label - prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1.75 2080 12714 2.0 0 0 4 8 1540 540 1984 0 98052 47.7056 -122.162 2080\n",
      " 12107]\n",
      "15019\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1.0 1000 4800 1.0 0 0 3 6 1000 0 1952 0 98117 47.6926 -122.362 1000\n",
      " 4800]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436800.0\n"
     ]
    }
   ],
   "source": [
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 767016.  ]\n",
      " [ 491297.22]\n",
      " [1287809.2 ]\n",
      " ...\n",
      " [ 436199.12]\n",
      " [ 367684.4 ]\n",
      " [ 477480.  ]]\n"
     ]
    }
   ],
   "source": [
    "#실제 Y 예측하기\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "# real_prediction = model.predict(test) 이렇게 집어 넣으면, 입력 커럼수가 달라서 안 됨\n",
    "data = test.values\n",
    "X_test = data[:, 2:21]\n",
    "real_prediction = model.predict(X_test)\n",
    "print(real_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15035</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15036</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15037</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15038</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15039</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   price\n",
       "0  15035  100000\n",
       "1  15036  100000\n",
       "2  15037  100000\n",
       "3  15038  100000\n",
       "4  15039  100000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi = pd.read_csv('./sample_submission.csv')\n",
    "hi.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = hi.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(6468, 1)\n"
     ]
    }
   ],
   "source": [
    "# pred_value = real_prediction.values\n",
    "print(type(real_prediction))\n",
    "print(real_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(6468, 2)\n"
     ]
    }
   ],
   "source": [
    "print(type(new))\n",
    "print(new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100000, 100000, 100000, ..., 100000, 100000, 100000], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = real_prediction.flatten() # new는 1행에 다 담겨있었고, real prediction은 6000행 1열이었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 767016.  ,  491297.22, 1287809.2 , ...,  436199.12,  367684.4 ,\n",
       "        477480.  ], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new[:,1] = hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  15035  767016]\n",
      " [  15036  491297]\n",
      " [  15037 1287809]\n",
      " ...\n",
      " [  21500  436199]\n",
      " [  21501  367684]\n",
      " [  21502  477480]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(new)\n",
    "print(type(new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"submission.csv\", new, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(new).to_csv(\"submission2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15035</td>\n",
       "      <td>767016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15036</td>\n",
       "      <td>491297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15037</td>\n",
       "      <td>1287809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15038</td>\n",
       "      <td>432146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15039</td>\n",
       "      <td>475544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>15040</td>\n",
       "      <td>541200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>15041</td>\n",
       "      <td>408966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15042</td>\n",
       "      <td>628200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>15043</td>\n",
       "      <td>409014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>15044</td>\n",
       "      <td>412020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>15045</td>\n",
       "      <td>637401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>15046</td>\n",
       "      <td>328733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>15047</td>\n",
       "      <td>847180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>15048</td>\n",
       "      <td>345840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>15049</td>\n",
       "      <td>646587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15050</td>\n",
       "      <td>302046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>15051</td>\n",
       "      <td>747577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>15052</td>\n",
       "      <td>449395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>15053</td>\n",
       "      <td>702842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>15054</td>\n",
       "      <td>434688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>15055</td>\n",
       "      <td>590485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>15056</td>\n",
       "      <td>668722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>15057</td>\n",
       "      <td>959736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>15058</td>\n",
       "      <td>614274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>15059</td>\n",
       "      <td>433028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>15060</td>\n",
       "      <td>322879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>15061</td>\n",
       "      <td>492014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>15062</td>\n",
       "      <td>627966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>15063</td>\n",
       "      <td>514681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>15064</td>\n",
       "      <td>429250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>6438</td>\n",
       "      <td>21473</td>\n",
       "      <td>469421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6439</th>\n",
       "      <td>6439</td>\n",
       "      <td>21474</td>\n",
       "      <td>1083092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6440</th>\n",
       "      <td>6440</td>\n",
       "      <td>21475</td>\n",
       "      <td>1527163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6441</th>\n",
       "      <td>6441</td>\n",
       "      <td>21476</td>\n",
       "      <td>393345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6442</th>\n",
       "      <td>6442</td>\n",
       "      <td>21477</td>\n",
       "      <td>994462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6443</th>\n",
       "      <td>6443</td>\n",
       "      <td>21478</td>\n",
       "      <td>442500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6444</th>\n",
       "      <td>6444</td>\n",
       "      <td>21479</td>\n",
       "      <td>1361480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6445</th>\n",
       "      <td>6445</td>\n",
       "      <td>21480</td>\n",
       "      <td>1727679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6446</th>\n",
       "      <td>6446</td>\n",
       "      <td>21481</td>\n",
       "      <td>506319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6447</th>\n",
       "      <td>6447</td>\n",
       "      <td>21482</td>\n",
       "      <td>512604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6448</th>\n",
       "      <td>6448</td>\n",
       "      <td>21483</td>\n",
       "      <td>598098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6449</th>\n",
       "      <td>6449</td>\n",
       "      <td>21484</td>\n",
       "      <td>785467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>6450</td>\n",
       "      <td>21485</td>\n",
       "      <td>435299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6451</th>\n",
       "      <td>6451</td>\n",
       "      <td>21486</td>\n",
       "      <td>467204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>6452</td>\n",
       "      <td>21487</td>\n",
       "      <td>598071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6453</th>\n",
       "      <td>6453</td>\n",
       "      <td>21488</td>\n",
       "      <td>499819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6454</th>\n",
       "      <td>6454</td>\n",
       "      <td>21489</td>\n",
       "      <td>370228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6455</th>\n",
       "      <td>6455</td>\n",
       "      <td>21490</td>\n",
       "      <td>394984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6456</th>\n",
       "      <td>6456</td>\n",
       "      <td>21491</td>\n",
       "      <td>1669943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6457</th>\n",
       "      <td>6457</td>\n",
       "      <td>21492</td>\n",
       "      <td>705595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6458</th>\n",
       "      <td>6458</td>\n",
       "      <td>21493</td>\n",
       "      <td>433907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6459</th>\n",
       "      <td>6459</td>\n",
       "      <td>21494</td>\n",
       "      <td>638463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6460</th>\n",
       "      <td>6460</td>\n",
       "      <td>21495</td>\n",
       "      <td>401720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6461</th>\n",
       "      <td>6461</td>\n",
       "      <td>21496</td>\n",
       "      <td>490327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6462</th>\n",
       "      <td>6462</td>\n",
       "      <td>21497</td>\n",
       "      <td>772120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463</th>\n",
       "      <td>6463</td>\n",
       "      <td>21498</td>\n",
       "      <td>319381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6464</th>\n",
       "      <td>6464</td>\n",
       "      <td>21499</td>\n",
       "      <td>470763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6465</th>\n",
       "      <td>6465</td>\n",
       "      <td>21500</td>\n",
       "      <td>436199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>6466</td>\n",
       "      <td>21501</td>\n",
       "      <td>367684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>6467</td>\n",
       "      <td>21502</td>\n",
       "      <td>477480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6468 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      0        1\n",
       "0              0  15035   767016\n",
       "1              1  15036   491297\n",
       "2              2  15037  1287809\n",
       "3              3  15038   432146\n",
       "4              4  15039   475544\n",
       "5              5  15040   541200\n",
       "6              6  15041   408966\n",
       "7              7  15042   628200\n",
       "8              8  15043   409014\n",
       "9              9  15044   412020\n",
       "10            10  15045   637401\n",
       "11            11  15046   328733\n",
       "12            12  15047   847180\n",
       "13            13  15048   345840\n",
       "14            14  15049   646587\n",
       "15            15  15050   302046\n",
       "16            16  15051   747577\n",
       "17            17  15052   449395\n",
       "18            18  15053   702842\n",
       "19            19  15054   434688\n",
       "20            20  15055   590485\n",
       "21            21  15056   668722\n",
       "22            22  15057   959736\n",
       "23            23  15058   614274\n",
       "24            24  15059   433028\n",
       "25            25  15060   322879\n",
       "26            26  15061   492014\n",
       "27            27  15062   627966\n",
       "28            28  15063   514681\n",
       "29            29  15064   429250\n",
       "...          ...    ...      ...\n",
       "6438        6438  21473   469421\n",
       "6439        6439  21474  1083092\n",
       "6440        6440  21475  1527163\n",
       "6441        6441  21476   393345\n",
       "6442        6442  21477   994462\n",
       "6443        6443  21478   442500\n",
       "6444        6444  21479  1361480\n",
       "6445        6445  21480  1727679\n",
       "6446        6446  21481   506319\n",
       "6447        6447  21482   512604\n",
       "6448        6448  21483   598098\n",
       "6449        6449  21484   785467\n",
       "6450        6450  21485   435299\n",
       "6451        6451  21486   467204\n",
       "6452        6452  21487   598071\n",
       "6453        6453  21488   499819\n",
       "6454        6454  21489   370228\n",
       "6455        6455  21490   394984\n",
       "6456        6456  21491  1669943\n",
       "6457        6457  21492   705595\n",
       "6458        6458  21493   433907\n",
       "6459        6459  21494   638463\n",
       "6460        6460  21495   401720\n",
       "6461        6461  21496   490327\n",
       "6462        6462  21497   772120\n",
       "6463        6463  21498   319381\n",
       "6464        6464  21499   470763\n",
       "6465        6465  21500   436199\n",
       "6466        6466  21501   367684\n",
       "6467        6467  21502   477480\n",
       "\n",
       "[6468 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv(\"submission2.csv\")\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
