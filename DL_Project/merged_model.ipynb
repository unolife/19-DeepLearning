{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge multiple model after preprocessing\n",
    "\n",
    "cf) baseline kernel: https://www.kaggle.com/kcs93023/2019-ml-month-2nd-baseline\n",
    "    모두의 딥러닝: http://www.yes24.com/Product/Goods/57736119?scode=032&OzSrank=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from math import sqrt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./input/test.csv')\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "print(test.shape, train.shape)\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Description\n",
    "\n",
    "1. ID : 집을 구분하는 번호 \n",
    "1. date : 집을 구매한 날짜 \n",
    "1. price : 타겟 변수인 집의 가격 \n",
    "1. bedrooms : 침실의 수\n",
    "1. bathrooms : 침실당 화장실 개수\n",
    "1. sqft_living : 주거 공간의 평방 피트\n",
    "1. sqft_lot : 부지의 평방 피트\n",
    "1. floors : 집의 층 수\n",
    "1. waterfront : 집의 전방에 강이 흐르는지 유무 (a.k.a. 리버뷰)\n",
    "1. view : 집이 얼마나 좋아 보이는지의 정도\n",
    "1. condition : 집의 전반적인 상태\n",
    "1. grade : King County grading 시스템 기준으로 매긴 집의 등급\n",
    "1. sqft_above : 지하실을 제외한 평방 피트\n",
    "1. sqft_basement : 지하실의 평방 피트\n",
    "1. yr_built : 집을 지은 년도\n",
    "1. yr_renovated : 집을 재건축한 년도\n",
    "1. zipcode : 우편번호\n",
    "1. lat : 위도\n",
    "1. long : 경도\n",
    "1. sqft_living15 : 2015년 기준 주거 공간의 평방 피트(집을 재건축했다면, 변화가 있을 수 있음)\n",
    "1. sqft_lot15 : 2015년 기준 부지의 평방 피트(집을 재건축했다면, 변화가 있을 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['price']\n",
    "del train['price'] # 가격을 별도로 저장 후, 원본에서 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(train) # 둘을 합치기 전에, 구분점(train의 길이)을 저장\n",
    "data = pd.concat((train, test), axis=0)  # 합침"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data.columns:\n",
    "    print('{} : {}'.format(c, len(data.loc[pd.isnull(data[c]),c].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manipulate id,date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_id = data['id'][train_len:]\n",
    "del data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = data['date'].apply(lambda x: str(x[:6])).astype(str)\n",
    "print(len(data))\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(10, 2, figsize=(20,60))\n",
    "\n",
    "# ignore id column\n",
    "count = 0\n",
    "columns = data.columns\n",
    "for row in range(10):\n",
    "    for col in range(2):\n",
    "        sns.kdeplot(data[columns[count]], ax=ax[row][col]) # kernel density plot\n",
    "        ax[row][col].set_title(columns[count], fontsize=15)\n",
    "        count+=1\n",
    "        if count == 19:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply log-scaling\n",
    "price, bedrooms, sqft_living, sqft_lot, sqft_above, sqft_basement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_columns = ['bedrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement']\n",
    "\n",
    "for c in skew_columns:\n",
    "    data[c] = np.log1p(data[c].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "count = 0\n",
    "for row in range(3):\n",
    "    for col in range(2):\n",
    "        if count == 5:\n",
    "            break\n",
    "        sns.kdeplot(data[skew_columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(skew_columns[count], fontsize=15)\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### divide data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = data.iloc[train_len:, :]\n",
    "x = data.iloc[:train_len, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Except Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingRegressor(random_state=2019)\n",
    "xgboost = xgb.XGBRegressor(random_state=2019)\n",
    "lightgbm = lgb.LGBMRegressor(random_state=2019)\n",
    "lasso = Lasso(alpha=1.0, random_state=2019)\n",
    "svm = svm.SVC(kernel='rbf', C=1, gamma=0.1, random_state=2019)\n",
    "\n",
    "models = [{'model':xgboost, 'name':'XGBoost'},\n",
    "          {'model':gboost, 'name': 'GradientBoosting'},\n",
    "          {'model':lightgbm, 'name':'LightGBM'}] # too slow and too low score\n",
    "#           {'model':xgboost, 'name':'XGBoost'},\n",
    "#           {'model':gboost, 'name': 'GradientBoosting'},\n",
    "#           {'model':lasso, 'name': 'Lasso'},\n",
    "#           {'model':svm, 'name': 'SVM'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_score(models):\n",
    "    kfold = KFold(n_splits=5, random_state=2019).get_n_splits(x.values)\n",
    "    for m in models:\n",
    "        print(\"Model {} CV score : {:.4f}\".format(m['name'], np.mean(cross_val_score(m['model'], x.values, y)), kf=kfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cv_score(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AveragingBlending(models, x, y, sub_x):\n",
    "    for m in models : \n",
    "        m['model'].fit(x.values, y)\n",
    "        \n",
    "    predictions = np.column_stack([\n",
    "        m['model'].predict(sub_x.values) for m in models\n",
    "    ])\n",
    "    return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = AveragingBlending(models, x, y, sub) # 다른 노트북 keras 학습이랑 같이 시키니까 커널 죽음... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.DataFrame(data={'id':sub_id, 'price':y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('lgbm+XGB+gboost_after_preprocessing.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.001, random_state=seed) # 15035개에서 0.001인 16개만 샘프롤 꺼냄\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(190, input_dim=19, activation='relu'))\n",
    "model.add(Dense(380, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam') # accuracy를 쓸 수 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=100, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_prediction = model.predict(X_test).flatten()\n",
    "\n",
    "# peek 5 samples\n",
    "\n",
    "for i in range(5):\n",
    "    label = Y_test.values[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f},      오차: {:.3f}\".format(label, prediction, abs(label - prediction)))\n",
    "RMSE = sqrt(mean_squared_error(Y_test, Y_prediction))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = model.predict(sub).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(data={'id':sub_id, 'price':test_predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('Keras_4th_add_more_layers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE score\n",
    "\n",
    "* light gmb : 121,182 - 04/07\n",
    "* lgbm+XGB+gboost_after_preprocessing : 129,439 - 04/07\n",
    "* merged model : 167,483 - 04/07\n",
    "* 3rd keras: : 281,574 - layer(40,20,5,1) - 04/07\n",
    "* 4th keras : 281,639 - layer(19,190,380,100,50,25,5,1) - 04/07  / rmse = 182,448\n",
    "\n",
    "keras - layer(19,190,380,100,50,25,5,1) - rmse=238,108"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
