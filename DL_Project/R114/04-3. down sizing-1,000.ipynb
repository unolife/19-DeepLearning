{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>district</th>\n",
       "      <th>dong</th>\n",
       "      <th>apartment</th>\n",
       "      <th>m2</th>\n",
       "      <th>price</th>\n",
       "      <th>floor</th>\n",
       "      <th>pre_m2</th>\n",
       "      <th>moving_date</th>\n",
       "      <th>num_people</th>\n",
       "      <th>people_by_m2</th>\n",
       "      <th>price_by_m2</th>\n",
       "      <th>price_by_pre_m2</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1156</td>\n",
       "      <td>1504</td>\n",
       "      <td>196.21</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>211.23</td>\n",
       "      <td>1976.06</td>\n",
       "      <td>480.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7582.0</td>\n",
       "      <td>7043.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1706</td>\n",
       "      <td>4942</td>\n",
       "      <td>202.58</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>252.31</td>\n",
       "      <td>2010.07</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7343.0</td>\n",
       "      <td>5896.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1156</td>\n",
       "      <td>9746</td>\n",
       "      <td>139.83</td>\n",
       "      <td>320000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>165.29</td>\n",
       "      <td>1982.04</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>7565.0</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>393</td>\n",
       "      <td>15322</td>\n",
       "      <td>191.04</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>219.22</td>\n",
       "      <td>1983.12</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5451.0</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1156</td>\n",
       "      <td>1509</td>\n",
       "      <td>144.20</td>\n",
       "      <td>304000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>158.68</td>\n",
       "      <td>1979.05</td>\n",
       "      <td>560.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>6969.0</td>\n",
       "      <td>6333.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city  district  dong  apartment      m2     price  floor  pre_m2  \\\n",
       "0     8         1  1156       1504  196.21  450000.0   13.0  211.23   \n",
       "1     8         1  1706       4942  202.58  450000.0    5.0  252.31   \n",
       "2     8         1  1156       9746  139.83  320000.0    7.0  165.29   \n",
       "3     8         1   393      15322  191.04  315000.0    2.0  219.22   \n",
       "4     8         1  1156       1509  144.20  304000.0   10.0  158.68   \n",
       "\n",
       "   moving_date  num_people  people_by_m2  price_by_m2  price_by_pre_m2  year  \\\n",
       "0      1976.06       480.0         120.0       7582.0           7043.0  2018   \n",
       "1      2010.07        19.0           1.0       7343.0           5896.0  2018   \n",
       "2      1982.04      1924.0         168.0       7565.0           6400.0  2018   \n",
       "3      1983.12      1204.0          84.0       5451.0           4750.0  2018   \n",
       "4      1979.05       560.0         168.0       6969.0           6333.0  2018   \n",
       "\n",
       "   month  \n",
       "0     12  \n",
       "1     12  \n",
       "2     12  \n",
       "3     12  \n",
       "4     12  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./preprocessed_apartment.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6174900, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>district</th>\n",
       "      <th>dong</th>\n",
       "      <th>apartment</th>\n",
       "      <th>m2</th>\n",
       "      <th>price</th>\n",
       "      <th>floor</th>\n",
       "      <th>pre_m2</th>\n",
       "      <th>moving_date</th>\n",
       "      <th>num_people</th>\n",
       "      <th>people_by_m2</th>\n",
       "      <th>price_by_m2</th>\n",
       "      <th>price_by_pre_m2</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4652760</th>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "      <td>184</td>\n",
       "      <td>14361</td>\n",
       "      <td>84.98</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>109.09</td>\n",
       "      <td>1992.09</td>\n",
       "      <td>211.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>622.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136995</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>1086</td>\n",
       "      <td>6242</td>\n",
       "      <td>50.85</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>66.12</td>\n",
       "      <td>1985.12</td>\n",
       "      <td>545.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487138</th>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>334</td>\n",
       "      <td>13943</td>\n",
       "      <td>59.89</td>\n",
       "      <td>31500.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>76.03</td>\n",
       "      <td>2000.05</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1739.0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181494</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1922</td>\n",
       "      <td>14338</td>\n",
       "      <td>69.33</td>\n",
       "      <td>37600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>86.67</td>\n",
       "      <td>2005.05</td>\n",
       "      <td>98.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1793.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323564</th>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>489</td>\n",
       "      <td>15345</td>\n",
       "      <td>84.99</td>\n",
       "      <td>58250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>109.56</td>\n",
       "      <td>2010.05</td>\n",
       "      <td>885.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2266.0</td>\n",
       "      <td>1758.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city  district  dong  apartment     m2    price  floor  pre_m2  \\\n",
       "4652760     7        82   184      14361  84.98  16000.0   17.0  109.09   \n",
       "4136995     5        60  1086       6242  50.85  13500.0    4.0   66.12   \n",
       "487138      8        61   334      13943  59.89  31500.0   20.0   76.03   \n",
       "181494      8         5  1922      14338  69.33  37600.0    4.0   86.67   \n",
       "2323564     1       148   489      15345  84.99  58250.0    1.0  109.56   \n",
       "\n",
       "         moving_date  num_people  people_by_m2  price_by_m2  price_by_pre_m2  \\\n",
       "4652760      1992.09       211.0         211.0        622.0            485.0   \n",
       "4136995      1985.12       545.0         160.0        878.0            675.0   \n",
       "487138       2000.05      1542.0         200.0       1739.0           1370.0   \n",
       "181494       2005.05        98.0          31.0       1793.0           1434.0   \n",
       "2323564      2010.05       885.0          21.0       2266.0           1758.0   \n",
       "\n",
       "         year  month  \n",
       "4652760  2018      5  \n",
       "4136995  2016     12  \n",
       "487138   2015      3  \n",
       "181494   2017      6  \n",
       "2323564  2016     12  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(n=1000)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "del df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test,y_train, y_test = train_test_split(df, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingRegressor(random_state=0)\n",
    "xgboost = xgb.XGBRegressor(random_state=0)\n",
    "lightgbm = lgb.LGBMRegressor(random_state=0)\n",
    "lasso = Lasso(alpha=1.0, random_state=0)\n",
    "svm = svm.SVC(kernel='rbf', C=1, gamma=0.1, random_state=0)\n",
    "\n",
    "models = [{'model':xgboost, 'name':'XGBoost'},\n",
    "          {'model':gboost, 'name': 'GradientBoosting'},\n",
    "          {'model':lightgbm, 'name':'LightGBM'},\n",
    "          {'model':lasso, 'name': 'Lasso'},\n",
    "          {'model':svm, 'name': 'SVM'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_each(models, x, y, sub_x, sub_y):\n",
    "    for m in models :\n",
    "        RMSE = []\n",
    "        \n",
    "        for m in models:\n",
    "            start = time.time()\n",
    "            m['model'].fit(x.values, y)\n",
    "            predictions = m['model'].predict(sub_x.values) \n",
    "            result = sqrt(mean_squared_error(sub_y, predictions))\n",
    "            end = round((time.time() - start), 4)\n",
    "            RMSE.append(m['name'])\n",
    "            RMSE.append(round(result))\n",
    "            RMSE.append(end)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['XGBoost',\n",
       " 6648,\n",
       " 0.1358,\n",
       " 'GradientBoosting',\n",
       " 6217,\n",
       " 0.07,\n",
       " 'LightGBM',\n",
       " 8835,\n",
       " 0.1311,\n",
       " 'Lasso',\n",
       " 7152,\n",
       " 0.03,\n",
       " 'SVM',\n",
       " 24399,\n",
       " 0.7192]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_each(models, x_train, y_train, x_test, y_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(140, input_dim=14, activation='relu'))\n",
    "model.add(Dense(35, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "# loss는 train loss고 val_loss는 validation loss임 / acc도 마찬가지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 420 samples, validate on 280 samples\n",
      "Epoch 1/100\n",
      "420/420 [==============================] - 28s 67ms/step - loss: 912911424.0000 - acc: 0.0000e+00 - val_loss: 984458368.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 984458368.00000, saving model to ./model/01-984458368.0000.hdf5\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 898925120.0000 - acc: 0.0000e+00 - val_loss: 971725824.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 984458368.00000 to 971725824.00000, saving model to ./model/02-971725824.0000.hdf5\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 885418368.0000 - acc: 0.0000e+00 - val_loss: 959218240.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 971725824.00000 to 959218240.00000, saving model to ./model/03-959218240.0000.hdf5\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 872262208.0000 - acc: 0.0000e+00 - val_loss: 946909696.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 959218240.00000 to 946909696.00000, saving model to ./model/04-946909696.0000.hdf5\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 859312576.0000 - acc: 0.0000e+00 - val_loss: 934860032.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss improved from 946909696.00000 to 934860032.00000, saving model to ./model/05-934860032.0000.hdf5\n",
      "Epoch 6/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 846621696.0000 - acc: 0.0000e+00 - val_loss: 923182272.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss improved from 934860032.00000 to 923182272.00000, saving model to ./model/06-923182272.0000.hdf5\n",
      "Epoch 7/100\n",
      "420/420 [==============================] - 0s 19us/step - loss: 834346944.0000 - acc: 0.0000e+00 - val_loss: 911932992.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss improved from 923182272.00000 to 911932992.00000, saving model to ./model/07-911932992.0000.hdf5\n",
      "Epoch 8/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 822550272.0000 - acc: 0.0000e+00 - val_loss: 900741824.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss improved from 911932992.00000 to 900741824.00000, saving model to ./model/08-900741824.0000.hdf5\n",
      "Epoch 9/100\n",
      "420/420 [==============================] - 0s 17us/step - loss: 810836992.0000 - acc: 0.0000e+00 - val_loss: 889546304.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss improved from 900741824.00000 to 889546304.00000, saving model to ./model/09-889546304.0000.hdf5\n",
      "Epoch 10/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 799068032.0000 - acc: 0.0000e+00 - val_loss: 878294976.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss improved from 889546304.00000 to 878294976.00000, saving model to ./model/10-878294976.0000.hdf5\n",
      "Epoch 11/100\n",
      "420/420 [==============================] - 0s 17us/step - loss: 787267840.0000 - acc: 0.0000e+00 - val_loss: 867008576.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss improved from 878294976.00000 to 867008576.00000, saving model to ./model/11-867008576.0000.hdf5\n",
      "Epoch 12/100\n",
      "420/420 [==============================] - 0s 19us/step - loss: 775464448.0000 - acc: 0.0000e+00 - val_loss: 855720064.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss improved from 867008576.00000 to 855720064.00000, saving model to ./model/12-855720064.0000.hdf5\n",
      "Epoch 13/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 763619456.0000 - acc: 0.0000e+00 - val_loss: 844368832.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss improved from 855720064.00000 to 844368832.00000, saving model to ./model/13-844368832.0000.hdf5\n",
      "Epoch 14/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 751731392.0000 - acc: 0.0000e+00 - val_loss: 832914368.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss improved from 844368832.00000 to 832914368.00000, saving model to ./model/14-832914368.0000.hdf5\n",
      "Epoch 15/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 739759104.0000 - acc: 0.0000e+00 - val_loss: 821335552.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss improved from 832914368.00000 to 821335552.00000, saving model to ./model/15-821335552.0000.hdf5\n",
      "Epoch 16/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 727671552.0000 - acc: 0.0000e+00 - val_loss: 809601024.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss improved from 821335552.00000 to 809601024.00000, saving model to ./model/16-809601024.0000.hdf5\n",
      "Epoch 17/100\n",
      "420/420 [==============================] - 0s 17us/step - loss: 715431936.0000 - acc: 0.0000e+00 - val_loss: 797725760.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss improved from 809601024.00000 to 797725760.00000, saving model to ./model/17-797725760.0000.hdf5\n",
      "Epoch 18/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 703041600.0000 - acc: 0.0000e+00 - val_loss: 785683840.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss improved from 797725760.00000 to 785683840.00000, saving model to ./model/18-785683840.0000.hdf5\n",
      "Epoch 19/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 690470848.0000 - acc: 0.0000e+00 - val_loss: 773404288.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss improved from 785683840.00000 to 773404288.00000, saving model to ./model/19-773404288.0000.hdf5\n",
      "Epoch 20/100\n",
      "420/420 [==============================] - 0s 29us/step - loss: 677693632.0000 - acc: 0.0000e+00 - val_loss: 760883520.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss improved from 773404288.00000 to 760883520.00000, saving model to ./model/20-760883520.0000.hdf5\n",
      "Epoch 21/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 664725120.0000 - acc: 0.0000e+00 - val_loss: 748219584.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss improved from 760883520.00000 to 748219584.00000, saving model to ./model/21-748219584.0000.hdf5\n",
      "Epoch 22/100\n",
      "420/420 [==============================] - 0s 19us/step - loss: 651598016.0000 - acc: 0.0000e+00 - val_loss: 735432576.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss improved from 748219584.00000 to 735432576.00000, saving model to ./model/22-735432576.0000.hdf5\n",
      "Epoch 23/100\n",
      "420/420 [==============================] - 0s 19us/step - loss: 638384704.0000 - acc: 0.0000e+00 - val_loss: 722570944.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss improved from 735432576.00000 to 722570944.00000, saving model to ./model/23-722570944.0000.hdf5\n",
      "Epoch 24/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 625110912.0000 - acc: 0.0000e+00 - val_loss: 709648960.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss improved from 722570944.00000 to 709648960.00000, saving model to ./model/24-709648960.0000.hdf5\n",
      "Epoch 25/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 611811904.0000 - acc: 0.0000e+00 - val_loss: 696715584.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss improved from 709648960.00000 to 696715584.00000, saving model to ./model/25-696715584.0000.hdf5\n",
      "Epoch 26/100\n",
      "420/420 [==============================] - 0s 19us/step - loss: 598551744.0000 - acc: 0.0000e+00 - val_loss: 683800064.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss improved from 696715584.00000 to 683800064.00000, saving model to ./model/26-683800064.0000.hdf5\n",
      "Epoch 27/100\n",
      "420/420 [==============================] - 0s 19us/step - loss: 585320448.0000 - acc: 0.0000e+00 - val_loss: 670873856.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss improved from 683800064.00000 to 670873856.00000, saving model to ./model/27-670873856.0000.hdf5\n",
      "Epoch 28/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 572114368.0000 - acc: 0.0000e+00 - val_loss: 657944960.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_loss improved from 670873856.00000 to 657944960.00000, saving model to ./model/28-657944960.0000.hdf5\n",
      "Epoch 29/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 558929152.0000 - acc: 0.0000e+00 - val_loss: 645029248.0000 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00029: val_loss improved from 657944960.00000 to 645029248.00000, saving model to ./model/29-645029248.0000.hdf5\n",
      "Epoch 30/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 545781376.0000 - acc: 0.0000e+00 - val_loss: 632164672.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_loss improved from 645029248.00000 to 632164672.00000, saving model to ./model/30-632164672.0000.hdf5\n",
      "Epoch 31/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 532713760.0000 - acc: 0.0000e+00 - val_loss: 619389824.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_loss improved from 632164672.00000 to 619389824.00000, saving model to ./model/31-619389824.0000.hdf5\n",
      "Epoch 32/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 519767136.0000 - acc: 0.0000e+00 - val_loss: 606729472.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_loss improved from 619389824.00000 to 606729472.00000, saving model to ./model/32-606729472.0000.hdf5\n",
      "Epoch 33/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 506986816.0000 - acc: 0.0000e+00 - val_loss: 594216384.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_loss improved from 606729472.00000 to 594216384.00000, saving model to ./model/33-594216384.0000.hdf5\n",
      "Epoch 34/100\n",
      "420/420 [==============================] - 0s 12us/step - loss: 494418656.0000 - acc: 0.0000e+00 - val_loss: 581899712.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00034: val_loss improved from 594216384.00000 to 581899712.00000, saving model to ./model/34-581899712.0000.hdf5\n",
      "Epoch 35/100\n",
      "420/420 [==============================] - 0s 17us/step - loss: 482115584.0000 - acc: 0.0000e+00 - val_loss: 569826368.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_loss improved from 581899712.00000 to 569826368.00000, saving model to ./model/35-569826368.0000.hdf5\n",
      "Epoch 36/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 470122272.0000 - acc: 0.0000e+00 - val_loss: 558056512.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_loss improved from 569826368.00000 to 558056512.00000, saving model to ./model/36-558056512.0000.hdf5\n",
      "Epoch 37/100\n",
      "420/420 [==============================] - 0s 12us/step - loss: 458495424.0000 - acc: 0.0000e+00 - val_loss: 546639488.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_loss improved from 558056512.00000 to 546639488.00000, saving model to ./model/37-546639488.0000.hdf5\n",
      "Epoch 38/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 447291584.0000 - acc: 0.0000e+00 - val_loss: 535625568.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00038: val_loss improved from 546639488.00000 to 535625568.00000, saving model to ./model/38-535625568.0000.hdf5\n",
      "Epoch 39/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 436568576.0000 - acc: 0.0000e+00 - val_loss: 525069056.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_loss improved from 535625568.00000 to 525069056.00000, saving model to ./model/39-525069056.0000.hdf5\n",
      "Epoch 40/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 426380096.0000 - acc: 0.0000e+00 - val_loss: 515013824.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00040: val_loss improved from 525069056.00000 to 515013824.00000, saving model to ./model/40-515013824.0000.hdf5\n",
      "Epoch 41/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 416775264.0000 - acc: 0.0000e+00 - val_loss: 505508480.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00041: val_loss improved from 515013824.00000 to 505508480.00000, saving model to ./model/41-505508480.0000.hdf5\n",
      "Epoch 42/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 407815936.0000 - acc: 0.0000e+00 - val_loss: 496613504.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00042: val_loss improved from 505508480.00000 to 496613504.00000, saving model to ./model/42-496613504.0000.hdf5\n",
      "Epoch 43/100\n",
      "420/420 [==============================] - 0s 26us/step - loss: 399542144.0000 - acc: 0.0000e+00 - val_loss: 488352512.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00043: val_loss improved from 496613504.00000 to 488352512.00000, saving model to ./model/43-488352512.0000.hdf5\n",
      "Epoch 44/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 391988640.0000 - acc: 0.0000e+00 - val_loss: 480757504.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00044: val_loss improved from 488352512.00000 to 480757504.00000, saving model to ./model/44-480757504.0000.hdf5\n",
      "Epoch 45/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 385175200.0000 - acc: 0.0000e+00 - val_loss: 473848992.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00045: val_loss improved from 480757504.00000 to 473848992.00000, saving model to ./model/45-473848992.0000.hdf5\n",
      "Epoch 46/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 379130272.0000 - acc: 0.0000e+00 - val_loss: 467632768.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00046: val_loss improved from 473848992.00000 to 467632768.00000, saving model to ./model/46-467632768.0000.hdf5\n",
      "Epoch 47/100\n",
      "420/420 [==============================] - 0s 17us/step - loss: 373857536.0000 - acc: 0.0000e+00 - val_loss: 462093760.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00047: val_loss improved from 467632768.00000 to 462093760.00000, saving model to ./model/47-462093760.0000.hdf5\n",
      "Epoch 48/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 369311008.0000 - acc: 0.0000e+00 - val_loss: 457177120.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00048: val_loss improved from 462093760.00000 to 457177120.00000, saving model to ./model/48-457177120.0000.hdf5\n",
      "Epoch 49/100\n",
      "420/420 [==============================] - 0s 12us/step - loss: 365451648.0000 - acc: 0.0000e+00 - val_loss: 452839200.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00049: val_loss improved from 457177120.00000 to 452839200.00000, saving model to ./model/49-452839200.0000.hdf5\n",
      "Epoch 50/100\n",
      "420/420 [==============================] - 0s 17us/step - loss: 362224768.0000 - acc: 0.0000e+00 - val_loss: 449034816.0000 - val_acc: 0.0036\n",
      "\n",
      "Epoch 00050: val_loss improved from 452839200.00000 to 449034816.00000, saving model to ./model/50-449034816.0000.hdf5\n",
      "Epoch 51/100\n",
      "420/420 [==============================] - 0s 19us/step - loss: 359547392.0000 - acc: 0.0000e+00 - val_loss: 445675008.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00051: val_loss improved from 449034816.00000 to 445675008.00000, saving model to ./model/51-445675008.0000.hdf5\n",
      "Epoch 52/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 357323584.0000 - acc: 0.0000e+00 - val_loss: 442671712.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00052: val_loss improved from 445675008.00000 to 442671712.00000, saving model to ./model/52-442671712.0000.hdf5\n",
      "Epoch 53/100\n",
      "420/420 [==============================] - 0s 12us/step - loss: 355417152.0000 - acc: 0.0000e+00 - val_loss: 439925216.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00053: val_loss improved from 442671712.00000 to 439925216.00000, saving model to ./model/53-439925216.0000.hdf5\n",
      "Epoch 54/100\n",
      "420/420 [==============================] - 0s 12us/step - loss: 353728192.0000 - acc: 0.0000e+00 - val_loss: 437344128.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00054: val_loss improved from 439925216.00000 to 437344128.00000, saving model to ./model/54-437344128.0000.hdf5\n",
      "Epoch 55/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 352142720.0000 - acc: 0.0000e+00 - val_loss: 434814688.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00055: val_loss improved from 437344128.00000 to 434814688.00000, saving model to ./model/55-434814688.0000.hdf5\n",
      "Epoch 56/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 350564640.0000 - acc: 0.0000e+00 - val_loss: 432282816.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00056: val_loss improved from 434814688.00000 to 432282816.00000, saving model to ./model/56-432282816.0000.hdf5\n",
      "Epoch 57/100\n",
      "420/420 [==============================] - 0s 12us/step - loss: 348905344.0000 - acc: 0.0000e+00 - val_loss: 429660064.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00057: val_loss improved from 432282816.00000 to 429660064.00000, saving model to ./model/57-429660064.0000.hdf5\n",
      "Epoch 58/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 347091616.0000 - acc: 0.0000e+00 - val_loss: 426896544.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00058: val_loss improved from 429660064.00000 to 426896544.00000, saving model to ./model/58-426896544.0000.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 345060000.0000 - acc: 0.0000e+00 - val_loss: 423967488.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00059: val_loss improved from 426896544.00000 to 423967488.00000, saving model to ./model/59-423967488.0000.hdf5\n",
      "Epoch 60/100\n",
      "420/420 [==============================] - 0s 12us/step - loss: 342776224.0000 - acc: 0.0000e+00 - val_loss: 420863712.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00060: val_loss improved from 423967488.00000 to 420863712.00000, saving model to ./model/60-420863712.0000.hdf5\n",
      "Epoch 61/100\n",
      "420/420 [==============================] - 0s 12us/step - loss: 340220544.0000 - acc: 0.0000e+00 - val_loss: 417568992.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00061: val_loss improved from 420863712.00000 to 417568992.00000, saving model to ./model/61-417568992.0000.hdf5\n",
      "Epoch 62/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 337411712.0000 - acc: 0.0000e+00 - val_loss: 414118368.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00062: val_loss improved from 417568992.00000 to 414118368.00000, saving model to ./model/62-414118368.0000.hdf5\n",
      "Epoch 63/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 334352192.0000 - acc: 0.0000e+00 - val_loss: 410530176.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00063: val_loss improved from 414118368.00000 to 410530176.00000, saving model to ./model/63-410530176.0000.hdf5\n",
      "Epoch 64/100\n",
      "420/420 [==============================] - 0s 12us/step - loss: 331092096.0000 - acc: 0.0000e+00 - val_loss: 406838656.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00064: val_loss improved from 410530176.00000 to 406838656.00000, saving model to ./model/64-406838656.0000.hdf5\n",
      "Epoch 65/100\n",
      "420/420 [==============================] - 0s 12us/step - loss: 327666592.0000 - acc: 0.0000e+00 - val_loss: 403087872.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00065: val_loss improved from 406838656.00000 to 403087872.00000, saving model to ./model/65-403087872.0000.hdf5\n",
      "Epoch 66/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 324119552.0000 - acc: 0.0000e+00 - val_loss: 399296352.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00066: val_loss improved from 403087872.00000 to 399296352.00000, saving model to ./model/66-399296352.0000.hdf5\n",
      "Epoch 67/100\n",
      "420/420 [==============================] - 0s 19us/step - loss: 320514016.0000 - acc: 0.0000e+00 - val_loss: 395505600.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00067: val_loss improved from 399296352.00000 to 395505600.00000, saving model to ./model/67-395505600.0000.hdf5\n",
      "Epoch 68/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 316897056.0000 - acc: 0.0000e+00 - val_loss: 391759360.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00068: val_loss improved from 395505600.00000 to 391759360.00000, saving model to ./model/68-391759360.0000.hdf5\n",
      "Epoch 69/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 313306816.0000 - acc: 0.0000e+00 - val_loss: 388094912.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00069: val_loss improved from 391759360.00000 to 388094912.00000, saving model to ./model/69-388094912.0000.hdf5\n",
      "Epoch 70/100\n",
      "420/420 [==============================] - 0s 19us/step - loss: 309785152.0000 - acc: 0.0000e+00 - val_loss: 384494208.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00070: val_loss improved from 388094912.00000 to 384494208.00000, saving model to ./model/70-384494208.0000.hdf5\n",
      "Epoch 71/100\n",
      "420/420 [==============================] - 0s 17us/step - loss: 306335872.0000 - acc: 0.0000e+00 - val_loss: 380977280.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00071: val_loss improved from 384494208.00000 to 380977280.00000, saving model to ./model/71-380977280.0000.hdf5\n",
      "Epoch 72/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 302968768.0000 - acc: 0.0000e+00 - val_loss: 377521984.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00072: val_loss improved from 380977280.00000 to 377521984.00000, saving model to ./model/72-377521984.0000.hdf5\n",
      "Epoch 73/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 299691008.0000 - acc: 0.0000e+00 - val_loss: 374144000.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00073: val_loss improved from 377521984.00000 to 374144000.00000, saving model to ./model/73-374144000.0000.hdf5\n",
      "Epoch 74/100\n",
      "420/420 [==============================] - 0s 12us/step - loss: 296516960.0000 - acc: 0.0000e+00 - val_loss: 370835680.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00074: val_loss improved from 374144000.00000 to 370835680.00000, saving model to ./model/74-370835680.0000.hdf5\n",
      "Epoch 75/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 293433280.0000 - acc: 0.0000e+00 - val_loss: 367570240.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00075: val_loss improved from 370835680.00000 to 367570240.00000, saving model to ./model/75-367570240.0000.hdf5\n",
      "Epoch 76/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 290423712.0000 - acc: 0.0000e+00 - val_loss: 364355360.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00076: val_loss improved from 367570240.00000 to 364355360.00000, saving model to ./model/76-364355360.0000.hdf5\n",
      "Epoch 77/100\n",
      "420/420 [==============================] - 0s 17us/step - loss: 287502496.0000 - acc: 0.0000e+00 - val_loss: 361196224.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00077: val_loss improved from 364355360.00000 to 361196224.00000, saving model to ./model/77-361196224.0000.hdf5\n",
      "Epoch 78/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 284634080.0000 - acc: 0.0000e+00 - val_loss: 358080704.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00078: val_loss improved from 361196224.00000 to 358080704.00000, saving model to ./model/78-358080704.0000.hdf5\n",
      "Epoch 79/100\n",
      "420/420 [==============================] - 0s 12us/step - loss: 281844576.0000 - acc: 0.0000e+00 - val_loss: 354994752.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00079: val_loss improved from 358080704.00000 to 354994752.00000, saving model to ./model/79-354994752.0000.hdf5\n",
      "Epoch 80/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 279116416.0000 - acc: 0.0000e+00 - val_loss: 351946720.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00080: val_loss improved from 354994752.00000 to 351946720.00000, saving model to ./model/80-351946720.0000.hdf5\n",
      "Epoch 81/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 276449120.0000 - acc: 0.0000e+00 - val_loss: 348945792.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00081: val_loss improved from 351946720.00000 to 348945792.00000, saving model to ./model/81-348945792.0000.hdf5\n",
      "Epoch 82/100\n",
      "420/420 [==============================] - 0s 19us/step - loss: 273836320.0000 - acc: 0.0000e+00 - val_loss: 346001440.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00082: val_loss improved from 348945792.00000 to 346001440.00000, saving model to ./model/82-346001440.0000.hdf5\n",
      "Epoch 83/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 271287104.0000 - acc: 0.0000e+00 - val_loss: 343109216.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00083: val_loss improved from 346001440.00000 to 343109216.00000, saving model to ./model/83-343109216.0000.hdf5\n",
      "Epoch 84/100\n",
      "420/420 [==============================] - 0s 19us/step - loss: 268798464.0000 - acc: 0.0000e+00 - val_loss: 340260640.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00084: val_loss improved from 343109216.00000 to 340260640.00000, saving model to ./model/84-340260640.0000.hdf5\n",
      "Epoch 85/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 266381056.0000 - acc: 0.0000e+00 - val_loss: 337464576.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00085: val_loss improved from 340260640.00000 to 337464576.00000, saving model to ./model/85-337464576.0000.hdf5\n",
      "Epoch 86/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 264024160.0000 - acc: 0.0000e+00 - val_loss: 334713632.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00086: val_loss improved from 337464576.00000 to 334713632.00000, saving model to ./model/86-334713632.0000.hdf5\n",
      "Epoch 87/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 261719920.0000 - acc: 0.0000e+00 - val_loss: 332005312.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00087: val_loss improved from 334713632.00000 to 332005312.00000, saving model to ./model/87-332005312.0000.hdf5\n",
      "Epoch 88/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 259464208.0000 - acc: 0.0000e+00 - val_loss: 329338272.0000 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00088: val_loss improved from 332005312.00000 to 329338272.00000, saving model to ./model/88-329338272.0000.hdf5\n",
      "Epoch 89/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 257255872.0000 - acc: 0.0000e+00 - val_loss: 326705088.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00089: val_loss improved from 329338272.00000 to 326705088.00000, saving model to ./model/89-326705088.0000.hdf5\n",
      "Epoch 90/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 255085360.0000 - acc: 0.0000e+00 - val_loss: 324100544.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00090: val_loss improved from 326705088.00000 to 324100544.00000, saving model to ./model/90-324100544.0000.hdf5\n",
      "Epoch 91/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 252954256.0000 - acc: 0.0000e+00 - val_loss: 321534848.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00091: val_loss improved from 324100544.00000 to 321534848.00000, saving model to ./model/91-321534848.0000.hdf5\n",
      "Epoch 92/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 250856576.0000 - acc: 0.0000e+00 - val_loss: 319002112.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00092: val_loss improved from 321534848.00000 to 319002112.00000, saving model to ./model/92-319002112.0000.hdf5\n",
      "Epoch 93/100\n",
      "420/420 [==============================] - 0s 21us/step - loss: 248787632.0000 - acc: 0.0000e+00 - val_loss: 316499008.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00093: val_loss improved from 319002112.00000 to 316499008.00000, saving model to ./model/93-316499008.0000.hdf5\n",
      "Epoch 94/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 246742672.0000 - acc: 0.0000e+00 - val_loss: 314021280.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00094: val_loss improved from 316499008.00000 to 314021280.00000, saving model to ./model/94-314021280.0000.hdf5\n",
      "Epoch 95/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 244721600.0000 - acc: 0.0000e+00 - val_loss: 311568320.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00095: val_loss improved from 314021280.00000 to 311568320.00000, saving model to ./model/95-311568320.0000.hdf5\n",
      "Epoch 96/100\n",
      "420/420 [==============================] - 0s 24us/step - loss: 242720560.0000 - acc: 0.0000e+00 - val_loss: 309141600.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00096: val_loss improved from 311568320.00000 to 309141600.00000, saving model to ./model/96-309141600.0000.hdf5\n",
      "Epoch 97/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 240733664.0000 - acc: 0.0000e+00 - val_loss: 306740960.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00097: val_loss improved from 309141600.00000 to 306740960.00000, saving model to ./model/97-306740960.0000.hdf5\n",
      "Epoch 98/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 238764208.0000 - acc: 0.0000e+00 - val_loss: 304364384.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00098: val_loss improved from 306740960.00000 to 304364384.00000, saving model to ./model/98-304364384.0000.hdf5\n",
      "Epoch 99/100\n",
      "420/420 [==============================] - 0s 14us/step - loss: 236811504.0000 - acc: 0.0000e+00 - val_loss: 302011904.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00099: val_loss improved from 304364384.00000 to 302011904.00000, saving model to ./model/99-302011904.0000.hdf5\n",
      "Epoch 100/100\n",
      "420/420 [==============================] - 0s 17us/step - loss: 234878320.0000 - acc: 0.0000e+00 - val_loss: 299688416.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00100: val_loss improved from 302011904.00000 to 299688416.00000, saving model to ./model/100-299688416.0000.hdf5\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, validation_split=0.4, epochs=100, batch_size=1000, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc = history.history['acc']\n",
    "\n",
    "# x값을 지정하고 정확도를 파랑색으로, 오차를 빨강색으로 표시\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.0811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19360.431761331343"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelPred = model.predict(x_test)\n",
    "end = time.time() - start\n",
    "print(round(end,4))\n",
    "RMSE = sqrt(mean_squared_error(y_test, modelPred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 13500.000, 예상가격: 20550.152\n",
      "실제가격: 33000.000, 예상가격: 33819.777\n",
      "실제가격: 17043.000, 예상가격: 29606.977\n",
      "실제가격: 20500.000, 예상가격: 18412.801\n",
      "실제가격: 55250.000, 예상가격: 29632.857\n",
      "실제가격: 51900.000, 예상가격: 28612.406\n",
      "실제가격: 8120.000, 예상가격: 21279.521\n",
      "실제가격: 2500.000, 예상가격: 16181.153\n",
      "실제가격: 7300.000, 예상가격: 23539.945\n",
      "실제가격: 7500.000, 예상가격: 23282.957\n"
     ]
    }
   ],
   "source": [
    "Y_prediction = modelPred.flatten()\n",
    "for i in range(10):\n",
    "    label = y_test.values[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 420 samples, validate on 280 samples\n",
      "Epoch 1/10\n",
      "420/420 [==============================] - 0s 910us/step - loss: 955407744.0000 - acc: 0.0000e+00 - val_loss: 1034666432.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1034666432.00000, saving model to ./model/01-1034666432.0000.hdf5\n",
      "Epoch 2/10\n",
      "420/420 [==============================] - 0s 24us/step - loss: 952777920.0000 - acc: 0.0000e+00 - val_loss: 1032079744.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 1034666432.00000 to 1032079744.00000, saving model to ./model/02-1032079744.0000.hdf5\n",
      "Epoch 3/10\n",
      "420/420 [==============================] - 0s 21us/step - loss: 949995648.0000 - acc: 0.0000e+00 - val_loss: 1029448640.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 1032079744.00000 to 1029448640.00000, saving model to ./model/03-1029448640.0000.hdf5\n",
      "Epoch 4/10\n",
      "420/420 [==============================] - 0s 21us/step - loss: 947187520.0000 - acc: 0.0000e+00 - val_loss: 1026840064.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 1029448640.00000 to 1026840064.00000, saving model to ./model/04-1026840064.0000.hdf5\n",
      "Epoch 5/10\n",
      "420/420 [==============================] - 0s 26us/step - loss: 944433600.0000 - acc: 0.0000e+00 - val_loss: 1024286272.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss improved from 1026840064.00000 to 1024286272.00000, saving model to ./model/05-1024286272.0000.hdf5\n",
      "Epoch 6/10\n",
      "420/420 [==============================] - 0s 24us/step - loss: 941741568.0000 - acc: 0.0000e+00 - val_loss: 1021761024.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss improved from 1024286272.00000 to 1021761024.00000, saving model to ./model/06-1021761024.0000.hdf5\n",
      "Epoch 7/10\n",
      "420/420 [==============================] - 0s 21us/step - loss: 939076096.0000 - acc: 0.0000e+00 - val_loss: 1019252416.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss improved from 1021761024.00000 to 1019252416.00000, saving model to ./model/07-1019252416.0000.hdf5\n",
      "Epoch 8/10\n",
      "420/420 [==============================] - 0s 19us/step - loss: 936452736.0000 - acc: 0.0000e+00 - val_loss: 1016766784.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss improved from 1019252416.00000 to 1016766784.00000, saving model to ./model/08-1016766784.0000.hdf5\n",
      "Epoch 9/10\n",
      "420/420 [==============================] - 0s 21us/step - loss: 933872960.0000 - acc: 0.0000e+00 - val_loss: 1014309440.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss improved from 1016766784.00000 to 1014309440.00000, saving model to ./model/09-1014309440.0000.hdf5\n",
      "Epoch 10/10\n",
      "420/420 [==============================] - 0s 21us/step - loss: 931318912.0000 - acc: 0.0000e+00 - val_loss: 1011908352.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss improved from 1014309440.00000 to 1011908352.00000, saving model to ./model/10-1011908352.0000.hdf5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33753.11323877499"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(140, input_dim=14, activation='relu'))\n",
    "model.add(Dense(35, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 저장 폴더 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "# loss는 train loss고 val_loss는 validation loss임 / acc도 마찬가지\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, validation_split=0.4, epochs=10, batch_size=1000, callbacks=[checkpointer])\n",
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc = history.history['acc']\n",
    "\n",
    "# x값을 지정하고 정확도를 파랑색으로, 오차를 빨강색으로 표시\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "modelPred = model.predict(x_test)\n",
    "end = time.time() - start\n",
    "print(round(end,4))\n",
    "RMSE = sqrt(mean_squared_error(y_test, modelPred))\n",
    "RMSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
