{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>district</th>\n",
       "      <th>dong</th>\n",
       "      <th>apartment</th>\n",
       "      <th>m2</th>\n",
       "      <th>price</th>\n",
       "      <th>floor</th>\n",
       "      <th>pre_m2</th>\n",
       "      <th>moving_date</th>\n",
       "      <th>num_people</th>\n",
       "      <th>people_by_m2</th>\n",
       "      <th>price_by_m2</th>\n",
       "      <th>price_by_pre_m2</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1156</td>\n",
       "      <td>1504</td>\n",
       "      <td>196.21</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>211.23</td>\n",
       "      <td>1976.06</td>\n",
       "      <td>480.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7582.0</td>\n",
       "      <td>7043.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1706</td>\n",
       "      <td>4942</td>\n",
       "      <td>202.58</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>252.31</td>\n",
       "      <td>2010.07</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7343.0</td>\n",
       "      <td>5896.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1156</td>\n",
       "      <td>9746</td>\n",
       "      <td>139.83</td>\n",
       "      <td>320000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>165.29</td>\n",
       "      <td>1982.04</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>7565.0</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>393</td>\n",
       "      <td>15322</td>\n",
       "      <td>191.04</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>219.22</td>\n",
       "      <td>1983.12</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5451.0</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1156</td>\n",
       "      <td>1509</td>\n",
       "      <td>144.20</td>\n",
       "      <td>304000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>158.68</td>\n",
       "      <td>1979.05</td>\n",
       "      <td>560.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>6969.0</td>\n",
       "      <td>6333.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city  district  dong  apartment      m2     price  floor  pre_m2  \\\n",
       "0     8         1  1156       1504  196.21  450000.0   13.0  211.23   \n",
       "1     8         1  1706       4942  202.58  450000.0    5.0  252.31   \n",
       "2     8         1  1156       9746  139.83  320000.0    7.0  165.29   \n",
       "3     8         1   393      15322  191.04  315000.0    2.0  219.22   \n",
       "4     8         1  1156       1509  144.20  304000.0   10.0  158.68   \n",
       "\n",
       "   moving_date  num_people  people_by_m2  price_by_m2  price_by_pre_m2  year  \\\n",
       "0      1976.06       480.0         120.0       7582.0           7043.0  2018   \n",
       "1      2010.07        19.0           1.0       7343.0           5896.0  2018   \n",
       "2      1982.04      1924.0         168.0       7565.0           6400.0  2018   \n",
       "3      1983.12      1204.0          84.0       5451.0           4750.0  2018   \n",
       "4      1979.05       560.0         168.0       6969.0           6333.0  2018   \n",
       "\n",
       "   month  \n",
       "0     12  \n",
       "1     12  \n",
       "2     12  \n",
       "3     12  \n",
       "4     12  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./preprocessed_apartment.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6174900, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>district</th>\n",
       "      <th>dong</th>\n",
       "      <th>apartment</th>\n",
       "      <th>m2</th>\n",
       "      <th>price</th>\n",
       "      <th>floor</th>\n",
       "      <th>pre_m2</th>\n",
       "      <th>moving_date</th>\n",
       "      <th>num_people</th>\n",
       "      <th>people_by_m2</th>\n",
       "      <th>price_by_m2</th>\n",
       "      <th>price_by_pre_m2</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3719372</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>432</td>\n",
       "      <td>14223</td>\n",
       "      <td>83.01</td>\n",
       "      <td>11890.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>115.70</td>\n",
       "      <td>2001.11</td>\n",
       "      <td>133.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1204</td>\n",
       "      <td>4548</td>\n",
       "      <td>84.97</td>\n",
       "      <td>118000.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>113.47</td>\n",
       "      <td>2009.12</td>\n",
       "      <td>476.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>4591.0</td>\n",
       "      <td>3438.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171243</th>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>1268</td>\n",
       "      <td>13064</td>\n",
       "      <td>84.34</td>\n",
       "      <td>24900.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>102.48</td>\n",
       "      <td>2000.11</td>\n",
       "      <td>532.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13013</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1495</td>\n",
       "      <td>14828</td>\n",
       "      <td>84.83</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>104.87</td>\n",
       "      <td>1994.02</td>\n",
       "      <td>930.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>3312.0</td>\n",
       "      <td>2679.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5180436</th>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>836</td>\n",
       "      <td>6090</td>\n",
       "      <td>59.92</td>\n",
       "      <td>19400.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>79.34</td>\n",
       "      <td>1998.08</td>\n",
       "      <td>608.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city  district  dong  apartment     m2     price  floor  pre_m2  \\\n",
       "3719372     4        26   432      14223  83.01   11890.0   11.0  115.70   \n",
       "11606       8         1  1204       4548  84.97  118000.0   19.0  113.47   \n",
       "2171243     1       142  1268      13064  84.34   24900.0   15.0  102.48   \n",
       "13013       8         1  1495      14828  84.83   85000.0    6.0  104.87   \n",
       "5180436    10        46   836       6090  59.92   19400.0   25.0   79.34   \n",
       "\n",
       "         moving_date  num_people  people_by_m2  price_by_m2  price_by_pre_m2  \\\n",
       "3719372      2001.11       133.0         131.0        474.0            340.0   \n",
       "11606        2009.12       476.0         153.0       4591.0           3438.0   \n",
       "2171243      2000.11       532.0         532.0        976.0            803.0   \n",
       "13013        1994.02       930.0         464.0       3312.0           2679.0   \n",
       "5180436      1998.08       608.0         249.0       1070.0            808.0   \n",
       "\n",
       "         year  month  \n",
       "3719372  2015      6  \n",
       "11606    2016      9  \n",
       "2171243  2011     11  \n",
       "13013    2016      7  \n",
       "5180436  2018      4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(n=15000)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "del df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test,y_train, y_test = train_test_split(df, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm = lgb.LGBMRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.98717051, 0.95481825, 0.99150883])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, random_state=0).get_n_splits(x_train.values)\n",
    "cross_val_score(lightgbm, x_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "       min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "       n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "       random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightgbm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2537.97172591042"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelPred = lightgbm.predict(x_test)\n",
    "RMSE = sqrt(mean_squared_error(y_test, modelPred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 9900.000, 예상가격: 9838.695\n",
      "실제가격: 18900.000, 예상가격: 19367.009\n",
      "실제가격: 26000.000, 예상가격: 26622.357\n",
      "실제가격: 32500.000, 예상가격: 32591.413\n",
      "실제가격: 20000.000, 예상가격: 19797.847\n",
      "실제가격: 16700.000, 예상가격: 16560.229\n",
      "실제가격: 25900.000, 예상가격: 25777.033\n",
      "실제가격: 21000.000, 예상가격: 21269.600\n",
      "실제가격: 26000.000, 예상가격: 25227.120\n",
      "실제가격: 30800.000, 예상가격: 31024.811\n"
     ]
    }
   ],
   "source": [
    "Y_prediction = modelPred.flatten()\n",
    "for i in range(10):\n",
    "    label = y_test.values[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(140, input_dim=14, activation='relu'))\n",
    "model.add(Dense(35, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "# loss는 train loss고 val_loss는 validation loss임 / acc도 마찬가지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 6300 samples, validate on 4200 samples\n",
      "Epoch 1/100\n",
      "6300/6300 [==============================] - 2s 317us/step - loss: 1038214113.5238 - acc: 0.0000e+00 - val_loss: 902692358.0952 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 902692358.09524, saving model to ./model/01-902692358.0952.hdf5\n",
      "Epoch 2/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 980145593.9048 - acc: 0.0000e+00 - val_loss: 839868748.1905 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 902692358.09524 to 839868748.19048, saving model to ./model/02-839868748.1905.hdf5\n",
      "Epoch 3/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 903001177.3968 - acc: 1.5873e-04 - val_loss: 735200408.3810 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 839868748.19048 to 735200408.38095, saving model to ./model/03-735200408.3810.hdf5\n",
      "Epoch 4/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 786208415.4921 - acc: 0.0000e+00 - val_loss: 618536600.3810 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 735200408.38095 to 618536600.38095, saving model to ./model/04-618536600.3810.hdf5\n",
      "Epoch 5/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 669578730.6667 - acc: 1.5873e-04 - val_loss: 511969263.2381 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00005: val_loss improved from 618536600.38095 to 511969263.23810, saving model to ./model/05-511969263.2381.hdf5\n",
      "Epoch 6/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 568921588.8254 - acc: 0.0000e+00 - val_loss: 436973746.2857 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss improved from 511969263.23810 to 436973746.28571, saving model to ./model/06-436973746.2857.hdf5\n",
      "Epoch 7/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 505644969.1429 - acc: 0.0000e+00 - val_loss: 406225586.2857 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss improved from 436973746.28571 to 406225586.28571, saving model to ./model/07-406225586.2857.hdf5\n",
      "Epoch 8/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 479494283.1746 - acc: 0.0000e+00 - val_loss: 394494083.0476 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00008: val_loss improved from 406225586.28571 to 394494083.04762, saving model to ./model/08-394494083.0476.hdf5\n",
      "Epoch 9/100\n",
      "6300/6300 [==============================] - 0s 7us/step - loss: 459187802.4127 - acc: 0.0000e+00 - val_loss: 369097269.3333 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss improved from 394494083.04762 to 369097269.33333, saving model to ./model/09-369097269.3333.hdf5\n",
      "Epoch 10/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 429227200.0000 - acc: 0.0000e+00 - val_loss: 338733450.6667 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss improved from 369097269.33333 to 338733450.66667, saving model to ./model/10-338733450.6667.hdf5\n",
      "Epoch 11/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 397046282.6667 - acc: 0.0000e+00 - val_loss: 309813581.7143 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss improved from 338733450.66667 to 309813581.71429, saving model to ./model/11-309813581.7143.hdf5\n",
      "Epoch 12/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 366083154.5397 - acc: 1.5873e-04 - val_loss: 282542396.9524 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00012: val_loss improved from 309813581.71429 to 282542396.95238, saving model to ./model/12-282542396.9524.hdf5\n",
      "Epoch 13/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 335842076.4444 - acc: 1.5873e-04 - val_loss: 257995365.3333 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss improved from 282542396.95238 to 257995365.33333, saving model to ./model/13-257995365.3333.hdf5\n",
      "Epoch 14/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 308518767.2381 - acc: 0.0000e+00 - val_loss: 237209999.2381 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss improved from 257995365.33333 to 237209999.23810, saving model to ./model/14-237209999.2381.hdf5\n",
      "Epoch 15/100\n",
      "6300/6300 [==============================] - 0s 7us/step - loss: 284893775.2381 - acc: 0.0000e+00 - val_loss: 219101156.5714 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss improved from 237209999.23810 to 219101156.57143, saving model to ./model/15-219101156.5714.hdf5\n",
      "Epoch 16/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 264108564.0635 - acc: 0.0000e+00 - val_loss: 203518099.8095 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss improved from 219101156.57143 to 203518099.80952, saving model to ./model/16-203518099.8095.hdf5\n",
      "Epoch 17/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 245397726.9841 - acc: 0.0000e+00 - val_loss: 189670407.6190 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00017: val_loss improved from 203518099.80952 to 189670407.61905, saving model to ./model/17-189670407.6190.hdf5\n",
      "Epoch 18/100\n",
      "6300/6300 [==============================] - 0s 8us/step - loss: 228103834.1587 - acc: 0.0000e+00 - val_loss: 176524998.0952 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss improved from 189670407.61905 to 176524998.09524, saving model to ./model/18-176524998.0952.hdf5\n",
      "Epoch 19/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 211726315.6825 - acc: 0.0000e+00 - val_loss: 163862058.6667 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00019: val_loss improved from 176524998.09524 to 163862058.66667, saving model to ./model/19-163862058.6667.hdf5\n",
      "Epoch 20/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 195991225.1429 - acc: 0.0000e+00 - val_loss: 151082240.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00020: val_loss improved from 163862058.66667 to 151082240.00000, saving model to ./model/20-151082240.0000.hdf5\n",
      "Epoch 21/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 180659980.6984 - acc: 0.0000e+00 - val_loss: 139027121.9048 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss improved from 151082240.00000 to 139027121.90476, saving model to ./model/21-139027121.9048.hdf5\n",
      "Epoch 22/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 165577211.6825 - acc: 0.0000e+00 - val_loss: 128536773.3333 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss improved from 139027121.90476 to 128536773.33333, saving model to ./model/22-128536773.3333.hdf5\n",
      "Epoch 23/100\n",
      "6300/6300 [==============================] - 0s 7us/step - loss: 153272577.9048 - acc: 0.0000e+00 - val_loss: 119323500.9524 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00023: val_loss improved from 128536773.33333 to 119323500.95238, saving model to ./model/23-119323500.9524.hdf5\n",
      "Epoch 24/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 140922585.9048 - acc: 0.0000e+00 - val_loss: 111903540.1905 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss improved from 119323500.95238 to 111903540.19048, saving model to ./model/24-111903540.1905.hdf5\n",
      "Epoch 25/100\n",
      "6300/6300 [==============================] - 0s 8us/step - loss: 131973254.6032 - acc: 0.0000e+00 - val_loss: 106148755.4286 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss improved from 111903540.19048 to 106148755.42857, saving model to ./model/25-106148755.4286.hdf5\n",
      "Epoch 26/100\n",
      "6300/6300 [==============================] - 0s 8us/step - loss: 124601497.3333 - acc: 0.0000e+00 - val_loss: 102358974.4762 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss improved from 106148755.42857 to 102358974.47619, saving model to ./model/26-102358974.4762.hdf5\n",
      "Epoch 27/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 119155816.2540 - acc: 1.5873e-04 - val_loss: 100065986.6667 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss improved from 102358974.47619 to 100065986.66667, saving model to ./model/27-100065986.6667.hdf5\n",
      "Epoch 28/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 115655105.0159 - acc: 0.0000e+00 - val_loss: 98654412.1905 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_loss improved from 100065986.66667 to 98654412.19048, saving model to ./model/28-98654412.1905.hdf5\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300/6300 [==============================] - 0s 5us/step - loss: 113294377.9048 - acc: 0.0000e+00 - val_loss: 98127232.0000 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00029: val_loss improved from 98654412.19048 to 98127232.00000, saving model to ./model/29-98127232.0000.hdf5\n",
      "Epoch 30/100\n",
      "6300/6300 [==============================] - 0s 7us/step - loss: 112424122.9206 - acc: 1.5873e-04 - val_loss: 98138068.1905 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 98127232.00000\n",
      "Epoch 31/100\n",
      "6300/6300 [==============================] - 0s 8us/step - loss: 111419866.0317 - acc: 1.5873e-04 - val_loss: 97611442.6667 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_loss improved from 98127232.00000 to 97611442.66667, saving model to ./model/31-97611442.6667.hdf5\n",
      "Epoch 32/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 110505772.8254 - acc: 0.0000e+00 - val_loss: 97091023.2381 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_loss improved from 97611442.66667 to 97091023.23810, saving model to ./model/32-97091023.2381.hdf5\n",
      "Epoch 33/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 109542893.5873 - acc: 0.0000e+00 - val_loss: 96185841.5238 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00033: val_loss improved from 97091023.23810 to 96185841.52381, saving model to ./model/33-96185841.5238.hdf5\n",
      "Epoch 34/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 108741402.9206 - acc: 0.0000e+00 - val_loss: 95685380.1905 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00034: val_loss improved from 96185841.52381 to 95685380.19048, saving model to ./model/34-95685380.1905.hdf5\n",
      "Epoch 35/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 108270374.8571 - acc: 3.1746e-04 - val_loss: 94722737.1429 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00035: val_loss improved from 95685380.19048 to 94722737.14286, saving model to ./model/35-94722737.1429.hdf5\n",
      "Epoch 36/100\n",
      "6300/6300 [==============================] - 0s 7us/step - loss: 107581466.9206 - acc: 0.0000e+00 - val_loss: 94156753.1429 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_loss improved from 94722737.14286 to 94156753.14286, saving model to ./model/36-94156753.1429.hdf5\n",
      "Epoch 37/100\n",
      "6300/6300 [==============================] - 0s 7us/step - loss: 106646253.4603 - acc: 0.0000e+00 - val_loss: 93477750.4762 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_loss improved from 94156753.14286 to 93477750.47619, saving model to ./model/37-93477750.4762.hdf5\n",
      "Epoch 38/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 105669210.9206 - acc: 1.5873e-04 - val_loss: 92674254.4762 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00038: val_loss improved from 93477750.47619 to 92674254.47619, saving model to ./model/38-92674254.4762.hdf5\n",
      "Epoch 39/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 104982067.3016 - acc: 1.5873e-04 - val_loss: 91883206.4762 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00039: val_loss improved from 92674254.47619 to 91883206.47619, saving model to ./model/39-91883206.4762.hdf5\n",
      "Epoch 40/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 104335467.8095 - acc: 1.5873e-04 - val_loss: 91250452.5714 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00040: val_loss improved from 91883206.47619 to 91250452.57143, saving model to ./model/40-91250452.5714.hdf5\n",
      "Epoch 41/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 103711999.7460 - acc: 0.0000e+00 - val_loss: 90732631.6190 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00041: val_loss improved from 91250452.57143 to 90732631.61905, saving model to ./model/41-90732631.6190.hdf5\n",
      "Epoch 42/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 102931756.0635 - acc: 0.0000e+00 - val_loss: 90100739.4286 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00042: val_loss improved from 90732631.61905 to 90100739.42857, saving model to ./model/42-90100739.4286.hdf5\n",
      "Epoch 43/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 102225255.2381 - acc: 0.0000e+00 - val_loss: 89526931.4286 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00043: val_loss improved from 90100739.42857 to 89526931.42857, saving model to ./model/43-89526931.4286.hdf5\n",
      "Epoch 44/100\n",
      "6300/6300 [==============================] - 0s 7us/step - loss: 101515715.5556 - acc: 4.7619e-04 - val_loss: 88845247.6190 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00044: val_loss improved from 89526931.42857 to 88845247.61905, saving model to ./model/44-88845247.6190.hdf5\n",
      "Epoch 45/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 101064598.3492 - acc: 1.5873e-04 - val_loss: 89341968.7619 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 88845247.61905\n",
      "Epoch 46/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 100531164.4444 - acc: 0.0000e+00 - val_loss: 88852435.8095 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 88845247.61905\n",
      "Epoch 47/100\n",
      "6300/6300 [==============================] - 0s 5us/step - loss: 99596327.6190 - acc: 0.0000e+00 - val_loss: 87330558.8571 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00047: val_loss improved from 88845247.61905 to 87330558.85714, saving model to ./model/47-87330558.8571.hdf5\n",
      "Epoch 48/100\n",
      "6300/6300 [==============================] - 0s 7us/step - loss: 98540713.1429 - acc: 1.5873e-04 - val_loss: 86239868.1905 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00048: val_loss improved from 87330558.85714 to 86239868.19048, saving model to ./model/48-86239868.1905.hdf5\n",
      "Epoch 49/100\n",
      "6300/6300 [==============================] - 0s 8us/step - loss: 97733527.3651 - acc: 1.5873e-04 - val_loss: 85705757.7143 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00049: val_loss improved from 86239868.19048 to 85705757.71429, saving model to ./model/49-85705757.7143.hdf5\n",
      "Epoch 50/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 96963253.8413 - acc: 0.0000e+00 - val_loss: 85121377.5238 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00050: val_loss improved from 85705757.71429 to 85121377.52381, saving model to ./model/50-85121377.5238.hdf5\n",
      "Epoch 51/100\n",
      "6300/6300 [==============================] - 0s 7us/step - loss: 96178947.3016 - acc: 0.0000e+00 - val_loss: 84848589.7143 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00051: val_loss improved from 85121377.52381 to 84848589.71429, saving model to ./model/51-84848589.7143.hdf5\n",
      "Epoch 52/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 95535994.6667 - acc: 0.0000e+00 - val_loss: 84062451.0476 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00052: val_loss improved from 84848589.71429 to 84062451.04762, saving model to ./model/52-84062451.0476.hdf5\n",
      "Epoch 53/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 95368630.2222 - acc: 1.5873e-04 - val_loss: 83060695.2381 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00053: val_loss improved from 84062451.04762 to 83060695.23810, saving model to ./model/53-83060695.2381.hdf5\n",
      "Epoch 54/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 94254080.7619 - acc: 1.5873e-04 - val_loss: 82690551.2381 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00054: val_loss improved from 83060695.23810 to 82690551.23810, saving model to ./model/54-82690551.2381.hdf5\n",
      "Epoch 55/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 93267783.8730 - acc: 0.0000e+00 - val_loss: 82165445.7143 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00055: val_loss improved from 82690551.23810 to 82165445.71429, saving model to ./model/55-82165445.7143.hdf5\n",
      "Epoch 56/100\n",
      "6300/6300 [==============================] - 0s 8us/step - loss: 92363022.2222 - acc: 0.0000e+00 - val_loss: 81254727.8095 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00056: val_loss improved from 82165445.71429 to 81254727.80952, saving model to ./model/56-81254727.8095.hdf5\n",
      "Epoch 57/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 91619232.1905 - acc: 3.1746e-04 - val_loss: 80549789.3333 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00057: val_loss improved from 81254727.80952 to 80549789.33333, saving model to ./model/57-80549789.3333.hdf5\n",
      "Epoch 58/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 90771422.4762 - acc: 1.5873e-04 - val_loss: 79811141.5238 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00058: val_loss improved from 80549789.33333 to 79811141.52381, saving model to ./model/58-79811141.5238.hdf5\n",
      "Epoch 59/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 89989412.1905 - acc: 0.0000e+00 - val_loss: 79286245.9048 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00059: val_loss improved from 79811141.52381 to 79286245.90476, saving model to ./model/59-79286245.9048.hdf5\n",
      "Epoch 60/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 89239899.1746 - acc: 0.0000e+00 - val_loss: 78764257.9048 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00060: val_loss improved from 79286245.90476 to 78764257.90476, saving model to ./model/60-78764257.9048.hdf5\n",
      "Epoch 61/100\n",
      "6300/6300 [==============================] - 0s 7us/step - loss: 88434062.4762 - acc: 0.0000e+00 - val_loss: 77961355.6190 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00061: val_loss improved from 78764257.90476 to 77961355.61905, saving model to ./model/61-77961355.6190.hdf5\n",
      "Epoch 62/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 87632068.3175 - acc: 0.0000e+00 - val_loss: 77438338.8571 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00062: val_loss improved from 77961355.61905 to 77438338.85714, saving model to ./model/62-77438338.8571.hdf5\n",
      "Epoch 63/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 86928230.8571 - acc: 3.1746e-04 - val_loss: 76351690.8571 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00063: val_loss improved from 77438338.85714 to 76351690.85714, saving model to ./model/63-76351690.8571.hdf5\n",
      "Epoch 64/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 85942094.9841 - acc: 0.0000e+00 - val_loss: 75356360.9524 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00064: val_loss improved from 76351690.85714 to 75356360.95238, saving model to ./model/64-75356360.9524.hdf5\n",
      "Epoch 65/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 85131691.6825 - acc: 1.5873e-04 - val_loss: 74446052.7619 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00065: val_loss improved from 75356360.95238 to 74446052.76190, saving model to ./model/65-74446052.7619.hdf5\n",
      "Epoch 66/100\n",
      "6300/6300 [==============================] - 0s 8us/step - loss: 84339557.5873 - acc: 0.0000e+00 - val_loss: 74397984.9524 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00066: val_loss improved from 74446052.76190 to 74397984.95238, saving model to ./model/66-74397984.9524.hdf5\n",
      "Epoch 67/100\n",
      "6300/6300 [==============================] - 0s 11us/step - loss: 83586496.6349 - acc: 1.5873e-04 - val_loss: 73474728.7619 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00067: val_loss improved from 74397984.95238 to 73474728.76190, saving model to ./model/67-73474728.7619.hdf5\n",
      "Epoch 68/100\n",
      "6300/6300 [==============================] - 0s 8us/step - loss: 82498011.5556 - acc: 1.5873e-04 - val_loss: 72489505.1429 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00068: val_loss improved from 73474728.76190 to 72489505.14286, saving model to ./model/68-72489505.1429.hdf5\n",
      "Epoch 69/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 81600318.9841 - acc: 1.5873e-04 - val_loss: 71336488.3810 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00069: val_loss improved from 72489505.14286 to 71336488.38095, saving model to ./model/69-71336488.3810.hdf5\n",
      "Epoch 70/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 80847108.3175 - acc: 1.5873e-04 - val_loss: 70544780.5714 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00070: val_loss improved from 71336488.38095 to 70544780.57143, saving model to ./model/70-70544780.5714.hdf5\n",
      "Epoch 71/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 80013400.8889 - acc: 0.0000e+00 - val_loss: 70190349.1429 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00071: val_loss improved from 70544780.57143 to 70190349.14286, saving model to ./model/71-70190349.1429.hdf5\n",
      "Epoch 72/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 79019292.9524 - acc: 0.0000e+00 - val_loss: 70160063.4286 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00072: val_loss improved from 70190349.14286 to 70160063.42857, saving model to ./model/72-70160063.4286.hdf5\n",
      "Epoch 73/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 77965037.3333 - acc: 0.0000e+00 - val_loss: 69168624.9524 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00073: val_loss improved from 70160063.42857 to 69168624.95238, saving model to ./model/73-69168624.9524.hdf5\n",
      "Epoch 74/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 76883847.1746 - acc: 4.7619e-04 - val_loss: 68329465.3333 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00074: val_loss improved from 69168624.95238 to 68329465.33333, saving model to ./model/74-68329465.3333.hdf5\n",
      "Epoch 75/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 76226434.2222 - acc: 0.0000e+00 - val_loss: 67198053.9048 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00075: val_loss improved from 68329465.33333 to 67198053.90476, saving model to ./model/75-67198053.9048.hdf5\n",
      "Epoch 76/100\n",
      "6300/6300 [==============================] - 0s 5us/step - loss: 75279063.8095 - acc: 1.5873e-04 - val_loss: 65872707.2381 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00076: val_loss improved from 67198053.90476 to 65872707.23810, saving model to ./model/76-65872707.2381.hdf5\n",
      "Epoch 77/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 74199546.3175 - acc: 1.5873e-04 - val_loss: 65058722.0952 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00077: val_loss improved from 65872707.23810 to 65058722.09524, saving model to ./model/77-65058722.0952.hdf5\n",
      "Epoch 78/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 73129095.6190 - acc: 1.5873e-04 - val_loss: 64291045.5238 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00078: val_loss improved from 65058722.09524 to 64291045.52381, saving model to ./model/78-64291045.5238.hdf5\n",
      "Epoch 79/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 72203770.7937 - acc: 0.0000e+00 - val_loss: 62869577.9048 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00079: val_loss improved from 64291045.52381 to 62869577.90476, saving model to ./model/79-62869577.9048.hdf5\n",
      "Epoch 80/100\n",
      "6300/6300 [==============================] - 0s 7us/step - loss: 71101564.7619 - acc: 0.0000e+00 - val_loss: 62081504.3810 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00080: val_loss improved from 62869577.90476 to 62081504.38095, saving model to ./model/80-62081504.3810.hdf5\n",
      "Epoch 81/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 70073567.6190 - acc: 0.0000e+00 - val_loss: 61625012.5714 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00081: val_loss improved from 62081504.38095 to 61625012.57143, saving model to ./model/81-61625012.5714.hdf5\n",
      "Epoch 82/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 69108897.9683 - acc: 3.1746e-04 - val_loss: 60975903.0476 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00082: val_loss improved from 61625012.57143 to 60975903.04762, saving model to ./model/82-60975903.0476.hdf5\n",
      "Epoch 83/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 68387649.3968 - acc: 3.1746e-04 - val_loss: 60677940.0000 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00083: val_loss improved from 60975903.04762 to 60677940.00000, saving model to ./model/83-60677940.0000.hdf5\n",
      "Epoch 84/100\n",
      "6300/6300 [==============================] - 0s 8us/step - loss: 67446475.8095 - acc: 0.0000e+00 - val_loss: 59052062.6667 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00084: val_loss improved from 60677940.00000 to 59052062.66667, saving model to ./model/84-59052062.6667.hdf5\n",
      "Epoch 85/100\n",
      "6300/6300 [==============================] - 0s 8us/step - loss: 66176468.7302 - acc: 1.5873e-04 - val_loss: 57990329.5238 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00085: val_loss improved from 59052062.66667 to 57990329.52381, saving model to ./model/85-57990329.5238.hdf5\n",
      "Epoch 86/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 65147148.6984 - acc: 0.0000e+00 - val_loss: 56652557.3333 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00086: val_loss improved from 57990329.52381 to 56652557.33333, saving model to ./model/86-56652557.3333.hdf5\n",
      "Epoch 87/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 63957433.5873 - acc: 1.5873e-04 - val_loss: 55829564.5714 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00087: val_loss improved from 56652557.33333 to 55829564.57143, saving model to ./model/87-55829564.5714.hdf5\n",
      "Epoch 88/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 63333385.5873 - acc: 1.5873e-04 - val_loss: 54902182.4762 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00088: val_loss improved from 55829564.57143 to 54902182.47619, saving model to ./model/88-54902182.4762.hdf5\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300/6300 [==============================] - 0s 7us/step - loss: 61974945.6508 - acc: 3.1746e-04 - val_loss: 54780963.4286 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00089: val_loss improved from 54902182.47619 to 54780963.42857, saving model to ./model/89-54780963.4286.hdf5\n",
      "Epoch 90/100\n",
      "6300/6300 [==============================] - 0s 8us/step - loss: 61251987.8730 - acc: 3.1746e-04 - val_loss: 53193030.8571 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00090: val_loss improved from 54780963.42857 to 53193030.85714, saving model to ./model/90-53193030.8571.hdf5\n",
      "Epoch 91/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 59623671.3651 - acc: 0.0000e+00 - val_loss: 52138919.0476 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00091: val_loss improved from 53193030.85714 to 52138919.04762, saving model to ./model/91-52138919.0476.hdf5\n",
      "Epoch 92/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 58717936.4762 - acc: 0.0000e+00 - val_loss: 51548475.2381 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00092: val_loss improved from 52138919.04762 to 51548475.23810, saving model to ./model/92-51548475.2381.hdf5\n",
      "Epoch 93/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 57512550.3492 - acc: 0.0000e+00 - val_loss: 50296811.2381 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00093: val_loss improved from 51548475.23810 to 50296811.23810, saving model to ./model/93-50296811.2381.hdf5\n",
      "Epoch 94/100\n",
      "6300/6300 [==============================] - 0s 6us/step - loss: 56593419.0476 - acc: 0.0000e+00 - val_loss: 49841945.5238 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00094: val_loss improved from 50296811.23810 to 49841945.52381, saving model to ./model/94-49841945.5238.hdf5\n",
      "Epoch 95/100\n",
      "6300/6300 [==============================] - 0s 7us/step - loss: 55517646.0952 - acc: 0.0000e+00 - val_loss: 48384066.2857 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00095: val_loss improved from 49841945.52381 to 48384066.28571, saving model to ./model/95-48384066.2857.hdf5\n",
      "Epoch 96/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 54278345.3333 - acc: 1.5873e-04 - val_loss: 48066976.5714 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00096: val_loss improved from 48384066.28571 to 48066976.57143, saving model to ./model/96-48066976.5714.hdf5\n",
      "Epoch 97/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 53095075.1111 - acc: 1.5873e-04 - val_loss: 46955810.6667 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00097: val_loss improved from 48066976.57143 to 46955810.66667, saving model to ./model/97-46955810.6667.hdf5\n",
      "Epoch 98/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 52151005.4603 - acc: 1.5873e-04 - val_loss: 46235453.9048 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00098: val_loss improved from 46955810.66667 to 46235453.90476, saving model to ./model/98-46235453.9048.hdf5\n",
      "Epoch 99/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 51104957.9048 - acc: 6.3492e-04 - val_loss: 44862888.9524 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00099: val_loss improved from 46235453.90476 to 44862888.95238, saving model to ./model/99-44862888.9524.hdf5\n",
      "Epoch 100/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 49881208.0635 - acc: 3.1746e-04 - val_loss: 44871839.2381 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 44862888.95238\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_split=0.4, epochs=100, batch_size=1000, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc = history.history['acc']\n",
    "\n",
    "# x값을 지정하고 정확도를 파랑색으로, 오차를 빨강색으로 표시\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6863.400725641831"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelPred = model.predict(x_test)\n",
    "RMSE = sqrt(mean_squared_error(y_test, modelPred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 9900.000, 예상가격: 9644.774\n",
      "실제가격: 18900.000, 예상가격: 20790.074\n",
      "실제가격: 26000.000, 예상가격: 25423.281\n",
      "실제가격: 32500.000, 예상가격: 29868.730\n",
      "실제가격: 20000.000, 예상가격: 20867.244\n",
      "실제가격: 16700.000, 예상가격: 18800.734\n",
      "실제가격: 25900.000, 예상가격: 34361.586\n",
      "실제가격: 21000.000, 예상가격: 24863.725\n",
      "실제가격: 26000.000, 예상가격: 27089.570\n",
      "실제가격: 30800.000, 예상가격: 38010.172\n"
     ]
    }
   ],
   "source": [
    "Y_prediction = modelPred.flatten()\n",
    "for i in range(10):\n",
    "    label = y_test.values[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./model/99-44862888.9524.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6872.4473990680235"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelPred = model.predict(x_test)\n",
    "RMSE = sqrt(mean_squared_error(y_test, modelPred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 9900.000, 예상가격: 9002.848\n",
      "실제가격: 18900.000, 예상가격: 20318.992\n",
      "실제가격: 26000.000, 예상가격: 24502.170\n",
      "실제가격: 32500.000, 예상가격: 28690.734\n",
      "실제가격: 20000.000, 예상가격: 20094.771\n",
      "실제가격: 16700.000, 예상가격: 17975.434\n",
      "실제가격: 25900.000, 예상가격: 33210.988\n",
      "실제가격: 21000.000, 예상가격: 23728.490\n",
      "실제가격: 26000.000, 예상가격: 25838.988\n",
      "실제가격: 30800.000, 예상가격: 36891.695\n"
     ]
    }
   ],
   "source": [
    "Y_prediction = modelPred.flatten()\n",
    "for i in range(10):\n",
    "    label = y_test.values[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
