{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>district</th>\n",
       "      <th>dong</th>\n",
       "      <th>apartment</th>\n",
       "      <th>m2</th>\n",
       "      <th>price</th>\n",
       "      <th>floor</th>\n",
       "      <th>pre_m2</th>\n",
       "      <th>moving_date</th>\n",
       "      <th>num_people</th>\n",
       "      <th>people_by_m2</th>\n",
       "      <th>price_by_m2</th>\n",
       "      <th>price_by_pre_m2</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1156</td>\n",
       "      <td>1504</td>\n",
       "      <td>196.21</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>211.23</td>\n",
       "      <td>1976.06</td>\n",
       "      <td>480.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7582.0</td>\n",
       "      <td>7043.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1706</td>\n",
       "      <td>4942</td>\n",
       "      <td>202.58</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>252.31</td>\n",
       "      <td>2010.07</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7343.0</td>\n",
       "      <td>5896.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1156</td>\n",
       "      <td>9746</td>\n",
       "      <td>139.83</td>\n",
       "      <td>320000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>165.29</td>\n",
       "      <td>1982.04</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>7565.0</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>393</td>\n",
       "      <td>15322</td>\n",
       "      <td>191.04</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>219.22</td>\n",
       "      <td>1983.12</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5451.0</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1156</td>\n",
       "      <td>1509</td>\n",
       "      <td>144.20</td>\n",
       "      <td>304000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>158.68</td>\n",
       "      <td>1979.05</td>\n",
       "      <td>560.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>6969.0</td>\n",
       "      <td>6333.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city  district  dong  apartment      m2     price  floor  pre_m2  \\\n",
       "0     8         1  1156       1504  196.21  450000.0   13.0  211.23   \n",
       "1     8         1  1706       4942  202.58  450000.0    5.0  252.31   \n",
       "2     8         1  1156       9746  139.83  320000.0    7.0  165.29   \n",
       "3     8         1   393      15322  191.04  315000.0    2.0  219.22   \n",
       "4     8         1  1156       1509  144.20  304000.0   10.0  158.68   \n",
       "\n",
       "   moving_date  num_people  people_by_m2  price_by_m2  price_by_pre_m2  year  \\\n",
       "0      1976.06       480.0         120.0       7582.0           7043.0  2018   \n",
       "1      2010.07        19.0           1.0       7343.0           5896.0  2018   \n",
       "2      1982.04      1924.0         168.0       7565.0           6400.0  2018   \n",
       "3      1983.12      1204.0          84.0       5451.0           4750.0  2018   \n",
       "4      1979.05       560.0         168.0       6969.0           6333.0  2018   \n",
       "\n",
       "   month  \n",
       "0     12  \n",
       "1     12  \n",
       "2     12  \n",
       "3     12  \n",
       "4     12  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./preprocessed_apartment.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6174900, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>district</th>\n",
       "      <th>dong</th>\n",
       "      <th>apartment</th>\n",
       "      <th>m2</th>\n",
       "      <th>price</th>\n",
       "      <th>floor</th>\n",
       "      <th>pre_m2</th>\n",
       "      <th>moving_date</th>\n",
       "      <th>num_people</th>\n",
       "      <th>people_by_m2</th>\n",
       "      <th>price_by_m2</th>\n",
       "      <th>price_by_pre_m2</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4916702</th>\n",
       "      <td>7</td>\n",
       "      <td>215</td>\n",
       "      <td>1590</td>\n",
       "      <td>720</td>\n",
       "      <td>84.84</td>\n",
       "      <td>22600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>108.31</td>\n",
       "      <td>1997.10</td>\n",
       "      <td>938.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970132</th>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>926</td>\n",
       "      <td>16166</td>\n",
       "      <td>84.92</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.40</td>\n",
       "      <td>2004.08</td>\n",
       "      <td>720.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842782</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>1569</td>\n",
       "      <td>13066</td>\n",
       "      <td>84.76</td>\n",
       "      <td>21400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>89.26</td>\n",
       "      <td>1998.10</td>\n",
       "      <td>690.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954135</th>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>1935</td>\n",
       "      <td>14710</td>\n",
       "      <td>59.99</td>\n",
       "      <td>9230.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.73</td>\n",
       "      <td>1992.05</td>\n",
       "      <td>188.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547336</th>\n",
       "      <td>11</td>\n",
       "      <td>89</td>\n",
       "      <td>1226</td>\n",
       "      <td>11331</td>\n",
       "      <td>84.69</td>\n",
       "      <td>22600.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>109.09</td>\n",
       "      <td>1997.06</td>\n",
       "      <td>410.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city  district  dong  apartment     m2    price  floor  pre_m2  \\\n",
       "4916702     7       215  1590        720  84.84  22600.0    3.0  108.31   \n",
       "2970132     0       196   926      16166  84.92  24000.0    1.0  112.40   \n",
       "1842782     1       112  1569      13066  84.76  21400.0    2.0   89.26   \n",
       "3954135     5        55  1935      14710  59.99   9230.0    2.0   72.73   \n",
       "5547336    11        89  1226      11331  84.69  22600.0   10.0  109.09   \n",
       "\n",
       "         moving_date  num_people  people_by_m2  price_by_m2  price_by_pre_m2  \\\n",
       "4916702      1997.10       938.0         514.0        881.0            690.0   \n",
       "2970132      2004.08       720.0         240.0        934.0            706.0   \n",
       "1842782      1998.10       690.0          20.0        835.0            793.0   \n",
       "3954135      1992.05       188.0          92.0        509.0            420.0   \n",
       "5547336      1997.06       410.0         242.0        882.0            685.0   \n",
       "\n",
       "         year  month  \n",
       "4916702  2009      9  \n",
       "2970132  2018      2  \n",
       "1842782  2010      6  \n",
       "3954135  2011      8  \n",
       "5547336  2017      7  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(n=15000)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "del df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test,y_train, y_test = train_test_split(df, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingRegressor(random_state=0)\n",
    "xgboost = xgb.XGBRegressor(random_state=0)\n",
    "lightgbm = lgb.LGBMRegressor(random_state=0)\n",
    "lasso = Lasso(alpha=1.0, random_state=0)\n",
    "svm = svm.SVC(kernel='rbf', C=1, gamma=0.1, random_state=0)\n",
    "\n",
    "models = [{'model':xgboost, 'name':'XGBoost'},\n",
    "          {'model':gboost, 'name': 'GradientBoosting'},\n",
    "          {'model':lightgbm, 'name':'LightGBM'},\n",
    "          {'model':lasso, 'name': 'Lasso'},\n",
    "          {'model':svm, 'name': 'SVM'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_each(models, x, y, sub_x, sub_y):\n",
    "    for m in models :\n",
    "        RMSE = []\n",
    "        \n",
    "        for m in models:\n",
    "            start = time.time()\n",
    "            m['model'].fit(x.values, y)\n",
    "            predictions = m['model'].predict(sub_x.values) \n",
    "            result = sqrt(mean_squared_error(sub_y, predictions))\n",
    "            end = round((time.time() - start), 4)\n",
    "            RMSE.append(m['name'])\n",
    "            RMSE.append(round(result))\n",
    "            RMSE.append(end)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['XGBoost',\n",
       " 2171,\n",
       " 0.9024,\n",
       " 'GradientBoosting',\n",
       " 2130,\n",
       " 0.6061,\n",
       " 'LightGBM',\n",
       " 3097,\n",
       " 0.3571,\n",
       " 'Lasso',\n",
       " 6587,\n",
       " 0.13,\n",
       " 'SVM',\n",
       " 22098,\n",
       " 256.4619]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_each(models, x_train, y_train, x_test, y_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(140, input_dim=14, activation='relu'))\n",
    "model.add(Dense(35, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "# loss는 train loss고 val_loss는 validation loss임 / acc도 마찬가지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 6300 samples, validate on 4200 samples\n",
      "Epoch 1/100\n",
      "6300/6300 [==============================] - 2s 253us/step - loss: 1022074429.9683 - acc: 0.0000e+00 - val_loss: 974914358.8571 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 974914358.85714, saving model to ./model/01-974914358.8571.hdf5\n",
      "Epoch 2/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 925443194.9206 - acc: 0.0000e+00 - val_loss: 845725318.0952 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 974914358.85714 to 845725318.09524, saving model to ./model/02-845725318.0952.hdf5\n",
      "Epoch 3/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 792695444.3175 - acc: 0.0000e+00 - val_loss: 712062387.8095 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 845725318.09524 to 712062387.80952, saving model to ./model/03-712062387.8095.hdf5\n",
      "Epoch 4/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 666730383.2381 - acc: 0.0000e+00 - val_loss: 594282464.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 712062387.80952 to 594282464.00000, saving model to ./model/04-594282464.0000.hdf5\n",
      "Epoch 5/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 559081325.7143 - acc: 0.0000e+00 - val_loss: 501977923.0476 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss improved from 594282464.00000 to 501977923.04762, saving model to ./model/05-501977923.0476.hdf5\n",
      "Epoch 6/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 480871241.6508 - acc: 0.0000e+00 - val_loss: 446859358.4762 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00006: val_loss improved from 501977923.04762 to 446859358.47619, saving model to ./model/06-446859358.4762.hdf5\n",
      "Epoch 7/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 441717635.5556 - acc: 0.0000e+00 - val_loss: 424414352.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss improved from 446859358.47619 to 424414352.00000, saving model to ./model/07-424414352.0000.hdf5\n",
      "Epoch 8/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 424330177.0159 - acc: 0.0000e+00 - val_loss: 402564951.6190 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss improved from 424414352.00000 to 402564951.61905, saving model to ./model/08-402564951.6190.hdf5\n",
      "Epoch 9/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 398589735.6190 - acc: 0.0000e+00 - val_loss: 371047328.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss improved from 402564951.61905 to 371047328.00000, saving model to ./model/09-371047328.0000.hdf5\n",
      "Epoch 10/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 368934422.3492 - acc: 0.0000e+00 - val_loss: 342805864.3810 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00010: val_loss improved from 371047328.00000 to 342805864.38095, saving model to ./model/10-342805864.3810.hdf5\n",
      "Epoch 11/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 343962350.2222 - acc: 0.0000e+00 - val_loss: 318404229.3333 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss improved from 342805864.38095 to 318404229.33333, saving model to ./model/11-318404229.3333.hdf5\n",
      "Epoch 12/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 322316708.8254 - acc: 0.0000e+00 - val_loss: 297537054.4762 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss improved from 318404229.33333 to 297537054.47619, saving model to ./model/12-297537054.4762.hdf5\n",
      "Epoch 13/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 303334756.0635 - acc: 0.0000e+00 - val_loss: 279074681.1429 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss improved from 297537054.47619 to 279074681.14286, saving model to ./model/13-279074681.1429.hdf5\n",
      "Epoch 14/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 288108225.2698 - acc: 0.0000e+00 - val_loss: 262147068.9524 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss improved from 279074681.14286 to 262147068.95238, saving model to ./model/14-262147068.9524.hdf5\n",
      "Epoch 15/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 274014965.3333 - acc: 0.0000e+00 - val_loss: 247400916.5714 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss improved from 262147068.95238 to 247400916.57143, saving model to ./model/15-247400916.5714.hdf5\n",
      "Epoch 16/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 261507807.7460 - acc: 1.5873e-04 - val_loss: 235741472.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss improved from 247400916.57143 to 235741472.00000, saving model to ./model/16-235741472.0000.hdf5\n",
      "Epoch 17/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 251029076.3175 - acc: 0.0000e+00 - val_loss: 223655251.8095 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00017: val_loss improved from 235741472.00000 to 223655251.80952, saving model to ./model/17-223655251.8095.hdf5\n",
      "Epoch 18/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 240017623.8730 - acc: 0.0000e+00 - val_loss: 214133084.1905 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00018: val_loss improved from 223655251.80952 to 214133084.19048, saving model to ./model/18-214133084.1905.hdf5\n",
      "Epoch 19/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 229524847.4921 - acc: 0.0000e+00 - val_loss: 202906720.3810 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00019: val_loss improved from 214133084.19048 to 202906720.38095, saving model to ./model/19-202906720.3810.hdf5\n",
      "Epoch 20/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 218120113.2698 - acc: 0.0000e+00 - val_loss: 190285981.7143 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00020: val_loss improved from 202906720.38095 to 190285981.71429, saving model to ./model/20-190285981.7143.hdf5\n",
      "Epoch 21/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 205778331.4286 - acc: 1.5873e-04 - val_loss: 177324610.2857 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00021: val_loss improved from 190285981.71429 to 177324610.28571, saving model to ./model/21-177324610.2857.hdf5\n",
      "Epoch 22/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 192665756.9524 - acc: 0.0000e+00 - val_loss: 163001728.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00022: val_loss improved from 177324610.28571 to 163001728.00000, saving model to ./model/22-163001728.0000.hdf5\n",
      "Epoch 23/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 180054811.3016 - acc: 1.5873e-04 - val_loss: 149812390.4762 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00023: val_loss improved from 163001728.00000 to 149812390.47619, saving model to ./model/23-149812390.4762.hdf5\n",
      "Epoch 24/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 168743139.0476 - acc: 0.0000e+00 - val_loss: 138163835.8095 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00024: val_loss improved from 149812390.47619 to 138163835.80952, saving model to ./model/24-138163835.8095.hdf5\n",
      "Epoch 25/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 158009160.3810 - acc: 0.0000e+00 - val_loss: 128498892.1905 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00025: val_loss improved from 138163835.80952 to 128498892.19048, saving model to ./model/25-128498892.1905.hdf5\n",
      "Epoch 26/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 149587976.2540 - acc: 0.0000e+00 - val_loss: 119592139.0476 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00026: val_loss improved from 128498892.19048 to 119592139.04762, saving model to ./model/26-119592139.0476.hdf5\n",
      "Epoch 27/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 141713519.6190 - acc: 0.0000e+00 - val_loss: 113836432.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00027: val_loss improved from 119592139.04762 to 113836432.00000, saving model to ./model/27-113836432.0000.hdf5\n",
      "Epoch 28/100\n",
      "6300/6300 [==============================] - 0s 8us/step - loss: 134996247.3651 - acc: 0.0000e+00 - val_loss: 109194600.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00028: val_loss improved from 113836432.00000 to 109194600.00000, saving model to ./model/28-109194600.0000.hdf5\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300/6300 [==============================] - 0s 10us/step - loss: 129131447.3651 - acc: 0.0000e+00 - val_loss: 104930246.8571 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00029: val_loss improved from 109194600.00000 to 104930246.85714, saving model to ./model/29-104930246.8571.hdf5\n",
      "Epoch 30/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 123602942.9841 - acc: 1.5873e-04 - val_loss: 101683489.1429 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00030: val_loss improved from 104930246.85714 to 101683489.14286, saving model to ./model/30-101683489.1429.hdf5\n",
      "Epoch 31/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 119669792.5079 - acc: 0.0000e+00 - val_loss: 99857440.1905 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00031: val_loss improved from 101683489.14286 to 99857440.19048, saving model to ./model/31-99857440.1905.hdf5\n",
      "Epoch 32/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 114865926.7302 - acc: 1.5873e-04 - val_loss: 97760051.4286 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00032: val_loss improved from 99857440.19048 to 97760051.42857, saving model to ./model/32-97760051.4286.hdf5\n",
      "Epoch 33/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 111303873.2698 - acc: 1.5873e-04 - val_loss: 95890905.1429 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00033: val_loss improved from 97760051.42857 to 95890905.14286, saving model to ./model/33-95890905.1429.hdf5\n",
      "Epoch 34/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 108360396.5714 - acc: 0.0000e+00 - val_loss: 94537802.0952 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00034: val_loss improved from 95890905.14286 to 94537802.09524, saving model to ./model/34-94537802.0952.hdf5\n",
      "Epoch 35/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 105299966.3492 - acc: 1.5873e-04 - val_loss: 93537544.5714 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00035: val_loss improved from 94537802.09524 to 93537544.57143, saving model to ./model/35-93537544.5714.hdf5\n",
      "Epoch 36/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 102539908.3175 - acc: 1.5873e-04 - val_loss: 92097516.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00036: val_loss improved from 93537544.57143 to 92097516.00000, saving model to ./model/36-92097516.0000.hdf5\n",
      "Epoch 37/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 99736583.2381 - acc: 1.5873e-04 - val_loss: 90592362.8571 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00037: val_loss improved from 92097516.00000 to 90592362.85714, saving model to ./model/37-90592362.8571.hdf5\n",
      "Epoch 38/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 97036854.6032 - acc: 1.5873e-04 - val_loss: 88959510.8571 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00038: val_loss improved from 90592362.85714 to 88959510.85714, saving model to ./model/38-88959510.8571.hdf5\n",
      "Epoch 39/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 95009399.8730 - acc: 3.1746e-04 - val_loss: 87136475.4286 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00039: val_loss improved from 88959510.85714 to 87136475.42857, saving model to ./model/39-87136475.4286.hdf5\n",
      "Epoch 40/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 93296097.3968 - acc: 0.0000e+00 - val_loss: 86091360.9524 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00040: val_loss improved from 87136475.42857 to 86091360.95238, saving model to ./model/40-86091360.9524.hdf5\n",
      "Epoch 41/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 91421882.5397 - acc: 0.0000e+00 - val_loss: 85311237.1429 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00041: val_loss improved from 86091360.95238 to 85311237.14286, saving model to ./model/41-85311237.1429.hdf5\n",
      "Epoch 42/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 89854981.9048 - acc: 0.0000e+00 - val_loss: 83941562.4762 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00042: val_loss improved from 85311237.14286 to 83941562.47619, saving model to ./model/42-83941562.4762.hdf5\n",
      "Epoch 43/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 88025316.0635 - acc: 0.0000e+00 - val_loss: 82235949.7143 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00043: val_loss improved from 83941562.47619 to 82235949.71429, saving model to ./model/43-82235949.7143.hdf5\n",
      "Epoch 44/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 86580154.5397 - acc: 0.0000e+00 - val_loss: 82570883.4286 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 82235949.71429\n",
      "Epoch 45/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 85595128.2540 - acc: 0.0000e+00 - val_loss: 79657047.2381 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00045: val_loss improved from 82235949.71429 to 79657047.23810, saving model to ./model/45-79657047.2381.hdf5\n",
      "Epoch 46/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 83236080.2540 - acc: 1.5873e-04 - val_loss: 78521796.5714 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00046: val_loss improved from 79657047.23810 to 78521796.57143, saving model to ./model/46-78521796.5714.hdf5\n",
      "Epoch 47/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 82119300.4444 - acc: 1.5873e-04 - val_loss: 78021847.2381 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00047: val_loss improved from 78521796.57143 to 78021847.23810, saving model to ./model/47-78021847.2381.hdf5\n",
      "Epoch 48/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 80671770.2857 - acc: 3.1746e-04 - val_loss: 75911469.5238 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00048: val_loss improved from 78021847.23810 to 75911469.52381, saving model to ./model/48-75911469.5238.hdf5\n",
      "Epoch 49/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 79090363.6190 - acc: 1.5873e-04 - val_loss: 74105932.1905 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00049: val_loss improved from 75911469.52381 to 74105932.19048, saving model to ./model/49-74105932.1905.hdf5\n",
      "Epoch 50/100\n",
      "6300/6300 [==============================] - ETA: 0s - loss: 87309312.0000 - acc: 0.0000e+ - 0s 10us/step - loss: 77278116.4444 - acc: 3.1746e-04 - val_loss: 73122927.0476 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00050: val_loss improved from 74105932.19048 to 73122927.04762, saving model to ./model/50-73122927.0476.hdf5\n",
      "Epoch 51/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 76210891.4286 - acc: 1.5873e-04 - val_loss: 72631920.1905 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00051: val_loss improved from 73122927.04762 to 72631920.19048, saving model to ./model/51-72631920.1905.hdf5\n",
      "Epoch 52/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 75326060.3175 - acc: 3.1746e-04 - val_loss: 71647952.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00052: val_loss improved from 72631920.19048 to 71647952.00000, saving model to ./model/52-71647952.0000.hdf5\n",
      "Epoch 53/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 73877571.5556 - acc: 3.1746e-04 - val_loss: 68929740.5714 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00053: val_loss improved from 71647952.00000 to 68929740.57143, saving model to ./model/53-68929740.5714.hdf5\n",
      "Epoch 54/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 71856654.4762 - acc: 3.1746e-04 - val_loss: 67769857.6190 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00054: val_loss improved from 68929740.57143 to 67769857.61905, saving model to ./model/54-67769857.6190.hdf5\n",
      "Epoch 55/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 70576401.0794 - acc: 3.1746e-04 - val_loss: 66736295.4286 - val_acc: 7.1429e-04\n",
      "\n",
      "Epoch 00055: val_loss improved from 67769857.61905 to 66736295.42857, saving model to ./model/55-66736295.4286.hdf5\n",
      "Epoch 56/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 69337433.6508 - acc: 0.0000e+00 - val_loss: 65410791.1429 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00056: val_loss improved from 66736295.42857 to 65410791.14286, saving model to ./model/56-65410791.1429.hdf5\n",
      "Epoch 57/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 68045979.0476 - acc: 0.0000e+00 - val_loss: 64324292.2857 - val_acc: 7.1429e-04\n",
      "\n",
      "Epoch 00057: val_loss improved from 65410791.14286 to 64324292.28571, saving model to ./model/57-64324292.2857.hdf5\n",
      "Epoch 58/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 66827029.5873 - acc: 1.5873e-04 - val_loss: 62783887.7143 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00058: val_loss improved from 64324292.28571 to 62783887.71429, saving model to ./model/58-62783887.7143.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 65324954.4127 - acc: 7.9365e-04 - val_loss: 61517009.2381 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00059: val_loss improved from 62783887.71429 to 61517009.23810, saving model to ./model/59-61517009.2381.hdf5\n",
      "Epoch 60/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 63965447.1111 - acc: 0.0000e+00 - val_loss: 60275415.6190 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00060: val_loss improved from 61517009.23810 to 60275415.61905, saving model to ./model/60-60275415.6190.hdf5\n",
      "Epoch 61/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 62818869.2698 - acc: 1.5873e-04 - val_loss: 59322069.7143 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00061: val_loss improved from 60275415.61905 to 59322069.71429, saving model to ./model/61-59322069.7143.hdf5\n",
      "Epoch 62/100\n",
      "6300/6300 [==============================] - 0s 8us/step - loss: 61666652.0635 - acc: 0.0000e+00 - val_loss: 58299405.5238 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00062: val_loss improved from 59322069.71429 to 58299405.52381, saving model to ./model/62-58299405.5238.hdf5\n",
      "Epoch 63/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 60302590.1905 - acc: 1.5873e-04 - val_loss: 56655537.3333 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00063: val_loss improved from 58299405.52381 to 56655537.33333, saving model to ./model/63-56655537.3333.hdf5\n",
      "Epoch 64/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 58912909.8730 - acc: 0.0000e+00 - val_loss: 55128660.2857 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00064: val_loss improved from 56655537.33333 to 55128660.28571, saving model to ./model/64-55128660.2857.hdf5\n",
      "Epoch 65/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 57492484.9524 - acc: 4.7619e-04 - val_loss: 54243323.0476 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00065: val_loss improved from 55128660.28571 to 54243323.04762, saving model to ./model/65-54243323.0476.hdf5\n",
      "Epoch 66/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 56404493.9048 - acc: 3.1746e-04 - val_loss: 52895331.6190 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00066: val_loss improved from 54243323.04762 to 52895331.61905, saving model to ./model/66-52895331.6190.hdf5\n",
      "Epoch 67/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 55162902.8571 - acc: 3.1746e-04 - val_loss: 51723466.6667 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00067: val_loss improved from 52895331.61905 to 51723466.66667, saving model to ./model/67-51723466.6667.hdf5\n",
      "Epoch 68/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 53897042.7937 - acc: 3.1746e-04 - val_loss: 50585089.6190 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00068: val_loss improved from 51723466.66667 to 50585089.61905, saving model to ./model/68-50585089.6190.hdf5\n",
      "Epoch 69/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 52733767.2381 - acc: 0.0000e+00 - val_loss: 49464838.4762 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00069: val_loss improved from 50585089.61905 to 49464838.47619, saving model to ./model/69-49464838.4762.hdf5\n",
      "Epoch 70/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 51478057.4603 - acc: 6.3492e-04 - val_loss: 47902232.2857 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00070: val_loss improved from 49464838.47619 to 47902232.28571, saving model to ./model/70-47902232.2857.hdf5\n",
      "Epoch 71/100\n",
      "6300/6300 [==============================] - 0s 11us/step - loss: 50201711.8095 - acc: 6.3492e-04 - val_loss: 47686836.3810 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00071: val_loss improved from 47902232.28571 to 47686836.38095, saving model to ./model/71-47686836.3810.hdf5\n",
      "Epoch 72/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 49364488.0635 - acc: 1.5873e-04 - val_loss: 46624260.2857 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00072: val_loss improved from 47686836.38095 to 46624260.28571, saving model to ./model/72-46624260.2857.hdf5\n",
      "Epoch 73/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 48383160.5079 - acc: 1.5873e-04 - val_loss: 46608396.8571 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00073: val_loss improved from 46624260.28571 to 46608396.85714, saving model to ./model/73-46608396.8571.hdf5\n",
      "Epoch 74/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 47552905.6508 - acc: 4.7619e-04 - val_loss: 43604898.1905 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00074: val_loss improved from 46608396.85714 to 43604898.19048, saving model to ./model/74-43604898.1905.hdf5\n",
      "Epoch 75/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 45744828.6984 - acc: 3.1746e-04 - val_loss: 42295850.9048 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00075: val_loss improved from 43604898.19048 to 42295850.90476, saving model to ./model/75-42295850.9048.hdf5\n",
      "Epoch 76/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 44774223.0794 - acc: 6.3492e-04 - val_loss: 41204856.6667 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00076: val_loss improved from 42295850.90476 to 41204856.66667, saving model to ./model/76-41204856.6667.hdf5\n",
      "Epoch 77/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 43678635.4603 - acc: 0.0000e+00 - val_loss: 40237211.5238 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00077: val_loss improved from 41204856.66667 to 40237211.52381, saving model to ./model/77-40237211.5238.hdf5\n",
      "Epoch 78/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 42749914.6032 - acc: 1.5873e-04 - val_loss: 39057146.9524 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00078: val_loss improved from 40237211.52381 to 39057146.95238, saving model to ./model/78-39057146.9524.hdf5\n",
      "Epoch 79/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 41702494.8571 - acc: 3.1746e-04 - val_loss: 38847869.2381 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00079: val_loss improved from 39057146.95238 to 38847869.23810, saving model to ./model/79-38847869.2381.hdf5\n",
      "Epoch 80/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 41151969.5873 - acc: 3.1746e-04 - val_loss: 38318885.0476 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00080: val_loss improved from 38847869.23810 to 38318885.04762, saving model to ./model/80-38318885.0476.hdf5\n",
      "Epoch 81/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 40417229.4286 - acc: 4.7619e-04 - val_loss: 37072579.2381 - val_acc: 7.1429e-04\n",
      "\n",
      "Epoch 00081: val_loss improved from 38318885.04762 to 37072579.23810, saving model to ./model/81-37072579.2381.hdf5\n",
      "Epoch 82/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 39112357.6508 - acc: 4.7619e-04 - val_loss: 35923662.9048 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00082: val_loss improved from 37072579.23810 to 35923662.90476, saving model to ./model/82-35923662.9048.hdf5\n",
      "Epoch 83/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 38414235.7143 - acc: 1.5873e-04 - val_loss: 35107263.2381 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00083: val_loss improved from 35923662.90476 to 35107263.23810, saving model to ./model/83-35107263.2381.hdf5\n",
      "Epoch 84/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 37478406.9206 - acc: 3.1746e-04 - val_loss: 34212447.5238 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00084: val_loss improved from 35107263.23810 to 34212447.52381, saving model to ./model/84-34212447.5238.hdf5\n",
      "Epoch 85/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 36653495.4921 - acc: 1.5873e-04 - val_loss: 33863162.6190 - val_acc: 7.1429e-04\n",
      "\n",
      "Epoch 00085: val_loss improved from 34212447.52381 to 33863162.61905, saving model to ./model/85-33863162.6190.hdf5\n",
      "Epoch 86/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 36159765.1429 - acc: 3.1746e-04 - val_loss: 33001879.9524 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00086: val_loss improved from 33863162.61905 to 33001879.95238, saving model to ./model/86-33001879.9524.hdf5\n",
      "Epoch 87/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 35565633.8413 - acc: 1.5873e-04 - val_loss: 33625267.8571 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 33001879.95238\n",
      "Epoch 88/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 35875342.0952 - acc: 3.1746e-04 - val_loss: 31749395.0000 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00088: val_loss improved from 33001879.95238 to 31749395.00000, saving model to ./model/88-31749395.0000.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 34725692.4127 - acc: 0.0000e+00 - val_loss: 30694265.7143 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00089: val_loss improved from 31749395.00000 to 30694265.71429, saving model to ./model/89-30694265.7143.hdf5\n",
      "Epoch 90/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 33651466.9841 - acc: 4.7619e-04 - val_loss: 30070529.0952 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00090: val_loss improved from 30694265.71429 to 30070529.09524, saving model to ./model/90-30070529.0952.hdf5\n",
      "Epoch 91/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 32914337.4762 - acc: 4.7619e-04 - val_loss: 29607889.9048 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00091: val_loss improved from 30070529.09524 to 29607889.90476, saving model to ./model/91-29607889.9048.hdf5\n",
      "Epoch 92/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 32415098.2857 - acc: 4.7619e-04 - val_loss: 29133254.4286 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00092: val_loss improved from 29607889.90476 to 29133254.42857, saving model to ./model/92-29133254.4286.hdf5\n",
      "Epoch 93/100\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 31796853.1270 - acc: 1.5873e-04 - val_loss: 28683769.2381 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00093: val_loss improved from 29133254.42857 to 28683769.23810, saving model to ./model/93-28683769.2381.hdf5\n",
      "Epoch 94/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 31901651.0159 - acc: 0.0000e+00 - val_loss: 28881286.0000 - val_acc: 7.1429e-04\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 28683769.23810\n",
      "Epoch 95/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 30740152.0000 - acc: 1.5873e-04 - val_loss: 28255966.7143 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00095: val_loss improved from 28683769.23810 to 28255966.71429, saving model to ./model/95-28255966.7143.hdf5\n",
      "Epoch 96/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 30354241.8413 - acc: 3.1746e-04 - val_loss: 28023188.1429 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00096: val_loss improved from 28255966.71429 to 28023188.14286, saving model to ./model/96-28023188.1429.hdf5\n",
      "Epoch 97/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 30149263.2698 - acc: 1.5873e-04 - val_loss: 29116854.7619 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 28023188.14286\n",
      "Epoch 98/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 30352731.1746 - acc: 6.3492e-04 - val_loss: 26597057.2857 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00098: val_loss improved from 28023188.14286 to 26597057.28571, saving model to ./model/98-26597057.2857.hdf5\n",
      "Epoch 99/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 28755155.5556 - acc: 3.1746e-04 - val_loss: 25834024.3810 - val_acc: 2.3810e-04\n",
      "\n",
      "Epoch 00099: val_loss improved from 26597057.28571 to 25834024.38095, saving model to ./model/99-25834024.3810.hdf5\n",
      "Epoch 100/100\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 28241497.7143 - acc: 3.1746e-04 - val_loss: 25511154.3810 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00100: val_loss improved from 25834024.38095 to 25511154.38095, saving model to ./model/100-25511154.3810.hdf5\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, validation_split=0.4, epochs=100, batch_size=1000, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc = history.history['acc']\n",
    "\n",
    "# x값을 지정하고 정확도를 파랑색으로, 오차를 빨강색으로 표시\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.6217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5827.624886236575"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelPred = model.predict(x_test)\n",
    "end = time.time() - start\n",
    "print(round(end,4))\n",
    "RMSE = sqrt(mean_squared_error(y_test, modelPred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 34500.000, 예상가격: 32851.223\n",
      "실제가격: 4830.000, 예상가격: 4029.843\n",
      "실제가격: 32300.000, 예상가격: 29875.703\n",
      "실제가격: 8900.000, 예상가격: 6758.728\n",
      "실제가격: 51000.000, 예상가격: 49403.289\n",
      "실제가격: 27500.000, 예상가격: 27836.709\n",
      "실제가격: 15000.000, 예상가격: 13676.421\n",
      "실제가격: 24200.000, 예상가격: 23587.172\n",
      "실제가격: 55000.000, 예상가격: 52387.305\n",
      "실제가격: 14750.000, 예상가격: 13873.280\n"
     ]
    }
   ],
   "source": [
    "Y_prediction = modelPred.flatten()\n",
    "for i in range(10):\n",
    "    label = y_test.values[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6300 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "6300/6300 [==============================] - 0s 72us/step - loss: 967434189.2063 - acc: 0.0000e+00 - val_loss: 900216408.3810 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 900216408.38095, saving model to ./model/01-900216408.3810.hdf5\n",
      "Epoch 2/10\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 858255120.2540 - acc: 0.0000e+00 - val_loss: 795370508.1905 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 900216408.38095 to 795370508.19048, saving model to ./model/02-795370508.1905.hdf5\n",
      "Epoch 3/10\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 754127036.9524 - acc: 1.5873e-04 - val_loss: 686718019.0476 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 795370508.19048 to 686718019.04762, saving model to ./model/03-686718019.0476.hdf5\n",
      "Epoch 4/10\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 647756180.3175 - acc: 0.0000e+00 - val_loss: 585568644.5714 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 686718019.04762 to 585568644.57143, saving model to ./model/04-585568644.5714.hdf5\n",
      "Epoch 5/10\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 557209544.1270 - acc: 0.0000e+00 - val_loss: 510381449.1429 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss improved from 585568644.57143 to 510381449.14286, saving model to ./model/05-510381449.1429.hdf5\n",
      "Epoch 6/10\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 500227408.2540 - acc: 0.0000e+00 - val_loss: 476590780.9524 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss improved from 510381449.14286 to 476590780.95238, saving model to ./model/06-476590780.9524.hdf5\n",
      "Epoch 7/10\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 476427374.2222 - acc: 0.0000e+00 - val_loss: 461342947.0476 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss improved from 476590780.95238 to 461342947.04762, saving model to ./model/07-461342947.0476.hdf5\n",
      "Epoch 8/10\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 457458969.3968 - acc: 0.0000e+00 - val_loss: 433840118.8571 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss improved from 461342947.04762 to 433840118.85714, saving model to ./model/08-433840118.8571.hdf5\n",
      "Epoch 9/10\n",
      "6300/6300 [==============================] - 0s 9us/step - loss: 428020834.5397 - acc: 0.0000e+00 - val_loss: 402843443.8095 - val_acc: 4.7619e-04\n",
      "\n",
      "Epoch 00009: val_loss improved from 433840118.85714 to 402843443.80952, saving model to ./model/09-402843443.8095.hdf5\n",
      "Epoch 10/10\n",
      "6300/6300 [==============================] - 0s 10us/step - loss: 398845033.6508 - acc: 1.5873e-04 - val_loss: 373641256.3810 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss improved from 402843443.80952 to 373641256.38095, saving model to ./model/10-373641256.3810.hdf5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEDCAYAAADOc0QpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAD9dJREFUeJzt3X+MZWddx/H3h1mX34hhV43dlq1afjQI1k4qQxMd3RILmjaCkBYxwTQ2JhQQQdOqaUiN2QhENLEY11qJiNRSidmQlSWpnWDstNlZCshuLdkUodNCOvwqRoPLrl//OLft7HS6c2d7Z869z7xfyebcc+6zdz452f3Mmec+c0+qCklSW57WdwBJ0uhZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDeq13JPcnOThJF8YYuwLk9ye5PNJ5pLs2oyMkjSJ+r5y/xBw6ZBj3w/8bVW9HLgB2LtRoSRp0vVa7lX1aeCby48l+bEkn0xyOMm/JnnJ4KnzgdsHj+8ALt/EqJI0Ufq+cl/NPuBtVXUh8G7gg4PjnwNeP3j8y8Bzk7ygh3ySNPa29R1guSTPAV4FfCzJo4efPti+G/jzJG8BPg08CJzY7IySNAnGqtzpfpL4dlX95Monquoh4HXw2DeB11fVI5ucT5ImwlhNy1TVd4AvJXkDQDqvGDzekeTRvNcBN/cUU5LGXt9LIT8KzAMvTrKY5CrgV4GrknwOOMLjb5zOAvcl+SLwQ8Af9RBZkiZC/MhfSWrPWE3LSJJGo7c3VHfs2FG7d+/u68tL0kQ6fPjw16tq51rjeiv33bt3s7Cw0NeXl6SJlOTLw4xzWkaSGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1aPLKfX4e9u7ttpKkVY3bp0Ke3vw87NkDx4/D9u1w++0wM9N3KkkaO5N15T431xX7yZPddm6u70SSNJYmq9xnZ7sr9qmpbjs723ciSRpLkzUtMzPTTcXMzXXF7pSMJK1qssodukK31CXptCZrWkaSNBTLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1aKhyT3JpkvuSHEty7SrPn5PkjiT3JPl8kteOPqokaVhrlnuSKeBG4DXA+cCVSc5fMewPgFur6gLgCuCDow4qSRreMFfuFwHHqur+qjoO3AJcvmJMAc8bPP5+4KHRRRxT8/Owd2+3laQxM8xt9s4CHli2vwj89Iox7wE+leRtwLOBS1Z7oSRXA1cDnHPOOevNOj7m52HPHjh+vLtR9+23e+s/SWNlmCv3rHKsVuxfCXyoqnYBrwU+nOQJr11V+6pquqqmd+7cuf6042Juriv2kye77dxc34kk6RTDlPsicPay/V08cdrlKuBWgKqaB54B7BhFwLE0O9tdsU9NddvZ2b4TSdIphpmWOQScl+Rc4EG6N0zftGLMV4A9wIeSvJSu3JdGGXSszMx0UzFzc12xOyUjacysWe5VdSLJNcBBYAq4uaqOJLkBWKiq/cC7gL9K8k66KZu3VNXKqZu2zMxY6pLG1jBX7lTVAeDAimPXL3t8FLh4tNEkSWfK31CVpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuk25+Hvbu7baSNDDUbfY0pubnYc8eOH4ctm/vbtrtfV0l4ZX7ZJub64r95MluOzfXdyJJY8Jyn2Szs90V+9RUt52d7TuRpDHhtMwkm5nppmLm5rpid0pG0oDlPulmZix1SU/gtIwkNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGjRUuSe5NMl9SY4lufZJxrwxydEkR5L8/WhjSpLWY81PhUwyBdwIvBpYBA4l2V9VR5eNOQ+4Dri4qr6V5Ac3KrAkaW3DXLlfBByrqvur6jhwC3D5ijG/AdxYVd8CqKqHRxtTkrQew5T7WcADy/YXB8eWexHwoiT/luSuJJeu9kJJrk6ykGRhaWnpzBJLktY0TLlnlWO1Yn8bcB4wC1wJ3JTk+U/4S1X7qmq6qqZ37ty53qwaZ/PzsHdvt5XUu2HuxLQInL1sfxfw0Cpj7qqq7wFfSnIfXdkfGklKjbf5edizp7tJ9/bt3a3/vDuU1KthrtwPAeclOTfJduAKYP+KMf8E/BxAkh100zT3jzKoxtjcXFfsJ09227m5vhNJW96a5V5VJ4BrgIPAvcCtVXUkyQ1JLhsMOwh8I8lR4A7gd6rqGxsVWmNmdra7Yp+a6razs30nkra8VK2cPt8c09PTtbCw0MvX1gaYn++u2GdnnZKRNlCSw1U1vda4YebcpbXNzFjq0hjx4wckqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe5qizcNkQA/OEwt8aYh0mO8clc7vGmI9BjLXe3wpiHSY5yWUTtmZrqpGG8aIlnuaow3DZEAp2UkqUmWuzRqLsfUGHBaRholl2NqTHjlLo2SyzE1Jix3aZRcjqkx4bSMNErjtBxzfn48cqgXlrs0auOwHNO5/y3PaRmpRc79b3mWu9Qi5/63PKdlpBaN09y/emG5S60ah7l/9cZpGUkby9/Y7YVX7pI2jqt2euOVu6SN46qd3ljukjaOq3Z647SMpI3jqp3eWO6SNpardnox1LRMkkuT3JfkWJJrTzPuV5JUkunRRZSkEdhiq3bWvHJPMgXcCLwaWAQOJdlfVUdXjHsu8Hbg7o0IKklnbAuu2hnmyv0i4FhV3V9Vx4FbgMtXGfeHwHuB744wnyQ9dVtw1c4w5X4W8MCy/cXBscckuQA4u6o+cboXSnJ1koUkC0tLS+sOK0lnZAuu2hnmDdWscqweezJ5GvAB4C1rvVBV7QP2AUxPT9cawyVpNLbgqp1hyn0ROHvZ/i7goWX7zwVeBswlAfhhYH+Sy6pqYVRBJekp2WKrdoaZljkEnJfk3CTbgSuA/Y8+WVWPVNWOqtpdVbuBuwCLXZJ6tGa5V9UJ4BrgIHAvcGtVHUlyQ5LLNjqgJDVlk5ZkDvVLTFV1ADiw4tj1TzJ29qnHkqQGbeKSTD9bRpI2yyYuybTcJWmzbOKSTD9bRpI2yyYuybTcJWkzbdKSTKdlJKlBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lq0FDlnuTSJPclOZbk2lWe/+0kR5N8PsntSV44+qiSpGGtWe5JpoAbgdcA5wNXJjl/xbB7gOmqejlwG/DeUQeVJA1vmCv3i4BjVXV/VR0HbgEuXz6gqu6oqv8Z7N4F7BptTEnSegxT7mcBDyzbXxwcezJXAf+82hNJrk6ykGRhaWlp+JSSpHUZptyzyrFadWDyZmAaeN9qz1fVvqqarqrpnTt3Dp9SkrQu24YYswicvWx/F/DQykFJLgF+H/jZqvrf0cSTJJ2JYa7cDwHnJTk3yXbgCmD/8gFJLgD+Erisqh4efUxJ0nqsWe5VdQK4BjgI3AvcWlVHktyQ5LLBsPcBzwE+luSzSfY/yctJkjbBMNMyVNUB4MCKY9cve3zJiHNJkp4Cf0NVkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lq0FDlnuTSJPclOZbk2lWef3qSfxg8f3eS3aMOKkka3prlnmQKuBF4DXA+cGWS81cMuwr4VlX9OPAB4I9HHfRR8/Owd2+37ZM5zDHOGcxhDqrqtH+AGeDgsv3rgOtWjDkIzAwebwO+DuR0r3vhhRfWet15Z9Uzn1k1NdVt77xz3S8xEuYwxzhnMEfbOYCFWqO3q2qoaZmzgAeW7S8Ojq06pqpOAI8AL1j5QkmuTrKQZGFpaWnY7z+PmZuD48fh5MluOze37pcYCXOYY5wzmMMcMNyce1Y5VmcwhqraV1XTVTW9c+fOYfKdYnYWtm+HqaluOzu77pcYCXOYY5wzmMMcMJg6Oe2AZAZ4T1X9wmD/OoCq2rtszMHBmPkk24CvATvrNC8+PT1dCwsL6w48P999t5udhZmZdf/1kTGHOcY5gznazZHkcFVNrzluiHLfBnwR2AM8CBwC3lRVR5aNeSvwE1X1m0muAF5XVW883eueablL0lY2bLlvW2tAVZ1Icg3dm6ZTwM1VdSTJDXQT+/uBvwY+nOQY8E3giqcWX5L0VKxZ7gBVdQA4sOLY9csefxd4w2ijSZLOlL+hKkkNstwlqUGWuyQ1yHKXpAatuRRyw75wsgR8+Qz/+g66jzhQx/NxKs/H4zwXp2rhfLywqtb8LdDeyv2pSLIwzDrPrcLzcSrPx+M8F6faSufDaRlJapDlLkkNmtRy39d3gDHj+TiV5+NxnotTbZnzMZFz7pKk05vUK3dJ0mlY7pLUoIkr97Vu1r1VJDk7yR1J7k1yJMk7+s40DpJMJbknySf6ztK3JM9PcluS/xj8O+nxU8z7leSdg/8nX0jy0STP6DvTRpuoch/yZt1bxQngXVX1UuCVwFu38LlY7h3AvX2HGBN/Bnyyql4CvIItel6SnAW8HZiuqpfRfXR58x9LPlHlDlwEHKuq+6vqOHALcHnPmXpRVV+tqs8MHv8X3X/clfe23VKS7AJ+Ebip7yx9S/I84Gfo7rVAVR2vqm/3m6pX24BnDm4+9CzgoZ7zbLhJK/dhbta95STZDVwA3N1vkt79KfC7wP/1HWQM/CiwBPzNYJrqpiTP7jtUH6rqQeD9wFeArwKPVNWn+k218Sat3Ie6EfdWkuQ5wD8Cv1VV3+k7T1+S/BLwcFUd7jvLmNgG/BTwF1V1AfDfwJZ8jyrJD9D9hH8u8CPAs5O8ud9UG2/Syn0ROHvZ/i62wI9XTybJ99EV+0eq6uN95+nZxcBlSf6Tbrru55P8Xb+RerUILFbVoz/N3UZX9lvRJcCXqmqpqr4HfBx4Vc+ZNtyklfsh4Lwk5ybZTvemyP6eM/UiSejmU++tqj/pO0/fquq6qtpVVbvp/l38S1U1f3X2ZKrqa8ADSV48OLQHONpjpD59BXhlkmcN/t/sYQu8uTzUPVTHxZPdrLvnWH25GPg14N+TfHZw7PcG97uVAN4GfGRwIXQ/8Os95+lFVd2d5DbgM3SrzO5hC3wMgR8/IEkNmrRpGUnSECx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1KD/BwP0KgFRckRaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19870.954035971266"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(140, input_dim=14, activation='relu'))\n",
    "model.add(Dense(35, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 저장 폴더 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "# loss는 train loss고 val_loss는 validation loss임 / acc도 마찬가지\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, validation_split=0.4, epochs=10, batch_size=1000, callbacks=[checkpointer])\n",
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc = history.history['acc']\n",
    "\n",
    "# x값을 지정하고 정확도를 파랑색으로, 오차를 빨강색으로 표시\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "modelPred = model.predict(x_test)\n",
    "end = time.time() - start\n",
    "print(round(end,4))\n",
    "RMSE = sqrt(mean_squared_error(y_test, modelPred))\n",
    "RMSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
