{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>district</th>\n",
       "      <th>dong</th>\n",
       "      <th>apartment</th>\n",
       "      <th>m2</th>\n",
       "      <th>price</th>\n",
       "      <th>floor</th>\n",
       "      <th>pre_m2</th>\n",
       "      <th>moving_date</th>\n",
       "      <th>num_people</th>\n",
       "      <th>people_by_m2</th>\n",
       "      <th>price_by_m2</th>\n",
       "      <th>price_by_pre_m2</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1156</td>\n",
       "      <td>1504</td>\n",
       "      <td>196.21</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>211.23</td>\n",
       "      <td>1976.06</td>\n",
       "      <td>480.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7582.0</td>\n",
       "      <td>7043.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1706</td>\n",
       "      <td>4942</td>\n",
       "      <td>202.58</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>252.31</td>\n",
       "      <td>2010.07</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7343.0</td>\n",
       "      <td>5896.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1156</td>\n",
       "      <td>9746</td>\n",
       "      <td>139.83</td>\n",
       "      <td>320000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>165.29</td>\n",
       "      <td>1982.04</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>7565.0</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>393</td>\n",
       "      <td>15322</td>\n",
       "      <td>191.04</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>219.22</td>\n",
       "      <td>1983.12</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5451.0</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1156</td>\n",
       "      <td>1509</td>\n",
       "      <td>144.20</td>\n",
       "      <td>304000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>158.68</td>\n",
       "      <td>1979.05</td>\n",
       "      <td>560.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>6969.0</td>\n",
       "      <td>6333.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city  district  dong  apartment      m2     price  floor  pre_m2  \\\n",
       "0     8         1  1156       1504  196.21  450000.0   13.0  211.23   \n",
       "1     8         1  1706       4942  202.58  450000.0    5.0  252.31   \n",
       "2     8         1  1156       9746  139.83  320000.0    7.0  165.29   \n",
       "3     8         1   393      15322  191.04  315000.0    2.0  219.22   \n",
       "4     8         1  1156       1509  144.20  304000.0   10.0  158.68   \n",
       "\n",
       "   moving_date  num_people  people_by_m2  price_by_m2  price_by_pre_m2  year  \\\n",
       "0      1976.06       480.0         120.0       7582.0           7043.0  2018   \n",
       "1      2010.07        19.0           1.0       7343.0           5896.0  2018   \n",
       "2      1982.04      1924.0         168.0       7565.0           6400.0  2018   \n",
       "3      1983.12      1204.0          84.0       5451.0           4750.0  2018   \n",
       "4      1979.05       560.0         168.0       6969.0           6333.0  2018   \n",
       "\n",
       "   month  \n",
       "0     12  \n",
       "1     12  \n",
       "2     12  \n",
       "3     12  \n",
       "4     12  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./preprocessed_apartment.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6174900, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_down1 = df.sample(n=600000)\n",
    "# print(df_down1.shape)\n",
    "# df_down1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_down2 = df.sample(n=15000)\n",
    "# print(df_down2.shape)\n",
    "# df_down2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_down3 = df.sample(n=1000)\n",
    "# print(df_down3.shape)\n",
    "# df_down3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_down4 = df.sample(n=100)\n",
    "# print(df_down4.shape)\n",
    "# df_down4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "del df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test,y_train, y_test = train_test_split(df, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingRegressor(random_state=0)\n",
    "xgboost = xgb.XGBRegressor(random_state=0)\n",
    "lightgbm = lgb.LGBMRegressor(random_state=0)\n",
    "lasso = Lasso(alpha=1.0, random_state=0)\n",
    "svm = svm.SVC(kernel='rbf', C=1, gamma=0.1, random_state=0)\n",
    "\n",
    "models = [{'model':xgboost, 'name':'XGBoost'},\n",
    "          {'model':gboost, 'name': 'GradientBoosting'},\n",
    "          {'model':lightgbm, 'name':'LightGBM'},\n",
    "          {'model':lasso, 'name': 'Lasso'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_each(models, x, y, sub_x, sub_y):\n",
    "    for m in models :\n",
    "        RMSE = []\n",
    "        \n",
    "        for m in models:\n",
    "            start = time.time()\n",
    "            m['model'].fit(x.values, y)\n",
    "            predictions = m['model'].predict(sub_x.values) \n",
    "            result = sqrt(mean_squared_error(sub_y, predictions))\n",
    "            end = round((time.time() - start), 4)\n",
    "            RMSE.append(m['name'])\n",
    "            RMSE.append(round(result))\n",
    "            RMSE.append(end)\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['XGBoost',\n",
       " 3611,\n",
       " 1548.7952,\n",
       " 'GradientBoosting',\n",
       " 1170,\n",
       " 882.4871,\n",
       " 'LightGBM',\n",
       " 1163,\n",
       " 46.4155,\n",
       " 'Lasso',\n",
       " 6778,\n",
       " 127.3297]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_each(models, x_train, y_train, x_test, y_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(140, input_dim=14, activation='relu'))\n",
    "model.add(Dense(35, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "# loss는 train loss고 val_loss는 validation loss임 / acc도 마찬가지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2593458 samples, validate on 1728972 samples\n",
      "Epoch 1/100\n",
      "2593458/2593458 [==============================] - 25s 10us/step - loss: 67607241.6963 - acc: 2.7878e-04 - val_loss: 4565983.1094 - val_acc: 5.6623e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4565983.10941, saving model to ./model/01-4565983.1094.hdf5\n",
      "Epoch 2/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 2209877.6923 - acc: 6.5627e-04 - val_loss: 895310.5862 - val_acc: 0.0010\n",
      "\n",
      "Epoch 00002: val_loss improved from 4565983.10941 to 895310.58620, saving model to ./model/02-895310.5862.hdf5\n",
      "Epoch 3/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 877944.0707 - acc: 9.2348e-04 - val_loss: 873350.2783 - val_acc: 6.4663e-04\n",
      "\n",
      "Epoch 00003: val_loss improved from 895310.58620 to 873350.27834, saving model to ./model/03-873350.2783.hdf5\n",
      "Epoch 4/100\n",
      "2593458/2593458 [==============================] - 22s 9us/step - loss: 595247.8656 - acc: 0.0012 - val_loss: 338585.4353 - val_acc: 0.0018\n",
      "\n",
      "Epoch 00004: val_loss improved from 873350.27834 to 338585.43528, saving model to ./model/04-338585.4353.hdf5\n",
      "Epoch 5/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 436697.3684 - acc: 0.0014 - val_loss: 295470.2622 - val_acc: 0.0017\n",
      "\n",
      "Epoch 00005: val_loss improved from 338585.43528 to 295470.26216, saving model to ./model/05-295470.2622.hdf5\n",
      "Epoch 6/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 358727.2322 - acc: 0.0016 - val_loss: 200224.3352 - val_acc: 0.0024\n",
      "\n",
      "Epoch 00006: val_loss improved from 295470.26216 to 200224.33518, saving model to ./model/06-200224.3352.hdf5\n",
      "Epoch 7/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 312834.3773 - acc: 0.0017 - val_loss: 278839.3267 - val_acc: 7.6230e-04\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 200224.33518\n",
      "Epoch 8/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 269027.9111 - acc: 0.0018 - val_loss: 177639.6574 - val_acc: 0.0025\n",
      "\n",
      "Epoch 00008: val_loss improved from 200224.33518 to 177639.65744, saving model to ./model/08-177639.6574.hdf5\n",
      "Epoch 9/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 241283.0529 - acc: 0.0020 - val_loss: 193516.3103 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 177639.65744\n",
      "Epoch 10/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 223526.0792 - acc: 0.0020 - val_loss: 140307.1082 - val_acc: 0.0027\n",
      "\n",
      "Epoch 00010: val_loss improved from 177639.65744 to 140307.10820, saving model to ./model/10-140307.1082.hdf5\n",
      "Epoch 11/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 211807.5506 - acc: 0.0021 - val_loss: 177396.8329 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 140307.10820\n",
      "Epoch 12/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 226153.5193 - acc: 0.0022 - val_loss: 213011.5085 - val_acc: 3.8520e-04\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 140307.10820\n",
      "Epoch 13/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 165923.1363 - acc: 0.0023 - val_loss: 123526.0432 - val_acc: 0.0035\n",
      "\n",
      "Epoch 00013: val_loss improved from 140307.10820 to 123526.04323, saving model to ./model/13-123526.0432.hdf5\n",
      "Epoch 14/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 225492.2396 - acc: 0.0025 - val_loss: 106023.7723 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00014: val_loss improved from 123526.04323 to 106023.77231, saving model to ./model/14-106023.7723.hdf5\n",
      "Epoch 15/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 140246.2281 - acc: 0.0024 - val_loss: 86018.3531 - val_acc: 0.0038\n",
      "\n",
      "Epoch 00015: val_loss improved from 106023.77231 to 86018.35306, saving model to ./model/15-86018.3531.hdf5\n",
      "Epoch 16/100\n",
      "2593458/2593458 [==============================] - 24s 9us/step - loss: 113117.9406 - acc: 0.0023 - val_loss: 56779.8903 - val_acc: 0.0035\n",
      "\n",
      "Epoch 00016: val_loss improved from 86018.35306 to 56779.89030, saving model to ./model/16-56779.8903.hdf5\n",
      "Epoch 17/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 124275.2733 - acc: 0.0025 - val_loss: 88422.8356 - val_acc: 0.0024\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 56779.89030\n",
      "Epoch 18/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 91526.8226 - acc: 0.0025 - val_loss: 68334.7345 - val_acc: 0.0035\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 56779.89030\n",
      "Epoch 19/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 91585.8657 - acc: 0.0027 - val_loss: 112796.5513 - val_acc: 8.8897e-04\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 56779.89030\n",
      "Epoch 20/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 100935.0044 - acc: 0.0027 - val_loss: 54337.6116 - val_acc: 0.0024\n",
      "\n",
      "Epoch 00020: val_loss improved from 56779.89030 to 54337.61163, saving model to ./model/20-54337.6116.hdf5\n",
      "Epoch 21/100\n",
      "2593458/2593458 [==============================] - 22s 8us/step - loss: 86216.8031 - acc: 0.0027 - val_loss: 48791.5773 - val_acc: 0.0039\n",
      "\n",
      "Epoch 00021: val_loss improved from 54337.61163 to 48791.57727, saving model to ./model/21-48791.5773.hdf5\n",
      "Epoch 22/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 101443.1013 - acc: 0.0026 - val_loss: 57125.6175 - val_acc: 0.0031\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 48791.57727\n",
      "Epoch 23/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 71604.8119 - acc: 0.0028 - val_loss: 49100.3335 - val_acc: 0.0024\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 48791.57727\n",
      "Epoch 24/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 93304.1761 - acc: 0.0027 - val_loss: 48079.5115 - val_acc: 0.0032\n",
      "\n",
      "Epoch 00024: val_loss improved from 48791.57727 to 48079.51149, saving model to ./model/24-48079.5115.hdf5\n",
      "Epoch 25/100\n",
      "2593458/2593458 [==============================] - 22s 9us/step - loss: 90530.2349 - acc: 0.0028 - val_loss: 37326.7722 - val_acc: 0.0040\n",
      "\n",
      "Epoch 00025: val_loss improved from 48079.51149 to 37326.77219, saving model to ./model/25-37326.7722.hdf5\n",
      "Epoch 26/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 73921.7411 - acc: 0.0028 - val_loss: 42992.4505 - val_acc: 0.0028\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 37326.77219\n",
      "Epoch 27/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 76433.3564 - acc: 0.0029 - val_loss: 51679.5695 - val_acc: 0.0036\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 37326.77219\n",
      "Epoch 28/100\n",
      "2593458/2593458 [==============================] - 22s 9us/step - loss: 82221.1238 - acc: 0.0028 - val_loss: 34724.9020 - val_acc: 0.0039\n",
      "\n",
      "Epoch 00028: val_loss improved from 37326.77219 to 34724.90205, saving model to ./model/28-34724.9020.hdf5\n",
      "Epoch 29/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 80368.9896 - acc: 0.0030 - val_loss: 40147.3555 - val_acc: 0.0034\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 34724.90205\n",
      "Epoch 30/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 103296.5414 - acc: 0.0029 - val_loss: 37183.5170 - val_acc: 0.0034\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 34724.90205\n",
      "Epoch 31/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 65370.2182 - acc: 0.0031 - val_loss: 57386.5307 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 34724.90205\n",
      "Epoch 32/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 71591.3212 - acc: 0.0030 - val_loss: 27866.1042 - val_acc: 0.0048\n",
      "\n",
      "Epoch 00032: val_loss improved from 34724.90205 to 27866.10425, saving model to ./model/32-27866.1042.hdf5\n",
      "Epoch 33/100\n",
      "2593458/2593458 [==============================] - 22s 8us/step - loss: 73705.6285 - acc: 0.0030 - val_loss: 37268.8801 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 27866.10425\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2593458/2593458 [==============================] - 22s 9us/step - loss: 68078.0203 - acc: 0.0034 - val_loss: 37511.8106 - val_acc: 0.0015\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 27866.10425\n",
      "Epoch 35/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 54499.5220 - acc: 0.0031 - val_loss: 23724.2148 - val_acc: 0.0045\n",
      "\n",
      "Epoch 00035: val_loss improved from 27866.10425 to 23724.21475, saving model to ./model/35-23724.2148.hdf5\n",
      "Epoch 36/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 62103.1575 - acc: 0.0033 - val_loss: 34936.7585 - val_acc: 0.0039\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 23724.21475\n",
      "Epoch 37/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 69441.5099 - acc: 0.0033 - val_loss: 25368.0654 - val_acc: 0.0041\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 23724.21475\n",
      "Epoch 38/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 49489.2577 - acc: 0.0037 - val_loss: 49901.1346 - val_acc: 0.0023\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 23724.21475\n",
      "Epoch 39/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 56181.1628 - acc: 0.0033 - val_loss: 40803.1465 - val_acc: 0.0050\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 23724.21475\n",
      "Epoch 40/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 65055.6221 - acc: 0.0035 - val_loss: 23603.4227 - val_acc: 0.0059\n",
      "\n",
      "Epoch 00040: val_loss improved from 23724.21475 to 23603.42273, saving model to ./model/40-23603.4227.hdf5\n",
      "Epoch 41/100\n",
      "2593458/2593458 [==============================] - 21s 8us/step - loss: 43400.0455 - acc: 0.0037 - val_loss: 47970.1475 - val_acc: 0.0037\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 23603.42273\n",
      "Epoch 42/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 59135.5204 - acc: 0.0036 - val_loss: 26592.1157 - val_acc: 0.0049\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 23603.42273\n",
      "Epoch 43/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 49613.6353 - acc: 0.0037 - val_loss: 20778.3670 - val_acc: 0.0047\n",
      "\n",
      "Epoch 00043: val_loss improved from 23603.42273 to 20778.36703, saving model to ./model/43-20778.3670.hdf5\n",
      "Epoch 44/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 53932.4220 - acc: 0.0035 - val_loss: 270975.1860 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 20778.36703\n",
      "Epoch 45/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 57547.5224 - acc: 0.0038 - val_loss: 71940.7737 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 20778.36703\n",
      "Epoch 46/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 44120.2662 - acc: 0.0037 - val_loss: 32764.0595 - val_acc: 0.0048\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 20778.36703\n",
      "Epoch 47/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 50410.8626 - acc: 0.0038 - val_loss: 25063.0982 - val_acc: 0.0058\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 20778.36703\n",
      "Epoch 48/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 46255.8925 - acc: 0.0037 - val_loss: 26295.3200 - val_acc: 0.0034\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 20778.36703\n",
      "Epoch 49/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 52960.9514 - acc: 0.0040 - val_loss: 20228.2225 - val_acc: 0.0047\n",
      "\n",
      "Epoch 00049: val_loss improved from 20778.36703 to 20228.22250, saving model to ./model/49-20228.2225.hdf5\n",
      "Epoch 50/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 46553.9681 - acc: 0.0039 - val_loss: 35296.7824 - val_acc: 0.0045\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 20228.22250\n",
      "Epoch 51/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 54114.7433 - acc: 0.0039 - val_loss: 19395.5452 - val_acc: 0.0049\n",
      "\n",
      "Epoch 00051: val_loss improved from 20228.22250 to 19395.54518, saving model to ./model/51-19395.5452.hdf5\n",
      "Epoch 52/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 61062.8842 - acc: 0.0038 - val_loss: 28039.0480 - val_acc: 0.0059\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 19395.54518\n",
      "Epoch 53/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 36485.9932 - acc: 0.0043 - val_loss: 22308.1761 - val_acc: 0.0036\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 19395.54518\n",
      "Epoch 54/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 42415.5282 - acc: 0.0039 - val_loss: 22776.3657 - val_acc: 0.0053\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 19395.54518\n",
      "Epoch 55/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 53056.1248 - acc: 0.0039 - val_loss: 27070.3563 - val_acc: 0.0035\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 19395.54518\n",
      "Epoch 56/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 39141.0434 - acc: 0.0039 - val_loss: 37676.4696 - val_acc: 0.0053\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 19395.54518\n",
      "Epoch 57/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 55347.4263 - acc: 0.0037 - val_loss: 17737.9681 - val_acc: 0.0050\n",
      "\n",
      "Epoch 00057: val_loss improved from 19395.54518 to 17737.96814, saving model to ./model/57-17737.9681.hdf5\n",
      "Epoch 58/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 48319.1670 - acc: 0.0045 - val_loss: 17036.7441 - val_acc: 0.0062\n",
      "\n",
      "Epoch 00058: val_loss improved from 17737.96814 to 17036.74413, saving model to ./model/58-17036.7441.hdf5\n",
      "Epoch 59/100\n",
      "2593458/2593458 [==============================] - 22s 9us/step - loss: 42147.7497 - acc: 0.0040 - val_loss: 93266.7633 - val_acc: 2.4118e-04\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 17036.74413\n",
      "Epoch 60/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 52114.5604 - acc: 0.0039 - val_loss: 26027.0530 - val_acc: 0.0040\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 17036.74413\n",
      "Epoch 61/100\n",
      "2593458/2593458 [==============================] - 22s 9us/step - loss: 32326.5370 - acc: 0.0044 - val_loss: 66011.7058 - val_acc: 0.0034\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 17036.74413\n",
      "Epoch 62/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 46874.6883 - acc: 0.0039 - val_loss: 21536.3184 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 17036.74413\n",
      "Epoch 63/100\n",
      "2593458/2593458 [==============================] - 22s 9us/step - loss: 44752.0242 - acc: 0.0043 - val_loss: 21357.9862 - val_acc: 0.0053\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 17036.74413\n",
      "Epoch 64/100\n",
      "2593458/2593458 [==============================] - 22s 9us/step - loss: 43825.3717 - acc: 0.0041 - val_loss: 23143.3328 - val_acc: 0.0036\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 17036.74413\n",
      "Epoch 65/100\n",
      "2593458/2593458 [==============================] - 22s 9us/step - loss: 49404.1001 - acc: 0.0040 - val_loss: 23236.7896 - val_acc: 0.0058\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 17036.74413\n",
      "Epoch 66/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 42928.2570 - acc: 0.0038 - val_loss: 16305.1093 - val_acc: 0.0062\n",
      "\n",
      "Epoch 00066: val_loss improved from 17036.74413 to 16305.10933, saving model to ./model/66-16305.1093.hdf5\n",
      "Epoch 67/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 42309.0764 - acc: 0.0042 - val_loss: 17464.6237 - val_acc: 0.0064\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 16305.10933\n",
      "Epoch 68/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 37371.5258 - acc: 0.0042 - val_loss: 25807.8211 - val_acc: 0.0027\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 16305.10933\n",
      "Epoch 69/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 42285.7870 - acc: 0.0042 - val_loss: 17116.9725 - val_acc: 0.0051\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 16305.10933\n",
      "Epoch 70/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 41647.9840 - acc: 0.0040 - val_loss: 19724.4913 - val_acc: 0.0028\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 16305.10933\n",
      "Epoch 71/100\n",
      "2593458/2593458 [==============================] - 22s 9us/step - loss: 41809.8899 - acc: 0.0040 - val_loss: 16943.0307 - val_acc: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00071: val_loss did not improve from 16305.10933\n",
      "Epoch 72/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 34459.5912 - acc: 0.0042 - val_loss: 16518.7399 - val_acc: 0.0050\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 16305.10933\n",
      "Epoch 73/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 33797.8872 - acc: 0.0040 - val_loss: 48196.8440 - val_acc: 0.0045\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 16305.10933\n",
      "Epoch 74/100\n",
      "2593458/2593458 [==============================] - 24s 9us/step - loss: 41092.1012 - acc: 0.0041 - val_loss: 103639.9712 - val_acc: 1.3071e-04\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 16305.10933\n",
      "Epoch 75/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 33724.4973 - acc: 0.0042 - val_loss: 81867.2613 - val_acc: 0.0050\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 16305.10933\n",
      "Epoch 76/100\n",
      "2593458/2593458 [==============================] - 24s 9us/step - loss: 38307.3601 - acc: 0.0041 - val_loss: 1299251.5524 - val_acc: 4.3957e-05\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 16305.10933\n",
      "Epoch 77/100\n",
      "2593458/2593458 [==============================] - 24s 9us/step - loss: 34300.4655 - acc: 0.0044 - val_loss: 30239.8228 - val_acc: 0.0050\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 16305.10933\n",
      "Epoch 78/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 38669.0312 - acc: 0.0045 - val_loss: 15881.8818 - val_acc: 0.0045\n",
      "\n",
      "Epoch 00078: val_loss improved from 16305.10933 to 15881.88184, saving model to ./model/78-15881.8818.hdf5\n",
      "Epoch 79/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 35118.4796 - acc: 0.0042 - val_loss: 55829.4341 - val_acc: 0.0044\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 15881.88184\n",
      "Epoch 80/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 39280.8959 - acc: 0.0043 - val_loss: 14897.3898 - val_acc: 0.0067\n",
      "\n",
      "Epoch 00080: val_loss improved from 15881.88184 to 14897.38982, saving model to ./model/80-14897.3898.hdf5\n",
      "Epoch 81/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 41307.4638 - acc: 0.0044 - val_loss: 12911.4892 - val_acc: 0.0054\n",
      "\n",
      "Epoch 00081: val_loss improved from 14897.38982 to 12911.48915, saving model to ./model/81-12911.4892.hdf5\n",
      "Epoch 82/100\n",
      "2593458/2593458 [==============================] - 24s 9us/step - loss: 32154.5638 - acc: 0.0042 - val_loss: 75360.0010 - val_acc: 2.3887e-04\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 12911.48915\n",
      "Epoch 83/100\n",
      "2593458/2593458 [==============================] - 22s 8us/step - loss: 35391.4454 - acc: 0.0044 - val_loss: 42546.4628 - val_acc: 0.0044\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 12911.48915\n",
      "Epoch 84/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 45222.6447 - acc: 0.0046 - val_loss: 25989.9569 - val_acc: 0.0063\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 12911.48915\n",
      "Epoch 85/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 32363.0793 - acc: 0.0043 - val_loss: 37775.6428 - val_acc: 7.5363e-04\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 12911.48915\n",
      "Epoch 86/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 34350.0929 - acc: 0.0043 - val_loss: 13795.1980 - val_acc: 0.0063\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 12911.48915\n",
      "Epoch 87/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 33731.2681 - acc: 0.0045 - val_loss: 16005.4201 - val_acc: 0.0070\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 12911.48915\n",
      "Epoch 88/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 34714.6960 - acc: 0.0043 - val_loss: 15713.5823 - val_acc: 0.0047\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 12911.48915\n",
      "Epoch 89/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 35359.4745 - acc: 0.0045 - val_loss: 15707.9823 - val_acc: 0.0044\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 12911.48915\n",
      "Epoch 90/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 37217.5366 - acc: 0.0044 - val_loss: 17100.6733 - val_acc: 0.0062\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 12911.48915\n",
      "Epoch 91/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 31585.2311 - acc: 0.0044 - val_loss: 42429.6226 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 12911.48915\n",
      "Epoch 92/100\n",
      "2593458/2593458 [==============================] - 24s 9us/step - loss: 32248.4276 - acc: 0.0047 - val_loss: 21540.2626 - val_acc: 0.0035\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 12911.48915\n",
      "Epoch 93/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 41914.8620 - acc: 0.0046 - val_loss: 16327.2998 - val_acc: 0.0074\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 12911.48915\n",
      "Epoch 94/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 33698.5647 - acc: 0.0045 - val_loss: 18240.2422 - val_acc: 0.0028\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 12911.48915\n",
      "Epoch 95/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 34242.5658 - acc: 0.0046 - val_loss: 22076.7304 - val_acc: 0.0038\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 12911.48915\n",
      "Epoch 96/100\n",
      "2593458/2593458 [==============================] - 22s 9us/step - loss: 30947.3271 - acc: 0.0046 - val_loss: 17705.7739 - val_acc: 0.0060\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 12911.48915\n",
      "Epoch 97/100\n",
      "2593458/2593458 [==============================] - 22s 8us/step - loss: 29551.6921 - acc: 0.0047 - val_loss: 11597.8062 - val_acc: 0.0070\n",
      "\n",
      "Epoch 00097: val_loss improved from 12911.48915 to 11597.80616, saving model to ./model/97-11597.8062.hdf5\n",
      "Epoch 98/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 30599.1748 - acc: 0.0044 - val_loss: 13510.9534 - val_acc: 0.0065\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 11597.80616\n",
      "Epoch 99/100\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 29613.5643 - acc: 0.0045 - val_loss: 18529.3302 - val_acc: 0.0060\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 11597.80616\n",
      "Epoch 100/100\n",
      "2593458/2593458 [==============================] - 22s 9us/step - loss: 41808.5744 - acc: 0.0046 - val_loss: 50932.2732 - val_acc: 5.1765e-04\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 11597.80616\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, validation_split=0.4, epochs=100, batch_size=1000, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc = history.history['acc']\n",
    "\n",
    "# x값을 지정하고 정확도를 파랑색으로, 오차를 빨강색으로 표시\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2343.8812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "228.91560211555066"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelPred = model.predict(x_test)\n",
    "end = time.time() - start\n",
    "print(round(end,4))\n",
    "RMSE = sqrt(mean_squared_error(y_test, modelPred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 25000.000, 예상가격: 25015.639\n",
      "실제가격: 20900.000, 예상가격: 20785.254\n",
      "실제가격: 35700.000, 예상가격: 35268.984\n",
      "실제가격: 29250.000, 예상가격: 29113.027\n",
      "실제가격: 5800.000, 예상가격: 5796.831\n",
      "실제가격: 9500.000, 예상가격: 9376.754\n",
      "실제가격: 15400.000, 예상가격: 15240.707\n",
      "실제가격: 6300.000, 예상가격: 6252.543\n",
      "실제가격: 20100.000, 예상가격: 19907.744\n",
      "실제가격: 41500.000, 예상가격: 41287.551\n"
     ]
    }
   ],
   "source": [
    "Y_prediction = modelPred.flatten()\n",
    "for i in range(10):\n",
    "    label = y_test.values[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./model/97-11597.8062.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113.2476758205423"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelPred = model.predict(x_test)\n",
    "RMSE = sqrt(mean_squared_error(y_test, modelPred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 25000.000, 예상가격: 25081.000\n",
      "실제가격: 20900.000, 예상가격: 20922.000\n",
      "실제가격: 35700.000, 예상가격: 35805.000\n",
      "실제가격: 29250.000, 예상가격: 29295.000\n",
      "실제가격: 5800.000, 예상가격: 5925.000\n",
      "실제가격: 9500.000, 예상가격: 9483.000\n",
      "실제가격: 15400.000, 예상가격: 15380.000\n",
      "실제가격: 6300.000, 예상가격: 6371.000\n",
      "실제가격: 20100.000, 예상가격: 20077.000\n",
      "실제가격: 41500.000, 예상가격: 41406.000\n"
     ]
    }
   ],
   "source": [
    "Y_prediction = modelPred.flatten()\n",
    "for i in range(10):\n",
    "    label = y_test.values[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, round(prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2593458 samples, validate on 1728972 samples\n",
      "Epoch 1/10\n",
      "2593458/2593458 [==============================] - 22s 8us/step - loss: 73712930.3306 - acc: 2.3559e-04 - val_loss: 5061312.9532 - val_acc: 4.4362e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5061312.95319, saving model to ./model/01-5061312.9532.hdf5\n",
      "Epoch 2/10\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 2630065.1739 - acc: 5.6797e-04 - val_loss: 1109839.6191 - val_acc: 9.4276e-04\n",
      "\n",
      "Epoch 00002: val_loss improved from 5061312.95319 to 1109839.61908, saving model to ./model/02-1109839.6191.hdf5\n",
      "Epoch 3/10\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 1021264.4194 - acc: 7.5652e-04 - val_loss: 903191.5148 - val_acc: 3.2563e-04\n",
      "\n",
      "Epoch 00003: val_loss improved from 1109839.61908 to 903191.51484, saving model to ./model/03-903191.5148.hdf5\n",
      "Epoch 4/10\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 765057.4359 - acc: 8.3595e-04 - val_loss: 425375.9170 - val_acc: 0.0010\n",
      "\n",
      "Epoch 00004: val_loss improved from 903191.51484 to 425375.91697, saving model to ./model/04-425375.9170.hdf5\n",
      "Epoch 5/10\n",
      "2593458/2593458 [==============================] - 22s 8us/step - loss: 539580.0208 - acc: 9.5895e-04 - val_loss: 443909.2638 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 425375.91697\n",
      "Epoch 6/10\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 438148.2585 - acc: 0.0011 - val_loss: 362980.1347 - val_acc: 9.1846e-04\n",
      "\n",
      "Epoch 00006: val_loss improved from 425375.91697 to 362980.13466, saving model to ./model/06-362980.1347.hdf5\n",
      "Epoch 7/10\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 411802.5943 - acc: 0.0011 - val_loss: 227146.4882 - val_acc: 0.0016\n",
      "\n",
      "Epoch 00007: val_loss improved from 362980.13466 to 227146.48816, saving model to ./model/07-227146.4882.hdf5\n",
      "Epoch 8/10\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 333953.9171 - acc: 0.0012 - val_loss: 2129507.5265 - val_acc: 1.3476e-04\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 227146.48816\n",
      "Epoch 9/10\n",
      "2593458/2593458 [==============================] - 21s 8us/step - loss: 290354.1430 - acc: 0.0012 - val_loss: 431787.4104 - val_acc: 4.6386e-04\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 227146.48816\n",
      "Epoch 10/10\n",
      "2593458/2593458 [==============================] - 23s 9us/step - loss: 380078.2829 - acc: 0.0012 - val_loss: 693421.4422 - val_acc: 8.9070e-04\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 227146.48816\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279.3059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "807.9923525102294"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(140, input_dim=14, activation='relu'))\n",
    "model.add(Dense(35, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 저장 폴더 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "# loss는 train loss고 val_loss는 validation loss임 / acc도 마찬가지\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, validation_split=0.4, epochs=10, batch_size=1000, callbacks=[checkpointer])\n",
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc = history.history['acc']\n",
    "\n",
    "# x값을 지정하고 정확도를 파랑색으로, 오차를 빨강색으로 표시\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "modelPred = model.predict(x_test)\n",
    "end = time.time() - start\n",
    "print(round(end,4))\n",
    "RMSE = sqrt(mean_squared_error(y_test, modelPred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
