{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>district</th>\n",
       "      <th>dong</th>\n",
       "      <th>apartment</th>\n",
       "      <th>m2</th>\n",
       "      <th>price</th>\n",
       "      <th>floor</th>\n",
       "      <th>pre_m2</th>\n",
       "      <th>moving_date</th>\n",
       "      <th>num_people</th>\n",
       "      <th>people_by_m2</th>\n",
       "      <th>price_by_m2</th>\n",
       "      <th>price_by_pre_m2</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1156</td>\n",
       "      <td>1504</td>\n",
       "      <td>196.21</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>211.23</td>\n",
       "      <td>1976.06</td>\n",
       "      <td>480.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7582.0</td>\n",
       "      <td>7043.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1706</td>\n",
       "      <td>4942</td>\n",
       "      <td>202.58</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>252.31</td>\n",
       "      <td>2010.07</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7343.0</td>\n",
       "      <td>5896.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1156</td>\n",
       "      <td>9746</td>\n",
       "      <td>139.83</td>\n",
       "      <td>320000.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>165.29</td>\n",
       "      <td>1982.04</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>7565.0</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>393</td>\n",
       "      <td>15322</td>\n",
       "      <td>191.04</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>219.22</td>\n",
       "      <td>1983.12</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5451.0</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1156</td>\n",
       "      <td>1509</td>\n",
       "      <td>144.20</td>\n",
       "      <td>304000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>158.68</td>\n",
       "      <td>1979.05</td>\n",
       "      <td>560.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>6969.0</td>\n",
       "      <td>6333.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city  district  dong  apartment      m2     price  floor  pre_m2  \\\n",
       "0     8         1  1156       1504  196.21  450000.0   13.0  211.23   \n",
       "1     8         1  1706       4942  202.58  450000.0    5.0  252.31   \n",
       "2     8         1  1156       9746  139.83  320000.0    7.0  165.29   \n",
       "3     8         1   393      15322  191.04  315000.0    2.0  219.22   \n",
       "4     8         1  1156       1509  144.20  304000.0   10.0  158.68   \n",
       "\n",
       "   moving_date  num_people  people_by_m2  price_by_m2  price_by_pre_m2  year  \\\n",
       "0      1976.06       480.0         120.0       7582.0           7043.0  2018   \n",
       "1      2010.07        19.0           1.0       7343.0           5896.0  2018   \n",
       "2      1982.04      1924.0         168.0       7565.0           6400.0  2018   \n",
       "3      1983.12      1204.0          84.0       5451.0           4750.0  2018   \n",
       "4      1979.05       560.0         168.0       6969.0           6333.0  2018   \n",
       "\n",
       "   month  \n",
       "0     12  \n",
       "1     12  \n",
       "2     12  \n",
       "3     12  \n",
       "4     12  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./preprocessed_apartment.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6174900, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "del df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test,y_train, y_test = train_test_split(df, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "# loss는 train loss고 val_loss는 validation loss임 / acc도 마찬가지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* layer 14 / 1400 / 2800 / 1024 / 512 / 256 / 64 / 8 / 1 [relu]\n",
    "* opt = adam,epoch = 150, batch = 500 / validation 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\p36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3025701 samples, validate on 1296729 samples\n",
      "Epoch 1/150\n",
      "3025701/3025701 [==============================] - 214s 71us/step - loss: 13503593.7434 - acc: 4.6568e-04 - val_loss: 548428.5447 - val_acc: 7.4804e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 548428.54470, saving model to ./model/01-548428.5447.hdf5\n",
      "Epoch 2/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 1346194.6737 - acc: 7.4462e-04 - val_loss: 1011246.0415 - val_acc: 7.9122e-04\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 548428.54470\n",
      "Epoch 3/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 1029516.0157 - acc: 9.7234e-04 - val_loss: 159789.4576 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00003: val_loss improved from 548428.54470 to 159789.45762, saving model to ./model/03-159789.4576.hdf5\n",
      "Epoch 4/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 633212.6314 - acc: 0.0011 - val_loss: 129727.2813 - val_acc: 0.0020\n",
      "\n",
      "Epoch 00004: val_loss improved from 159789.45762 to 129727.28126, saving model to ./model/04-129727.2813.hdf5\n",
      "Epoch 5/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 509818.8211 - acc: 0.0012 - val_loss: 221254.4450 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 129727.28126\n",
      "Epoch 6/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 431415.2142 - acc: 0.0013 - val_loss: 1403837.0378 - val_acc: 6.4624e-04\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 129727.28126\n",
      "Epoch 7/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 539661.9827 - acc: 0.0015 - val_loss: 127024.1729 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00007: val_loss improved from 129727.28126 to 127024.17290, saving model to ./model/07-127024.1729.hdf5\n",
      "Epoch 8/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 322786.3643 - acc: 0.0014 - val_loss: 260606.5315 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 127024.17290\n",
      "Epoch 9/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 386776.5543 - acc: 0.0017 - val_loss: 125096.7768 - val_acc: 0.0022\n",
      "\n",
      "Epoch 00009: val_loss improved from 127024.17290 to 125096.77681, saving model to ./model/09-125096.7768.hdf5\n",
      "Epoch 10/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 333121.3322 - acc: 0.0018 - val_loss: 67507.7478 - val_acc: 0.0020\n",
      "\n",
      "Epoch 00010: val_loss improved from 125096.77681 to 67507.74785, saving model to ./model/10-67507.7478.hdf5\n",
      "Epoch 11/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 286567.0340 - acc: 0.0019 - val_loss: 1193851.2670 - val_acc: 1.7737e-05\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 67507.74785\n",
      "Epoch 12/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 307374.5468 - acc: 0.0019 - val_loss: 69151.6665 - val_acc: 0.0024\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 67507.74785\n",
      "Epoch 13/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 231652.8917 - acc: 0.0019 - val_loss: 160299.0642 - val_acc: 0.0016\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 67507.74785\n",
      "Epoch 14/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 239144.2545 - acc: 0.0019 - val_loss: 58798.6221 - val_acc: 0.0034\n",
      "\n",
      "Epoch 00014: val_loss improved from 67507.74785 to 58798.62208, saving model to ./model/14-58798.6221.hdf5\n",
      "Epoch 15/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 227965.8456 - acc: 0.0021 - val_loss: 701946.4532 - val_acc: 7.6732e-04\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 58798.62208\n",
      "Epoch 16/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 222198.5246 - acc: 0.0021 - val_loss: 191078.2411 - val_acc: 5.8840e-04\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 58798.62208\n",
      "Epoch 17/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 209687.7773 - acc: 0.0021 - val_loss: 39797.3824 - val_acc: 0.0029\n",
      "\n",
      "Epoch 00017: val_loss improved from 58798.62208 to 39797.38242, saving model to ./model/17-39797.3824.hdf5\n",
      "Epoch 18/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 178437.8176 - acc: 0.0023 - val_loss: 270620.6356 - val_acc: 4.2877e-04\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 39797.38242\n",
      "Epoch 19/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 174415.2529 - acc: 0.0023 - val_loss: 100906.4979 - val_acc: 0.0022\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 39797.38242\n",
      "Epoch 20/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 172506.1627 - acc: 0.0023 - val_loss: 57560.0508 - val_acc: 0.0030\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 39797.38242\n",
      "Epoch 21/150\n",
      "3025701/3025701 [==============================] - 213s 70us/step - loss: 185685.5545 - acc: 0.0024 - val_loss: 33748.8422 - val_acc: 0.0045\n",
      "\n",
      "Epoch 00021: val_loss improved from 39797.38242 to 33748.84223, saving model to ./model/21-33748.8422.hdf5\n",
      "Epoch 22/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 151223.2322 - acc: 0.0023 - val_loss: 50490.3055 - val_acc: 0.0032\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 33748.84223\n",
      "Epoch 23/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 148015.7905 - acc: 0.0025 - val_loss: 33351.5466 - val_acc: 0.0043\n",
      "\n",
      "Epoch 00023: val_loss improved from 33748.84223 to 33351.54662, saving model to ./model/23-33351.5466.hdf5\n",
      "Epoch 24/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 117201.9672 - acc: 0.0025 - val_loss: 28624.1861 - val_acc: 0.0020\n",
      "\n",
      "Epoch 00024: val_loss improved from 33351.54662 to 28624.18614, saving model to ./model/24-28624.1861.hdf5\n",
      "Epoch 25/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 148793.2212 - acc: 0.0026 - val_loss: 45004.7637 - val_acc: 0.0016\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 28624.18614\n",
      "Epoch 26/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 151505.8617 - acc: 0.0027 - val_loss: 29243.7362 - val_acc: 0.0018\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 28624.18614\n",
      "Epoch 27/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 151144.2952 - acc: 0.0028 - val_loss: 312783.5127 - val_acc: 2.6220e-04\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 28624.18614\n",
      "Epoch 28/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 170001.5466 - acc: 0.0029 - val_loss: 59420.2556 - val_acc: 0.0029\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 28624.18614\n",
      "Epoch 29/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 133027.1229 - acc: 0.0029 - val_loss: 132796.2816 - val_acc: 0.0029\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 28624.18614\n",
      "Epoch 30/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 133955.0608 - acc: 0.0027 - val_loss: 56961.8100 - val_acc: 0.0018\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 28624.18614\n",
      "Epoch 31/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 116029.2164 - acc: 0.0029 - val_loss: 19453.9075 - val_acc: 0.0050\n",
      "\n",
      "Epoch 00031: val_loss improved from 28624.18614 to 19453.90755, saving model to ./model/31-19453.9075.hdf5\n",
      "Epoch 32/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 117382.3242 - acc: 0.0031 - val_loss: 34902.8892 - val_acc: 0.0034\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 19453.90755\n",
      "Epoch 33/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 125087.1195 - acc: 0.0028 - val_loss: 19033.7508 - val_acc: 0.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: val_loss improved from 19453.90755 to 19033.75081, saving model to ./model/33-19033.7508.hdf5\n",
      "Epoch 34/150\n",
      "3025701/3025701 [==============================] - 208s 69us/step - loss: 110875.7314 - acc: 0.0029 - val_loss: 46898.4074 - val_acc: 0.0028\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 19033.75081\n",
      "Epoch 35/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 104528.3184 - acc: 0.0031 - val_loss: 18738.5656 - val_acc: 0.0062\n",
      "\n",
      "Epoch 00035: val_loss improved from 19033.75081 to 18738.56557, saving model to ./model/35-18738.5656.hdf5\n",
      "Epoch 36/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 140201.2868 - acc: 0.0030 - val_loss: 90348.2521 - val_acc: 3.7093e-04\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 18738.56557\n",
      "Epoch 37/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 102259.4560 - acc: 0.0031 - val_loss: 34526.3337 - val_acc: 0.0027\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 18738.56557\n",
      "Epoch 38/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 99480.7236 - acc: 0.0029 - val_loss: 24724.2813 - val_acc: 0.0023\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 18738.56557\n",
      "Epoch 39/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 92183.3318 - acc: 0.0030 - val_loss: 278042.4459 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 18738.56557\n",
      "Epoch 40/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 102520.5321 - acc: 0.0030 - val_loss: 50419.1010 - val_acc: 0.0034\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 18738.56557\n",
      "Epoch 41/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 78688.8317 - acc: 0.0031 - val_loss: 79293.2694 - val_acc: 3.1310e-04\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 18738.56557\n",
      "Epoch 42/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 107961.7820 - acc: 0.0031 - val_loss: 73511.1734 - val_acc: 5.4753e-04\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 18738.56557\n",
      "Epoch 43/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 90981.5306 - acc: 0.0033 - val_loss: 275215.9620 - val_acc: 4.8584e-05\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 18738.56557\n",
      "Epoch 44/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 93678.4205 - acc: 0.0033 - val_loss: 19092.7428 - val_acc: 0.0059\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 18738.56557\n",
      "Epoch 45/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 92930.3753 - acc: 0.0033 - val_loss: 91068.6017 - val_acc: 0.0025\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 18738.56557\n",
      "Epoch 46/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 116481.1660 - acc: 0.0034 - val_loss: 40064.8218 - val_acc: 0.0022\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 18738.56557\n",
      "Epoch 47/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 104386.9586 - acc: 0.0033 - val_loss: 316140.2420 - val_acc: 3.0384e-04\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 18738.56557\n",
      "Epoch 48/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 81260.9083 - acc: 0.0036 - val_loss: 17337.3157 - val_acc: 0.0044\n",
      "\n",
      "Epoch 00048: val_loss improved from 18738.56557 to 17337.31575, saving model to ./model/48-17337.3157.hdf5\n",
      "Epoch 49/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 76428.3863 - acc: 0.0034 - val_loss: 108055.6311 - val_acc: 0.0015\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 17337.31575\n",
      "Epoch 50/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 120969.2489 - acc: 0.0031 - val_loss: 35609.8935 - val_acc: 0.0028\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 17337.31575\n",
      "Epoch 51/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 65053.3911 - acc: 0.0034 - val_loss: 122636.7900 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 17337.31575\n",
      "Epoch 52/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 79285.0155 - acc: 0.0033 - val_loss: 32560.6573 - val_acc: 0.0029\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 17337.31575\n",
      "Epoch 53/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 76372.5921 - acc: 0.0034 - val_loss: 16893.4613 - val_acc: 0.0040\n",
      "\n",
      "Epoch 00053: val_loss improved from 17337.31575 to 16893.46133, saving model to ./model/53-16893.4613.hdf5\n",
      "Epoch 54/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 73671.5221 - acc: 0.0034 - val_loss: 37422.7020 - val_acc: 0.0030\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 16893.46133\n",
      "Epoch 55/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 71218.0438 - acc: 0.0036 - val_loss: 19025.5379 - val_acc: 0.0044\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 16893.46133\n",
      "Epoch 56/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 65705.4432 - acc: 0.0036 - val_loss: 177892.9873 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 16893.46133\n",
      "Epoch 57/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 86327.3252 - acc: 0.0036 - val_loss: 142409.1418 - val_acc: 6.3159e-04\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 16893.46133\n",
      "Epoch 58/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 70776.2275 - acc: 0.0037 - val_loss: 18047.4231 - val_acc: 0.0047\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 16893.46133\n",
      "Epoch 59/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 66691.5084 - acc: 0.0039 - val_loss: 31663.3067 - val_acc: 0.0044\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 16893.46133\n",
      "Epoch 60/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 77229.9306 - acc: 0.0036 - val_loss: 15167.6973 - val_acc: 0.0063\n",
      "\n",
      "Epoch 00060: val_loss improved from 16893.46133 to 15167.69729, saving model to ./model/60-15167.6973.hdf5\n",
      "Epoch 61/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 71705.7988 - acc: 0.0040 - val_loss: 62570.8827 - val_acc: 0.0030\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 15167.69729\n",
      "Epoch 62/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 71409.5534 - acc: 0.0035 - val_loss: 28617.0009 - val_acc: 0.0047\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 15167.69729\n",
      "Epoch 63/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 75496.9362 - acc: 0.0039 - val_loss: 294500.6596 - val_acc: 1.2724e-04\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 15167.69729\n",
      "Epoch 64/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 61953.4287 - acc: 0.0040 - val_loss: 29717.2730 - val_acc: 0.0042\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 15167.69729\n",
      "Epoch 65/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 78266.1191 - acc: 0.0039 - val_loss: 42332.7197 - val_acc: 0.0018\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 15167.69729\n",
      "Epoch 66/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 68547.6472 - acc: 0.0037 - val_loss: 18001.2901 - val_acc: 0.0072\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 15167.69729\n",
      "Epoch 67/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 81558.3635 - acc: 0.0038 - val_loss: 23445.3658 - val_acc: 0.0021\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 15167.69729\n",
      "Epoch 68/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 57617.0368 - acc: 0.0037 - val_loss: 38668.6358 - val_acc: 0.0045\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 15167.69729\n",
      "Epoch 69/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 62542.9065 - acc: 0.0038 - val_loss: 15696.1414 - val_acc: 0.0059\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 15167.69729\n",
      "Epoch 70/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 70144.5243 - acc: 0.0039 - val_loss: 15536.3402 - val_acc: 0.0056\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 15167.69729\n",
      "Epoch 71/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 61724.3415 - acc: 0.0038 - val_loss: 14401.0271 - val_acc: 0.0070\n",
      "\n",
      "Epoch 00071: val_loss improved from 15167.69729 to 14401.02709, saving model to ./model/71-14401.0271.hdf5\n",
      "Epoch 72/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 64550.9622 - acc: 0.0038 - val_loss: 12828.5754 - val_acc: 0.0080\n",
      "\n",
      "Epoch 00072: val_loss improved from 14401.02709 to 12828.57540, saving model to ./model/72-12828.5754.hdf5\n",
      "Epoch 73/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 59417.1337 - acc: 0.0040 - val_loss: 12546.7673 - val_acc: 0.0075\n",
      "\n",
      "Epoch 00073: val_loss improved from 12828.57540 to 12546.76729, saving model to ./model/73-12546.7673.hdf5\n",
      "Epoch 74/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 73420.8968 - acc: 0.0041 - val_loss: 16517.4149 - val_acc: 0.0045\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 12546.76729\n",
      "Epoch 75/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 52004.7737 - acc: 0.0039 - val_loss: 12787.5682 - val_acc: 0.0077\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 12546.76729\n",
      "Epoch 76/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 75986.7293 - acc: 0.0040 - val_loss: 16130.0468 - val_acc: 0.0047\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 12546.76729\n",
      "Epoch 77/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 102150.4384 - acc: 0.0040 - val_loss: 30639.6013 - val_acc: 0.0053\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 12546.76729\n",
      "Epoch 78/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 62627.7821 - acc: 0.0041 - val_loss: 15641.1323 - val_acc: 0.0057\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 12546.76729\n",
      "Epoch 79/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 71147.3264 - acc: 0.0040 - val_loss: 29504.8004 - val_acc: 0.0041\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 12546.76729\n",
      "Epoch 80/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 67802.5249 - acc: 0.0039 - val_loss: 21199.4864 - val_acc: 0.0020\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 12546.76729\n",
      "Epoch 81/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 67115.8840 - acc: 0.0041 - val_loss: 18500.1285 - val_acc: 0.0036\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 12546.76729\n",
      "Epoch 82/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 67802.2011 - acc: 0.0037 - val_loss: 422915.2989 - val_acc: 0.0010\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 12546.76729\n",
      "Epoch 83/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 60672.1353 - acc: 0.0038 - val_loss: 22953.4396 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 12546.76729\n",
      "Epoch 84/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 73539.3324 - acc: 0.0039 - val_loss: 167326.9225 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 12546.76729\n",
      "Epoch 85/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 53275.7653 - acc: 0.0041 - val_loss: 28686.1150 - val_acc: 0.0057\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 12546.76729\n",
      "Epoch 86/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 66917.6007 - acc: 0.0039 - val_loss: 25141.6911 - val_acc: 0.0076\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 12546.76729\n",
      "Epoch 87/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 60375.7894 - acc: 0.0039 - val_loss: 55418.4824 - val_acc: 0.0032\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 12546.76729\n",
      "Epoch 88/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 54152.4346 - acc: 0.0038 - val_loss: 72471.1754 - val_acc: 0.0023\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 12546.76729\n",
      "Epoch 89/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 65555.3241 - acc: 0.0039 - val_loss: 423082.2935 - val_acc: 0.0010\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 12546.76729\n",
      "Epoch 90/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 79493.9539 - acc: 0.0038 - val_loss: 727616.9432 - val_acc: 2.9305e-05\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 12546.76729\n",
      "Epoch 91/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 72285.8378 - acc: 0.0040 - val_loss: 154692.2936 - val_acc: 5.5524e-05\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 12546.76729\n",
      "Epoch 92/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 57483.6210 - acc: 0.0039 - val_loss: 61440.2257 - val_acc: 0.0018\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 12546.76729\n",
      "Epoch 93/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 75431.2913 - acc: 0.0038 - val_loss: 83426.8410 - val_acc: 0.0060\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 12546.76729\n",
      "Epoch 94/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 63691.5916 - acc: 0.0038 - val_loss: 34053.5643 - val_acc: 0.0037\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 12546.76729\n",
      "Epoch 95/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 86426.5365 - acc: 0.0039 - val_loss: 68134.1386 - val_acc: 0.0045\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 12546.76729\n",
      "Epoch 96/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 77242.1569 - acc: 0.0039 - val_loss: 30776.5380 - val_acc: 0.0024\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 12546.76729\n",
      "Epoch 97/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 83381.2403 - acc: 0.0034 - val_loss: 35099.5444 - val_acc: 0.0037\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 12546.76729\n",
      "Epoch 98/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 90318.4356 - acc: 0.0035 - val_loss: 36348.1277 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 12546.76729\n",
      "Epoch 99/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 65055.7566 - acc: 0.0037 - val_loss: 74083.0454 - val_acc: 0.0034\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 12546.76729\n",
      "Epoch 100/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 99990.9282 - acc: 0.0036 - val_loss: 86493.9036 - val_acc: 4.3648e-04\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 12546.76729\n",
      "Epoch 101/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 70973.8873 - acc: 0.0035 - val_loss: 86703.2033 - val_acc: 0.0021\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 12546.76729\n",
      "Epoch 102/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 113477.5787 - acc: 0.0032 - val_loss: 48787.1271 - val_acc: 0.0048\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 12546.76729\n",
      "Epoch 103/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 122815.5471 - acc: 0.0033 - val_loss: 25973.5254 - val_acc: 0.0045\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 12546.76729\n",
      "Epoch 104/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 92558.3784 - acc: 0.0035 - val_loss: 141744.9524 - val_acc: 0.0014\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 12546.76729\n",
      "Epoch 105/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 98136.3844 - acc: 0.0033 - val_loss: 127872.8100 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 12546.76729\n",
      "Epoch 106/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 135906.8181 - acc: 0.0036 - val_loss: 23808.1446 - val_acc: 0.0039\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 12546.76729\n",
      "Epoch 107/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 122607.3295 - acc: 0.0036 - val_loss: 52723.9223 - val_acc: 0.0015\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 12546.76729\n",
      "Epoch 108/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 95971.6937 - acc: 0.0033 - val_loss: 30085.5275 - val_acc: 0.0027\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 12546.76729\n",
      "Epoch 109/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 102052.2851 - acc: 0.0033 - val_loss: 37300.7916 - val_acc: 0.0028\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 12546.76729\n",
      "Epoch 110/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 79628.2886 - acc: 0.0037 - val_loss: 25130.6588 - val_acc: 0.0025\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 12546.76729\n",
      "Epoch 111/150\n",
      "3025701/3025701 [==============================] - 210s 69us/step - loss: 74022.1227 - acc: 0.0037 - val_loss: 34472.2450 - val_acc: 8.8530e-04\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 12546.76729\n",
      "Epoch 112/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 92155.6992 - acc: 0.0037 - val_loss: 18307.6231 - val_acc: 0.0068\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 12546.76729\n",
      "Epoch 113/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 60954.4782 - acc: 0.0037 - val_loss: 19807.5104 - val_acc: 0.0031\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 12546.76729\n",
      "Epoch 114/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 63316.3683 - acc: 0.0038 - val_loss: 19257.2114 - val_acc: 0.0043\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 12546.76729\n",
      "Epoch 115/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 57765.0316 - acc: 0.0039 - val_loss: 15992.7096 - val_acc: 0.0070\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 12546.76729\n",
      "Epoch 116/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 85017.3401 - acc: 0.0040 - val_loss: 20364.5572 - val_acc: 0.0027\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 12546.76729\n",
      "Epoch 117/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 65070.8322 - acc: 0.0039 - val_loss: 18095.4046 - val_acc: 0.0031\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 12546.76729\n",
      "Epoch 118/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 51370.1115 - acc: 0.0040 - val_loss: 107561.0175 - val_acc: 0.0014\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 12546.76729\n",
      "Epoch 119/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 71537.0373 - acc: 0.0039 - val_loss: 13101.9860 - val_acc: 0.0074\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 12546.76729\n",
      "Epoch 120/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 55612.8380 - acc: 0.0044 - val_loss: 11376.8381 - val_acc: 0.0051\n",
      "\n",
      "Epoch 00120: val_loss improved from 12546.76729 to 11376.83809, saving model to ./model/120-11376.8381.hdf5\n",
      "Epoch 121/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 58186.9960 - acc: 0.0041 - val_loss: 11736.1944 - val_acc: 0.0075\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 11376.83809\n",
      "Epoch 122/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 55637.8935 - acc: 0.0045 - val_loss: 14598.2788 - val_acc: 0.0067\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 11376.83809\n",
      "Epoch 123/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 62139.8774 - acc: 0.0044 - val_loss: 16940.7429 - val_acc: 0.0033\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 11376.83809\n",
      "Epoch 124/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 55219.4351 - acc: 0.0043 - val_loss: 28122.6537 - val_acc: 0.0014\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 11376.83809\n",
      "Epoch 125/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 54304.5904 - acc: 0.0043 - val_loss: 11029.5263 - val_acc: 0.0071\n",
      "\n",
      "Epoch 00125: val_loss improved from 11376.83809 to 11029.52629, saving model to ./model/125-11029.5263.hdf5\n",
      "Epoch 126/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 53044.7168 - acc: 0.0043 - val_loss: 323854.8866 - val_acc: 3.5628e-04\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 11029.52629\n",
      "Epoch 127/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 43922.1447 - acc: 0.0043 - val_loss: 12154.7236 - val_acc: 0.0089\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 11029.52629\n",
      "Epoch 128/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 54350.1025 - acc: 0.0042 - val_loss: 46765.9091 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 11029.52629\n",
      "Epoch 129/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 53989.9211 - acc: 0.0043 - val_loss: 56951.1401 - val_acc: 0.0018\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 11029.52629\n",
      "Epoch 130/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 60231.2429 - acc: 0.0047 - val_loss: 13771.4674 - val_acc: 0.0050\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 11029.52629\n",
      "Epoch 131/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 47680.1551 - acc: 0.0046 - val_loss: 14220.3485 - val_acc: 0.0054\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 11029.52629\n",
      "Epoch 132/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 63079.1658 - acc: 0.0044 - val_loss: 15716.9239 - val_acc: 0.0040\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 11029.52629\n",
      "Epoch 133/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 49023.4384 - acc: 0.0043 - val_loss: 14213.8084 - val_acc: 0.0076\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 11029.52629\n",
      "Epoch 134/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 47042.1783 - acc: 0.0044 - val_loss: 12668.4242 - val_acc: 0.0048\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 11029.52629\n",
      "Epoch 135/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 53021.7657 - acc: 0.0047 - val_loss: 19926.4293 - val_acc: 0.0043\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 11029.52629\n",
      "Epoch 136/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 46104.3982 - acc: 0.0044 - val_loss: 8955.0829 - val_acc: 0.0087\n",
      "\n",
      "Epoch 00136: val_loss improved from 11029.52629 to 8955.08294, saving model to ./model/136-8955.0829.hdf5\n",
      "Epoch 137/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 49100.6038 - acc: 0.0045 - val_loss: 40539.2107 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 8955.08294\n",
      "Epoch 138/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 45364.0910 - acc: 0.0042 - val_loss: 8890.8330 - val_acc: 0.0083\n",
      "\n",
      "Epoch 00138: val_loss improved from 8955.08294 to 8890.83301, saving model to ./model/138-8890.8330.hdf5\n",
      "Epoch 139/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 46086.2585 - acc: 0.0045 - val_loss: 99531.0977 - val_acc: 2.7222e-04\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 8890.83301\n",
      "Epoch 140/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 52290.4697 - acc: 0.0045 - val_loss: 9023.4384 - val_acc: 0.0092\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 8890.83301\n",
      "Epoch 141/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 54346.6046 - acc: 0.0046 - val_loss: 59895.7248 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 8890.83301\n",
      "Epoch 142/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 45427.3366 - acc: 0.0045 - val_loss: 34131.7553 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 8890.83301\n",
      "Epoch 143/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 50319.6167 - acc: 0.0044 - val_loss: 34471.8156 - val_acc: 0.0030\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 8890.83301\n",
      "Epoch 144/150\n",
      "3025701/3025701 [==============================] - 212s 70us/step - loss: 48195.3037 - acc: 0.0045 - val_loss: 22272.8366 - val_acc: 0.0065\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 8890.83301\n",
      "Epoch 145/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 44610.3247 - acc: 0.0045 - val_loss: 14531.7155 - val_acc: 0.0080\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 8890.83301\n",
      "Epoch 146/150\n",
      "3025701/3025701 [==============================] - 210s 70us/step - loss: 46977.9307 - acc: 0.0044 - val_loss: 14725.0992 - val_acc: 0.0053\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 8890.83301\n",
      "Epoch 147/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 47861.9662 - acc: 0.0047 - val_loss: 19154.2068 - val_acc: 0.0041\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 8890.83301\n",
      "Epoch 148/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 41723.1610 - acc: 0.0048 - val_loss: 13369.5128 - val_acc: 0.0040\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 8890.83301\n",
      "Epoch 149/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 50367.3174 - acc: 0.0045 - val_loss: 23060.1959 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 8890.83301\n",
      "Epoch 150/150\n",
      "3025701/3025701 [==============================] - 211s 70us/step - loss: 44944.2634 - acc: 0.0046 - val_loss: 30428.4431 - val_acc: 0.0081\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 8890.83301\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  31731.6502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "176.90971144833745"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(140, input_dim=14, activation='relu'))\n",
    "model.add(Dense(1400, activation='relu'))\n",
    "model.add(Dense(2800, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, \n",
    "                    validation_split=0.3, \n",
    "                    epochs=150, \n",
    "                    batch_size=500, \n",
    "                    callbacks=[checkpointer])\n",
    "\n",
    "\n",
    "y_vloss = history.history['val_loss']\n",
    "y_acc = history.history['acc']\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "modelPred = model.predict(x_test)\n",
    "end = time.time() - start\n",
    "print('time: ', round(end,4))\n",
    "RMSE = sqrt(mean_squared_error(y_test, modelPred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3025701 samples, validate on 1296729 samples\n",
      "Epoch 1/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 16340512.8596 - acc: 4.1412e-04 - val_loss: 512746.7403 - val_acc: 0.0010\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 512746.74025, saving model to ./model/01-512746.7403.hdf5\n",
      "Epoch 2/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 1826374.4843 - acc: 7.2942e-04 - val_loss: 225767.1511 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00002: val_loss improved from 512746.74025 to 225767.15108, saving model to ./model/02-225767.1511.hdf5\n",
      "Epoch 3/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 1274159.0033 - acc: 8.5402e-04 - val_loss: 317322.0732 - val_acc: 0.0014\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 225767.15108\n",
      "Epoch 4/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 743667.3728 - acc: 9.5746e-04 - val_loss: 313077.2372 - val_acc: 9.6396e-04\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 225767.15108\n",
      "Epoch 5/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 813040.0123 - acc: 0.0011 - val_loss: 123750.6081 - val_acc: 0.0018\n",
      "\n",
      "Epoch 00005: val_loss improved from 225767.15108 to 123750.60813, saving model to ./model/05-123750.6081.hdf5\n",
      "Epoch 6/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 467776.1181 - acc: 0.0013 - val_loss: 93889.3797 - val_acc: 0.0014\n",
      "\n",
      "Epoch 00006: val_loss improved from 123750.60813 to 93889.37973, saving model to ./model/06-93889.3797.hdf5\n",
      "Epoch 7/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 481029.9249 - acc: 0.0013 - val_loss: 810687.4850 - val_acc: 5.8609e-04\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 93889.37973\n",
      "Epoch 8/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 507203.7462 - acc: 0.0014 - val_loss: 518133.0316 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 93889.37973\n",
      "Epoch 9/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 329380.6169 - acc: 0.0016 - val_loss: 163703.5413 - val_acc: 9.5163e-04\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 93889.37973\n",
      "Epoch 10/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 305987.0917 - acc: 0.0015 - val_loss: 349279.6117 - val_acc: 9.2695e-04\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 93889.37973\n",
      "Epoch 11/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 320888.9687 - acc: 0.0016 - val_loss: 312108.6055 - val_acc: 6.1462e-04\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 93889.37973\n",
      "Epoch 12/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 303980.3582 - acc: 0.0017 - val_loss: 48938.2760 - val_acc: 0.0024\n",
      "\n",
      "Epoch 00012: val_loss improved from 93889.37973 to 48938.27601, saving model to ./model/12-48938.2760.hdf5\n",
      "Epoch 13/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 262389.1555 - acc: 0.0016 - val_loss: 170412.8848 - val_acc: 3.8327e-04\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 48938.27601\n",
      "Epoch 14/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 242891.7270 - acc: 0.0018 - val_loss: 118945.4577 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 48938.27601\n",
      "Epoch 15/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 278746.0129 - acc: 0.0018 - val_loss: 92368.8709 - val_acc: 0.0023\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 48938.27601\n",
      "Epoch 16/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 199307.5652 - acc: 0.0022 - val_loss: 120662.8405 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 48938.27601\n",
      "Epoch 17/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 309691.3340 - acc: 0.0021 - val_loss: 354170.4774 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 48938.27601\n",
      "Epoch 18/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 164056.6030 - acc: 0.0021 - val_loss: 38259.4400 - val_acc: 0.0038\n",
      "\n",
      "Epoch 00018: val_loss improved from 48938.27601 to 38259.43999, saving model to ./model/18-38259.4400.hdf5\n",
      "Epoch 19/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 207661.3734 - acc: 0.0021 - val_loss: 1938286.9335 - val_acc: 3.7016e-05\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 38259.43999\n",
      "Epoch 20/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 197158.3708 - acc: 0.0024 - val_loss: 93170.6035 - val_acc: 5.3674e-04\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 38259.43999\n",
      "Epoch 21/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 184397.9290 - acc: 0.0023 - val_loss: 163175.5993 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 38259.43999\n",
      "Epoch 22/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 158536.8602 - acc: 0.0022 - val_loss: 125050.5575 - val_acc: 0.0022\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 38259.43999\n",
      "Epoch 23/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 143126.6537 - acc: 0.0024 - val_loss: 37565.0820 - val_acc: 0.0041\n",
      "\n",
      "Epoch 00023: val_loss improved from 38259.43999 to 37565.08198, saving model to ./model/23-37565.0820.hdf5\n",
      "Epoch 24/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 147578.0576 - acc: 0.0024 - val_loss: 45293.4210 - val_acc: 0.0038\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 37565.08198\n",
      "Epoch 25/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 162986.9857 - acc: 0.0024 - val_loss: 115715.9140 - val_acc: 0.0028\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 37565.08198\n",
      "Epoch 26/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 150407.4820 - acc: 0.0025 - val_loss: 32701.9007 - val_acc: 0.0037\n",
      "\n",
      "Epoch 00026: val_loss improved from 37565.08198 to 32701.90072, saving model to ./model/26-32701.9007.hdf5\n",
      "Epoch 27/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 144935.1478 - acc: 0.0025 - val_loss: 85915.3487 - val_acc: 0.0020\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 32701.90072\n",
      "Epoch 28/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 160220.5866 - acc: 0.0024 - val_loss: 71081.5436 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 32701.90072\n",
      "Epoch 29/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 120021.5213 - acc: 0.0027 - val_loss: 22998.2209 - val_acc: 0.0048\n",
      "\n",
      "Epoch 00029: val_loss improved from 32701.90072 to 22998.22095, saving model to ./model/29-22998.2209.hdf5\n",
      "Epoch 30/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 142433.6530 - acc: 0.0027 - val_loss: 185363.4373 - val_acc: 7.9122e-04\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 22998.22095\n",
      "Epoch 31/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 130706.1553 - acc: 0.0025 - val_loss: 61766.1639 - val_acc: 0.0041\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 22998.22095\n",
      "Epoch 32/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 163661.8243 - acc: 0.0024 - val_loss: 34258.2955 - val_acc: 0.0032\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 22998.22095\n",
      "Epoch 33/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 110880.5935 - acc: 0.0026 - val_loss: 64390.8511 - val_acc: 0.0028\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 22998.22095\n",
      "Epoch 34/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 131115.5867 - acc: 0.0027 - val_loss: 92520.8287 - val_acc: 0.0021\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 22998.22095\n",
      "Epoch 35/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 119213.0273 - acc: 0.0027 - val_loss: 16303.7821 - val_acc: 0.0059\n",
      "\n",
      "Epoch 00035: val_loss improved from 22998.22095 to 16303.78213, saving model to ./model/35-16303.7821.hdf5\n",
      "Epoch 36/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 185872.9372 - acc: 0.0032 - val_loss: 115744.3911 - val_acc: 6.9868e-04\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 16303.78213\n",
      "Epoch 37/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 96521.2366 - acc: 0.0028 - val_loss: 70415.6903 - val_acc: 0.0014\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 16303.78213\n",
      "Epoch 38/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 92046.1635 - acc: 0.0029 - val_loss: 95602.5627 - val_acc: 0.0018\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 16303.78213\n",
      "Epoch 39/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 89321.1765 - acc: 0.0029 - val_loss: 15218.1049 - val_acc: 0.0054\n",
      "\n",
      "Epoch 00039: val_loss improved from 16303.78213 to 15218.10490, saving model to ./model/39-15218.1049.hdf5\n",
      "Epoch 40/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 114505.9271 - acc: 0.0030 - val_loss: 31600.5794 - val_acc: 0.0051\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 15218.10490\n",
      "Epoch 41/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 104704.4430 - acc: 0.0028 - val_loss: 30613.3008 - val_acc: 0.0022\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 15218.10490\n",
      "Epoch 42/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 96342.4804 - acc: 0.0030 - val_loss: 76121.3111 - val_acc: 0.0029\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 15218.10490\n",
      "Epoch 43/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 109992.8562 - acc: 0.0029 - val_loss: 144201.1656 - val_acc: 3.8559e-04\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 15218.10490\n",
      "Epoch 44/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 118196.7713 - acc: 0.0029 - val_loss: 425712.3959 - val_acc: 5.5216e-04\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 15218.10490\n",
      "Epoch 45/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 65318.0414 - acc: 0.0031 - val_loss: 117342.3716 - val_acc: 1.2647e-04\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 15218.10490\n",
      "Epoch 46/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 99436.6925 - acc: 0.0029 - val_loss: 48579.8081 - val_acc: 0.0028\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 15218.10490\n",
      "Epoch 47/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 74306.9405 - acc: 0.0031 - val_loss: 56348.7955 - val_acc: 0.0024\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 15218.10490\n",
      "Epoch 48/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 93713.2267 - acc: 0.0031 - val_loss: 21623.8694 - val_acc: 0.0029\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 15218.10490\n",
      "Epoch 49/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 65807.1155 - acc: 0.0032 - val_loss: 74961.1381 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 15218.10490\n",
      "Epoch 50/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 89408.4093 - acc: 0.0031 - val_loss: 33689.6774 - val_acc: 0.0034\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 15218.10490\n",
      "Epoch 51/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 67336.0867 - acc: 0.0034 - val_loss: 137197.8900 - val_acc: 0.0036\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 15218.10490\n",
      "Epoch 52/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 123467.9359 - acc: 0.0028 - val_loss: 817667.7105 - val_acc: 4.8969e-04\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 15218.10490\n",
      "Epoch 53/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 86071.2466 - acc: 0.0032 - val_loss: 184410.8961 - val_acc: 7.3415e-04\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 15218.10490\n",
      "Epoch 54/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 75538.4298 - acc: 0.0033 - val_loss: 182600.9323 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 15218.10490\n",
      "Epoch 55/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 98829.9703 - acc: 0.0032 - val_loss: 122087.2101 - val_acc: 3.6168e-04\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 15218.10490\n",
      "Epoch 56/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 108879.2225 - acc: 0.0032 - val_loss: 52541.3767 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 15218.10490\n",
      "Epoch 57/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 67232.7663 - acc: 0.0033 - val_loss: 32195.0066 - val_acc: 0.0041\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 15218.10490\n",
      "Epoch 58/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 93296.3671 - acc: 0.0033 - val_loss: 64394.5605 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 15218.10490\n",
      "Epoch 59/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 90636.2402 - acc: 0.0031 - val_loss: 35909.6486 - val_acc: 0.0038\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 15218.10490\n",
      "Epoch 60/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 66774.3587 - acc: 0.0037 - val_loss: 23532.5561 - val_acc: 0.0049\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 15218.10490\n",
      "Epoch 61/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 74834.3716 - acc: 0.0035 - val_loss: 84816.1442 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 15218.10490\n",
      "Epoch 62/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 76564.9063 - acc: 0.0036 - val_loss: 173977.5245 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 15218.10490\n",
      "Epoch 63/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 82750.1115 - acc: 0.0037 - val_loss: 19037.2014 - val_acc: 0.0018\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 15218.10490\n",
      "Epoch 64/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 54622.7503 - acc: 0.0035 - val_loss: 340020.9065 - val_acc: 5.3982e-06\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 15218.10490\n",
      "Epoch 65/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 77851.0369 - acc: 0.0036 - val_loss: 23445.9921 - val_acc: 0.0030\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 15218.10490\n",
      "Epoch 66/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 80114.8590 - acc: 0.0036 - val_loss: 277747.3838 - val_acc: 0.0011\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 15218.10490\n",
      "Epoch 67/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 64616.0489 - acc: 0.0037 - val_loss: 14432.7282 - val_acc: 0.0049\n",
      "\n",
      "Epoch 00067: val_loss improved from 15218.10490 to 14432.72823, saving model to ./model/67-14432.7282.hdf5\n",
      "Epoch 68/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 57686.5280 - acc: 0.0039 - val_loss: 15829.4958 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 14432.72823\n",
      "Epoch 69/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 71857.4203 - acc: 0.0039 - val_loss: 15146.8231 - val_acc: 0.0052\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 14432.72823\n",
      "Epoch 70/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 50338.1886 - acc: 0.0038 - val_loss: 41235.0906 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 14432.72823\n",
      "Epoch 71/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 79175.2432 - acc: 0.0038 - val_loss: 99363.3794 - val_acc: 4.0101e-05\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 14432.72823\n",
      "Epoch 72/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 58524.9013 - acc: 0.0038 - val_loss: 65968.5911 - val_acc: 0.0036\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 14432.72823\n",
      "Epoch 73/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 64445.0513 - acc: 0.0038 - val_loss: 19342.5105 - val_acc: 0.0058\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 14432.72823\n",
      "Epoch 74/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 57895.8214 - acc: 0.0037 - val_loss: 60804.5368 - val_acc: 0.0015\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 14432.72823\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 57606.7953 - acc: 0.0039 - val_loss: 12083.9931 - val_acc: 0.0047\n",
      "\n",
      "Epoch 00075: val_loss improved from 14432.72823 to 12083.99305, saving model to ./model/75-12083.9931.hdf5\n",
      "Epoch 76/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 70411.4709 - acc: 0.0040 - val_loss: 35045.7014 - val_acc: 0.0061\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 12083.99305\n",
      "Epoch 77/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 78202.5536 - acc: 0.0038 - val_loss: 230826.9568 - val_acc: 5.1283e-04\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 12083.99305\n",
      "Epoch 78/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 43915.6845 - acc: 0.0043 - val_loss: 43726.6950 - val_acc: 0.0012\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 12083.99305\n",
      "Epoch 79/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 86860.0283 - acc: 0.0036 - val_loss: 14204.6186 - val_acc: 0.0064\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 12083.99305\n",
      "Epoch 80/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 61298.4410 - acc: 0.0045 - val_loss: 14100.9765 - val_acc: 0.0060\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 12083.99305\n",
      "Epoch 81/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 41464.5420 - acc: 0.0038 - val_loss: 31558.5651 - val_acc: 0.0017\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 12083.99305\n",
      "Epoch 82/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 63818.4294 - acc: 0.0037 - val_loss: 24847.9583 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 12083.99305\n",
      "Epoch 83/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 45546.1741 - acc: 0.0041 - val_loss: 14107.9677 - val_acc: 0.0041\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 12083.99305\n",
      "Epoch 84/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 52311.5974 - acc: 0.0040 - val_loss: 10432.5689 - val_acc: 0.0066\n",
      "\n",
      "Epoch 00084: val_loss improved from 12083.99305 to 10432.56885, saving model to ./model/84-10432.5689.hdf5\n",
      "Epoch 85/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 47729.3869 - acc: 0.0040 - val_loss: 12680.8054 - val_acc: 0.0056\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 10432.56885\n",
      "Epoch 86/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 47739.1081 - acc: 0.0041 - val_loss: 14092.2938 - val_acc: 0.0075\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 10432.56885\n",
      "Epoch 87/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 58278.4672 - acc: 0.0042 - val_loss: 8818.9786 - val_acc: 0.0057\n",
      "\n",
      "Epoch 00087: val_loss improved from 10432.56885 to 8818.97863, saving model to ./model/87-8818.9786.hdf5\n",
      "Epoch 88/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 55289.7439 - acc: 0.0038 - val_loss: 14842.5236 - val_acc: 0.0068\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 8818.97863\n",
      "Epoch 89/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 60945.3918 - acc: 0.0043 - val_loss: 214694.7459 - val_acc: 1.7814e-04\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 8818.97863\n",
      "Epoch 90/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 81974.4195 - acc: 0.0047 - val_loss: 28827.4054 - val_acc: 0.0036\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 8818.97863\n",
      "Epoch 91/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 57607.3673 - acc: 0.0050 - val_loss: 84836.5618 - val_acc: 0.0018\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 8818.97863\n",
      "Epoch 92/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 59795.8425 - acc: 0.0040 - val_loss: 15239.0791 - val_acc: 0.0031\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 8818.97863\n",
      "Epoch 93/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 43236.9496 - acc: 0.0044 - val_loss: 16796.7998 - val_acc: 0.0073\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 8818.97863\n",
      "Epoch 94/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 80043.5975 - acc: 0.0044 - val_loss: 11747.6548 - val_acc: 0.0077\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 8818.97863\n",
      "Epoch 95/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 42278.3342 - acc: 0.0048 - val_loss: 11047.2326 - val_acc: 0.0059\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 8818.97863\n",
      "Epoch 96/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 52024.7986 - acc: 0.0037 - val_loss: 81855.6310 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 8818.97863\n",
      "Epoch 97/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 47769.0969 - acc: 0.0047 - val_loss: 7713.0048 - val_acc: 0.0088\n",
      "\n",
      "Epoch 00097: val_loss improved from 8818.97863 to 7713.00478, saving model to ./model/97-7713.0048.hdf5\n",
      "Epoch 98/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 51999.9868 - acc: 0.0046 - val_loss: 11629.7338 - val_acc: 0.0080\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 7713.00478\n",
      "Epoch 99/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 72236.1736 - acc: 0.0042 - val_loss: 29678.4026 - val_acc: 8.6603e-04\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 7713.00478\n",
      "Epoch 100/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 43940.5252 - acc: 0.0045 - val_loss: 22613.2769 - val_acc: 0.0035\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 7713.00478\n",
      "Epoch 101/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 43999.0422 - acc: 0.0044 - val_loss: 33419.7285 - val_acc: 0.0017\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 7713.00478\n",
      "Epoch 102/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 49222.6118 - acc: 0.0041 - val_loss: 116377.6507 - val_acc: 6.4007e-05ss: 48935.480 - ETA: 2s - loss: 4\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 7713.00478\n",
      "Epoch 103/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 54990.4272 - acc: 0.0043 - val_loss: 17570.0148 - val_acc: 0.00553640 - acc\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 7713.00478\n",
      "Epoch 104/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 55542.6137 - acc: 0.0046 - val_loss: 10154.7158 - val_acc: 0.0091\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 7713.00478\n",
      "Epoch 105/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 50146.3413 - acc: 0.0045 - val_loss: 10725.8449 - val_acc: 0.0051\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 7713.00478\n",
      "Epoch 106/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 57597.7210 - acc: 0.0043 - val_loss: 31517.3404 - val_acc: 0.0031\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 7713.00478\n",
      "Epoch 107/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 60744.9341 - acc: 0.0043 - val_loss: 14553.3625 - val_acc: 0.0058\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 7713.00478\n",
      "Epoch 108/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 27137.9171 - acc: 0.0049 - val_loss: 24098.4714 - val_acc: 0.0030\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 7713.00478\n",
      "Epoch 109/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 50405.2868 - acc: 0.0040 - val_loss: 12546.6016 - val_acc: 0.0050\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 7713.00478\n",
      "Epoch 110/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 56192.6606 - acc: 0.0043 - val_loss: 20236.4838 - val_acc: 0.0011\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 7713.00478\n",
      "Epoch 111/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 59958.0968 - acc: 0.0047 - val_loss: 13803.9281 - val_acc: 0.0042\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 7713.00478\n",
      "Epoch 112/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 38626.5823 - acc: 0.0043 - val_loss: 23812.5871 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 7713.00478\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 54489.9731 - acc: 0.0045 - val_loss: 8679.0785 - val_acc: 0.0084\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 7713.00478\n",
      "Epoch 114/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 54465.1413 - acc: 0.0040 - val_loss: 14405.3260 - val_acc: 0.0076\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 7713.00478\n",
      "Epoch 115/200\n",
      "3025701/3025701 [==============================] - 145s 48us/step - loss: 47738.6004 - acc: 0.0043 - val_loss: 21553.6462 - val_acc: 0.0014\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 7713.00478\n",
      "Epoch 116/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 48105.1979 - acc: 0.0043 - val_loss: 16110.3439 - val_acc: 0.0038\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 7713.00478\n",
      "Epoch 117/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 47501.9130 - acc: 0.0043 - val_loss: 89583.3402 - val_acc: 1.3418e-04\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 7713.00478\n",
      "Epoch 118/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 55505.0530 - acc: 0.0043 - val_loss: 21768.9094 - val_acc: 0.0073\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 7713.00478\n",
      "Epoch 119/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 46713.9090 - acc: 0.0048 - val_loss: 19569.2225 - val_acc: 0.0020\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 7713.00478\n",
      "Epoch 120/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 39466.4720 - acc: 0.0046 - val_loss: 205934.7144 - val_acc: 3.6245e-05\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 7713.00478\n",
      "Epoch 121/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 42343.9534 - acc: 0.0045 - val_loss: 41508.4257 - val_acc: 7.7734e-04\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 7713.00478\n",
      "Epoch 122/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 53556.1446 - acc: 0.0048 - val_loss: 41087.0131 - val_acc: 6.3776e-04\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 7713.00478\n",
      "Epoch 123/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 61798.7201 - acc: 0.0049 - val_loss: 115591.3403 - val_acc: 0.0027\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 7713.00478\n",
      "Epoch 124/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 41409.3961 - acc: 0.0047 - val_loss: 19566.1026 - val_acc: 0.0025\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 7713.00478\n",
      "Epoch 125/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 38214.9284 - acc: 0.0049 - val_loss: 36657.7960 - val_acc: 7.3955e-04\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 7713.00478\n",
      "Epoch 126/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 50319.6842 - acc: 0.0044 - val_loss: 16943.9507 - val_acc: 0.0065\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 7713.00478\n",
      "Epoch 127/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 59863.1453 - acc: 0.0045 - val_loss: 9473.0819 - val_acc: 0.0091\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 7713.00478\n",
      "Epoch 128/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 43191.0250 - acc: 0.0046 - val_loss: 71041.9768 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 7713.00478\n",
      "Epoch 129/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 40462.2492 - acc: 0.0046 - val_loss: 13666.2204 - val_acc: 0.0063\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 7713.00478\n",
      "Epoch 130/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 37586.9320 - acc: 0.0046 - val_loss: 185041.3782 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 7713.00478\n",
      "Epoch 131/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 45855.8497 - acc: 0.0044 - val_loss: 62477.4744 - val_acc: 0.0020\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 7713.00478\n",
      "Epoch 132/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 41808.7435 - acc: 0.0044 - val_loss: 81699.7404 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 7713.00478\n",
      "Epoch 133/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 41797.9661 - acc: 0.0049 - val_loss: 230468.7701 - val_acc: 1.9125e-04\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 7713.00478\n",
      "Epoch 134/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 47017.0281 - acc: 0.0045 - val_loss: 23585.6751 - val_acc: 0.0052\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 7713.00478\n",
      "Epoch 135/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 41361.0214 - acc: 0.0049 - val_loss: 7577.5290 - val_acc: 0.0099\n",
      "\n",
      "Epoch 00135: val_loss improved from 7713.00478 to 7577.52899, saving model to ./model/135-7577.5290.hdf5\n",
      "Epoch 136/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 39465.4635 - acc: 0.0045 - val_loss: 20453.0500 - val_acc: 0.003044 - ac\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 7577.52899\n",
      "Epoch 137/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 46965.6768 - acc: 0.0048 - val_loss: 12036.1060 - val_acc: 0.0083\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 7577.52899\n",
      "Epoch 138/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 38795.0427 - acc: 0.0043 - val_loss: 9422.9438 - val_acc: 0.0098 0.0\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 7577.52899\n",
      "Epoch 139/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 58128.1567 - acc: 0.0047 - val_loss: 56666.1531 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 7577.52899\n",
      "Epoch 140/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 43158.8348 - acc: 0.0044 - val_loss: 18398.6175 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 7577.52899\n",
      "Epoch 141/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 49053.1688 - acc: 0.0045 - val_loss: 316940.0221 - val_acc: 9.4854e-05\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 7577.52899\n",
      "Epoch 142/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 41949.7593 - acc: 0.0046 - val_loss: 14621.0453 - val_acc: 0.0017\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 7577.52899\n",
      "Epoch 143/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 40291.0745 - acc: 0.0044 - val_loss: 32731.4272 - val_acc: 0.0045\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 7577.52899\n",
      "Epoch 144/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 43011.4444 - acc: 0.0047 - val_loss: 156486.6286 - val_acc: 0.0025\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 7577.52899\n",
      "Epoch 145/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 36821.5414 - acc: 0.0047 - val_loss: 73339.9242 - val_acc: 0.0017\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 7577.52899\n",
      "Epoch 146/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 48730.9408 - acc: 0.0046 - val_loss: 44539.1643 - val_acc: 0.0041\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 7577.52899\n",
      "Epoch 147/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 68770.9316 - acc: 0.0044 - val_loss: 8973.7478 - val_acc: 0.0079\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 7577.52899\n",
      "Epoch 148/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 53371.7582 - acc: 0.0052 - val_loss: 61155.7124 - val_acc: 8.9533e-04\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 7577.52899\n",
      "Epoch 149/200\n",
      "3025701/3025701 [==============================] - 152s 50us/step - loss: 41562.9356 - acc: 0.0047 - val_loss: 65998.7290 - val_acc: 8.1436e-04\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 7577.52899\n",
      "Epoch 150/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 31620.9341 - acc: 0.0048 - val_loss: 18525.1357 - val_acc: 0.0057\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 7577.52899\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 40764.3864 - acc: 0.0046 - val_loss: 68931.0592 - val_acc: 0.0031\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 7577.52899\n",
      "Epoch 152/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 40330.8462 - acc: 0.0050 - val_loss: 8336.7631 - val_acc: 0.0104\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 7577.52899\n",
      "Epoch 153/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 39851.3484 - acc: 0.0045 - val_loss: 39664.9302 - val_acc: 0.0040\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 7577.52899\n",
      "Epoch 154/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 35838.6841 - acc: 0.0047 - val_loss: 24858.6715 - val_acc: 0.0018\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 7577.52899\n",
      "Epoch 155/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 40397.7860 - acc: 0.0047 - val_loss: 39416.3176 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 7577.52899\n",
      "Epoch 156/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 34024.0822 - acc: 0.0047 - val_loss: 16198.3254 - val_acc: 0.0056\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 7577.52899\n",
      "Epoch 157/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 54365.9284 - acc: 0.0049 - val_loss: 82846.8716 - val_acc: 0.0013\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 7577.52899\n",
      "Epoch 158/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 45938.6170 - acc: 0.0048 - val_loss: 46110.0551 - val_acc: 8.6371e-04\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 7577.52899\n",
      "Epoch 159/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 38690.9179 - acc: 0.0049 - val_loss: 23833.0931 - val_acc: 0.0021\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 7577.52899\n",
      "Epoch 160/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 40101.9988 - acc: 0.0048 - val_loss: 64836.2504 - val_acc: 1.2262e-04\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 7577.52899\n",
      "Epoch 161/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 40095.7320 - acc: 0.0048 - val_loss: 11867.2811 - val_acc: 0.0060\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 7577.52899\n",
      "Epoch 162/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 37422.4496 - acc: 0.0048 - val_loss: 9377.4054 - val_acc: 0.0051\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 7577.52899\n",
      "Epoch 163/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 41381.4467 - acc: 0.0046 - val_loss: 67803.8897 - val_acc: 0.0031\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 7577.52899\n",
      "Epoch 164/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 39365.7145 - acc: 0.0047 - val_loss: 11987.0250 - val_acc: 0.0071\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 7577.52899\n",
      "Epoch 165/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 37219.9655 - acc: 0.0052 - val_loss: 12856.0549 - val_acc: 0.0065\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 7577.52899\n",
      "Epoch 166/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 34053.3344 - acc: 0.0046 - val_loss: 16513.2790 - val_acc: 0.0017\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 7577.52899\n",
      "Epoch 167/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 50378.7952 - acc: 0.0048 - val_loss: 8656.9795 - val_acc: 0.0089\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 7577.52899\n",
      "Epoch 168/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 40778.9559 - acc: 0.0049 - val_loss: 33448.5757 - val_acc: 0.0025\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 7577.52899\n",
      "Epoch 169/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 32807.6353 - acc: 0.0049 - val_loss: 294403.7845 - val_acc: 8.7528e-04\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 7577.52899\n",
      "Epoch 170/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 37279.6128 - acc: 0.0046 - val_loss: 19304.9382 - val_acc: 0.0035\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 7577.52899\n",
      "Epoch 171/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 44594.2239 - acc: 0.0052 - val_loss: 12408.2993 - val_acc: 0.0026\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 7577.52899\n",
      "Epoch 172/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 39132.1013 - acc: 0.0048 - val_loss: 40449.7365 - val_acc: 0.0018\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 7577.52899\n",
      "Epoch 173/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 37988.2635 - acc: 0.0044 - val_loss: 16029.2601 - val_acc: 0.0051\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 7577.52899\n",
      "Epoch 174/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 36859.8586 - acc: 0.0051 - val_loss: 34309.8249 - val_acc: 0.0021\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 7577.52899\n",
      "Epoch 175/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 33756.8925 - acc: 0.0047 - val_loss: 45229.4107 - val_acc: 0.0020\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 7577.52899\n",
      "Epoch 176/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 49822.8488 - acc: 0.0053 - val_loss: 117719.3062 - val_acc: 0.0034\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 7577.52899\n",
      "Epoch 177/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 40291.8615 - acc: 0.0049 - val_loss: 150743.2934 - val_acc: 7.7117e-05\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 7577.52899\n",
      "Epoch 178/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 43312.7025 - acc: 0.0048 - val_loss: 11948.7783 - val_acc: 0.0051\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 7577.52899\n",
      "Epoch 179/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 34249.4965 - acc: 0.0054 - val_loss: 11587.6877 - val_acc: 0.0063\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 7577.52899\n",
      "Epoch 180/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 37407.5748 - acc: 0.0050 - val_loss: 9502.0860 - val_acc: 0.0061\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 7577.52899\n",
      "Epoch 181/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 34127.3940 - acc: 0.0051 - val_loss: 8893.6042 - val_acc: 0.0054\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 7577.52899\n",
      "Epoch 182/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 32299.0467 - acc: 0.0048 - val_loss: 188142.0184 - val_acc: 8.1744e-05\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 7577.52899\n",
      "Epoch 183/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 39446.2621 - acc: 0.0049 - val_loss: 34042.3821 - val_acc: 0.0054\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 7577.52899\n",
      "Epoch 184/200\n",
      "3025701/3025701 [==============================] - 149s 49us/step - loss: 32646.3356 - acc: 0.0053 - val_loss: 16236.8303 - val_acc: 0.0077\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 7577.52899\n",
      "Epoch 185/200\n",
      "3025701/3025701 [==============================] - 148s 49us/step - loss: 45644.2918 - acc: 0.0051 - val_loss: 23678.1112 - val_acc: 0.0011ss: 45813.50\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 7577.52899\n",
      "Epoch 186/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 37094.8721 - acc: 0.0049 - val_loss: 10718.6282 - val_acc: 0.0044\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 7577.52899\n",
      "Epoch 187/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 31317.0574 - acc: 0.0051 - val_loss: 11927.0094 - val_acc: 0.0080\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 7577.52899\n",
      "Epoch 188/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 36093.5686 - acc: 0.0054 - val_loss: 10739.3040 - val_acc: 0.0038\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 7577.52899\n",
      "Epoch 189/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 35941.1880 - acc: 0.0052 - val_loss: 14612.1139 - val_acc: 0.0080\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 7577.52899\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 38468.4975 - acc: 0.0052 - val_loss: 13967.9270 - val_acc: 0.0072\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 7577.52899\n",
      "Epoch 191/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 33710.1597 - acc: 0.0048 - val_loss: 23150.8737 - val_acc: 0.0060\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 7577.52899\n",
      "Epoch 192/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 31540.3024 - acc: 0.0052 - val_loss: 6410.7995 - val_acc: 0.0110\n",
      "\n",
      "Epoch 00192: val_loss improved from 7577.52899 to 6410.79947, saving model to ./model/192-6410.7995.hdf5\n",
      "Epoch 193/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 28438.9662 - acc: 0.0047 - val_loss: 18171.8842 - val_acc: 0.0028\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 6410.79947\n",
      "Epoch 194/200\n",
      "3025701/3025701 [==============================] - 146s 48us/step - loss: 44053.5782 - acc: 0.0055 - val_loss: 7171.3889 - val_acc: 0.0090\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 6410.79947\n",
      "Epoch 195/200\n",
      "3025701/3025701 [==============================] - 147s 48us/step - loss: 51260.3051 - acc: 0.0056 - val_loss: 155270.5829 - val_acc: 0.0024\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 6410.79947\n",
      "Epoch 196/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 24410.5251 - acc: 0.0056 - val_loss: 21435.3624 - val_acc: 0.0017\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 6410.79947\n",
      "Epoch 197/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 36860.3367 - acc: 0.0049 - val_loss: 159115.6518 - val_acc: 5.4753e-05\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 6410.79947\n",
      "Epoch 198/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 33137.7187 - acc: 0.0052 - val_loss: 23146.1846 - val_acc: 0.0050\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 6410.79947\n",
      "Epoch 199/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 31123.5404 - acc: 0.0052 - val_loss: 8709.1642 - val_acc: 0.0037\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 6410.79947\n",
      "Epoch 200/200\n",
      "3025701/3025701 [==============================] - 147s 49us/step - loss: 39353.4377 - acc: 0.0054 - val_loss: 14431.1444 - val_acc: 0.0019\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 6410.79947\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  29352.8549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "120.86004337980673"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(140, input_dim=14, activation='relu'))\n",
    "model.add(Dense(1400, activation='relu'))\n",
    "model.add(Dense(2800, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 저장 폴더 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "# loss는 train loss고 val_loss는 validation loss임 / acc도 마찬가지\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, \n",
    "                    validation_split=0.3, \n",
    "                    epochs=200, \n",
    "                    batch_size=1000, \n",
    "                    callbacks=[checkpointer])\n",
    "\n",
    "\n",
    "y_vloss = history.history['val_loss']\n",
    "y_acc = history.history['acc']\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "modelPred = model.predict(x_test)\n",
    "end = time.time() - start\n",
    "print('time: ', round(end,4))\n",
    "RMSE = sqrt(mean_squared_error(y_test, modelPred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.78360299149645"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./model/138-8890.8330.hdf5')\n",
    "modelPred = model.predict(x_test)\n",
    "RMSE = sqrt(mean_squared_error(y_test, modelPred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.72560649988823"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('./model/192-6410.7995.hdf5')\n",
    "modelPred = model.predict(x_test)\n",
    "RMSE = sqrt(mean_squared_error(y_test, modelPred))\n",
    "RMSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
