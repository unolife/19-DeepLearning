{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN을 이용한 텍스트 생성(즉시 실행)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "<td>\n",
    "<a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/sequences/text_generation\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "</td><td>\n",
    "<a target=\"_blank\"  href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/sequences/text_generation.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
    "</td><td>\n",
    "<a target=\"_blank\"  href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/sequences/text_generation.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 이 문서는 텐서플로 커뮤니티에서 번역했습니다. 커뮤니티 번역 활동의 특성상 정확한 번역과 최신 내용을 반영하기 위해 노력함에도\n",
    "불구하고 [공식 영문 문서](https://www.tensorflow.org/?hl=en)의 내용과 일치하지 않을 수 있습니다.\n",
    "이 번역에 개선할 부분이 있다면\n",
    "[tensorflow/docs](https://github.com/tensorflow/docs) 깃헙 저장소로 풀 리퀘스트를 보내주시기 바랍니다.\n",
    "문서 번역이나 리뷰에 지원하려면 [이 양식](https://bit.ly/tf-translate)을\n",
    "작성하거나\n",
    "[docs@tensorflow.org](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs)로\n",
    "메일을 보내주시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf-nightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 튜토리얼은 철자기반의 RNN을 이용해서 어떻게 텍스트를 생성할 수 있는지를 설명한다. Andrej Karpathy의 [반복신경망의 비합리적 효과](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)셰익스피어의 작품 데이터셋을 가지고 작업을 할 예정이다. 이 데이터(셰익스피어)에서 나오는 일련의 문자들(\"e\")을 고려하여, 그 순서에서 다음 문자를 예측하기 위해서 모델을 학습시킨다. 모델을 반복적으로 호출함으로써 더 긴 텍스트 시퀀스가 생성할 수 있다.\n",
    "\n",
    "Note: GPU 가속을 활성화하여 이 노트북을 더 빠르게 실행할 수 있다. In Colab: *Runtime > Change runtime type > Hardware acclerator > GPU*. 만약 로컬환경에서 실행한다면, TensorFlow 버전이 1.11 이상인지 확인해야 한다.\n",
    "\n",
    "이 튜토리얼은 [tf.keras](https://www.tensorflow.org/programmers_guide/keras)와 [eager excution](https://www.tensorflow.org/programmers_guide/eager)(즉시실행)로 구현된 실행 가능한 코드를 포함한다. 이 튜토리얼의 모델이 30 에포크(epoch) 동안 학습하고, 문자 \"Q\"로 시작했을때 나온 샘플 출력이다:\n",
    "\n",
    "<pre>\n",
    "QUEENE:\n",
    "I had thought thou hadst a Roman; for the oracle,\n",
    "Thus by All bids the man against the word,\n",
    "Which are so weak of care, by old care done;\n",
    "Your children were in your holy love,\n",
    "And the precipitation through the bleeding throne.\n",
    "\n",
    "BISHOP OF ELY:\n",
    "Marry, and will, my lord, to weep in such a one were prettiest;\n",
    "Yet now I was adopted heir\n",
    "Of the world's lamentable day,\n",
    "To watch the next way with his father with his face?\n",
    "\n",
    "ESCALUS:\n",
    "The cause why then we are all resolved more sons.\n",
    "\n",
    "VOLUMNIA:\n",
    "O, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, it is no sin it should be dead,\n",
    "And love and pale as any will to that word.\n",
    "\n",
    "QUEEN ELIZABETH:\n",
    "But how long have I heard the soul for this world,\n",
    "And show his hands of life be proved to stand.\n",
    "\n",
    "PETRUCHIO:\n",
    "I say he look'd on, if I must be content\n",
    "To stay him from the fatal of our country's bliss.\n",
    "His lordship pluck'd from this sentence then for prey,\n",
    "And then let us twain, being the moon,\n",
    "were she such a case as fills m\n",
    "</pre>\n",
    "\n",
    "일부 문장은 문법적이지만, 대부분은 말이 안 되는 문장이다. 모델은 단어의 의미를 학습해오지 않았다, 그러나 다음 사항들을 고려해보자:\n",
    "\n",
    "* 모델은 철자 기반이다. 학습을 시작할 때, 모델은 영어 단어의 철자를 어떻게 쓰는지 알지 못하거나 심지어 단어들이 텍스트의 단위라는 것을 알지 못했다.\n",
    "\n",
    "* 출력의 구조는 연극의 대본과 유사하다 - 텍스트 블록이 대체적으로 데이터셋과 유사하게 모두 대문자로된 화자의 이름으로 시작한다.\n",
    "\n",
    "* 아래에서 증명된 바와 같이 모델은 작은 텍스트 묶음(각각 100자)에 대해 학습되며, 여전히 일관된 구조를 가진 긴 텍스트 시퀀스를 생성할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로우 및 다른 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셰익스피어 데이터셋 다운로드\n",
    "\n",
    "자신의 데이터에서 이 코드를 실행하려면 다음 행을 변경하십시오.(셰익스피어 외의 개인 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1122304/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 읽기\n",
    "먼저, 본문을 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat. / 읽은 다음, py2 호환을 위해 디코딩한다.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it  / 텍스트의 길이는 그 안에 있는 문자 수이다.\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text  /  텍스트의 처음 250자를 보자.\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file / 파일에 있는 고유한 문자\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 벡터화\n",
    "학습을 이전에 우리는 문자열을 대표 수치값과 연결(사상)시켜야 한다. 두 개의 검색 테이블 생성: 하나는 문자를 숫자에 연결시키기 위함이고, 다른 하나는 숫자를 문자에 연결시키기 위함이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 우리는 각 문자에 대한 정수 표현을 가지고 있다. 0부터 `len(unique)`까지의 인덱스로 문자를 매핑(연결, 사상)한 것에 주의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '$' :   3,\n",
      "  '&' :   4,\n",
      "  \"'\" :   5,\n",
      "  ',' :   6,\n",
      "  '-' :   7,\n",
      "  '.' :   8,\n",
      "  '3' :   9,\n",
      "  ':' :  10,\n",
      "  ';' :  11,\n",
      "  '?' :  12,\n",
      "  'A' :  13,\n",
      "  'B' :  14,\n",
      "  'C' :  15,\n",
      "  'D' :  16,\n",
      "  'E' :  17,\n",
      "  'F' :  18,\n",
      "  'G' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen' ---- characters mapped to int ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "# Show how the first 13 characters from the text are mapped to integers\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "철자 하나 혹은 일련의 철자들을 고려했을 때, 가장 그럴듯한 다음 철자는 무엇인가? 이것은 우리가 (예측을) 수행하기 위해 모델을 학습시키는 작업이다. 모델에 대한 입력은 일련의 철자들이고, 우리는 각 단계마다 다음 문자, 즉 출력을 예측하기 위해 모델을 학습시킨다.\n",
    "\n",
    "RNN은 이전에 본 요소에 의존하는 내부 상태를 유지하므로, 이 순간까지 연산된 모든 문자를 고려하면, 다음 문자는 무엇인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 예제 및 타겟(목표변수) 생성\n",
    "\n",
    "다음으로 텍스트를 예제 시퀀스로 나눠라. 각 입력 시퀀스는 텍스트로 부터 얻은 문자들의 `seq_length`를 포함한다. \n",
    "한 문자를 오른쪽으로 이동하지 않는 한, 해당 대상에는 동일한 길이의 텍스트가 포함되어 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
